{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import gridspec\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "\n",
    "# Устанавливаем seed для воспроизводимости результатов\n",
    "np.random.seed(42)\n",
    "\n",
    "# Генерируем датасет\n",
    "n = 1000\n",
    "X, Y = make_classification(n_samples=n, n_features=5, n_redundant=0, n_classes=2, random_state=42)\n",
    "\n",
    "# Преобразуем тип данных в np.float32 и np.int32 для X и Y соответственно\n",
    "X = X.astype(np.float32)\n",
    "Y = Y.astype(np.int32)\n",
    "\n",
    "# Разделяем данные на обучающий и тестовый наборы\n",
    "train_x, test_x, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем датасет\n",
    "n = 1000\n",
    "X, Y = make_classification(n_samples=n, n_features=5, n_redundant=0, n_classes=2, random_state=42)\n",
    "\n",
    "# Преобразуем тип данных в np.float32 и np.int32 для X и Y соответственно\n",
    "X = X.astype(np.float32)\n",
    "Y = Y.astype(np.int32)\n",
    "\n",
    "# Разделяем данные на обучающий и тестовый наборы\n",
    "train_x, test_x, train_labels, test_labels = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.train_loss_history = []\n",
    "        self.test_loss_history = []\n",
    "\n",
    "    class Linear:\n",
    "        def __init__(\n",
    "                self,\n",
    "                nin,\n",
    "                nout,\n",
    "                momentum:float=0.9\n",
    "            ):\n",
    "            np.random.seed(42)\n",
    "            self.W = np.random.randn(nin, nout) # упростим инициализацию весов\n",
    "            self.b = np.ones((1, nout)) # упростим инициализацию байесов\n",
    "            self.dW = np.random.randn(self.W.shape[0], self.W.shape[1]) # можно не инициализировать будет далее\n",
    "            self.db = np.random.randn(self.b.shape[0], self.b.shape[1]) # можно не инициализировать будет далее\n",
    "            self.previous_dW = np.zeros_like(self.W) # для момента\n",
    "            self.previous_db = np.zeros_like(self.b) # для момента\n",
    "            self.momentum = momentum\n",
    "            self.x = None\n",
    "\n",
    "\n",
    "        def forward(self, x):\n",
    "            self.x = x\n",
    "            return np.dot(x, self.W) + self.b\n",
    "\n",
    "        def backward(self, dz):\n",
    "            dx = np.dot(dz, self.W.T)\n",
    "            self.dW = np.dot(self.x.T, dz)\n",
    "            self.db = dz.sum(axis=0)\n",
    "            return dx\n",
    "\n",
    "        def update(self, lr):\n",
    "            self.W -= lr * self.dW\n",
    "            self.b -= lr * self.db\n",
    "\n",
    "    class Softmax:\n",
    "        def forward(self,z):\n",
    "            self.z = z\n",
    "            zmax = z.max(axis=1,keepdims=True)\n",
    "            expz = np.exp(z-zmax)\n",
    "            Z = expz.sum(axis=1,keepdims=True)\n",
    "            return expz / Z\n",
    "        def backward(self,dp):\n",
    "            p = self.forward(self.z)\n",
    "            pdp = p * dp\n",
    "            return pdp - p * pdp.sum(axis=1, keepdims=True)\n",
    "        \n",
    "    class CrossEntropyLoss:\n",
    "        def forward(self,p,y):\n",
    "            self.p = p\n",
    "            self.y = y\n",
    "            p_of_y = p[np.arange(len(y)), y]\n",
    "            log_prob = np.log(p_of_y)\n",
    "            return -log_prob.mean()\n",
    "        \n",
    "        def backward(self):\n",
    "            dlog_softmax = np.zeros_like(self.p)\n",
    "            dlog_softmax[np.arange(len(self.y)), self.y] -= 1.0/len(self.y)\n",
    "            return dlog_softmax / self.p\n",
    "\n",
    "    class Sigmoid:\n",
    "        def forward(self, z):\n",
    "            self.z = z\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "\n",
    "        def backward(self, dp):\n",
    "            sig = self.forward(self.z)\n",
    "            return dp * sig * (1 - sig)\n",
    "        \n",
    "\n",
    "    class ReLU:\n",
    "        def forward(self, z):\n",
    "            self.z = z\n",
    "            return np.maximum(0, z)\n",
    "\n",
    "        def backward(self, dp):\n",
    "            dz = np.where(self.z > 0, 1, 0)\n",
    "            return dp * dz\n",
    "\n",
    "        \n",
    "    class BinaryCrossEntropyLoss:\n",
    "        def forward(self, p, y):\n",
    "            self.p = p\n",
    "            self.y = y\n",
    "            self.y_binary = np.zeros((len(y), 2))\n",
    "            self.y_binary[np.arange(len(y)), y] = 1\n",
    "            return -np.mean(self.y_binary * np.log(p) + (1 - self.y_binary) * np.log(1 - p))\n",
    "                \n",
    "        def backward(self):\n",
    "            return (self.p - self.y_binary) / self.p.shape[0]\n",
    "        \n",
    "    class MeanSquaredError:\n",
    "        def forward(self, p, y):\n",
    "            self.p = p\n",
    "            self.y = y\n",
    "            return np.mean((p - y) ** 2)\n",
    "\n",
    "        def backward(self):\n",
    "            return (2 * (self.p - self.y)) / self.p.shape[0]\n",
    "\n",
    "\n",
    "    class MeanAbsoluteError:\n",
    "        def forward(self, p, y):\n",
    "            self.p = p\n",
    "            self.y = y\n",
    "            return np.mean(np.abs(p - y))\n",
    "\n",
    "        def backward(self):\n",
    "            return np.sign(self.p - self.y) / self.p.shape[0]\n",
    "    \n",
    "    def add(self, layer_type, *args, **kwargs):\n",
    "        if layer_type == 'Linear':\n",
    "            self.layers.append(self.Linear(*args, **kwargs))\n",
    "        elif layer_type == 'Softmax':\n",
    "            self.layers.append(self.Softmax(*args, **kwargs))\n",
    "        elif layer_type == 'Sigmoid':\n",
    "            self.layers.append(self.Sigmoid(*args, **kwargs))\n",
    "        elif layer_type == 'ReLU':  # Добавляем блок для слоя ReLU\n",
    "            self.layers.append(self.ReLU(*args, **kwargs))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown layer type\")\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self,z):\n",
    "        for l in self.layers[::-1]:\n",
    "            z = l.backward(z)\n",
    "        return z\n",
    "    \n",
    "    def update(self,lr):\n",
    "        for layer in self.layers:\n",
    "            if 'update' in layer.__dir__():\n",
    "                layer.update(lr)\n",
    "\n",
    "    def update_momentum_sgd(self, lr):\n",
    "        for layer in self.layers:\n",
    "            if 'update' in layer.__dir__():\n",
    "                dW = layer.dW\n",
    "                db = layer.db\n",
    "                # Add momentum to the update\n",
    "                dW = layer.momentum * layer.previous_dW + (1 - layer.momentum) * dW\n",
    "                db = layer.momentum * layer.previous_db + (1 - layer.momentum) * db\n",
    "                # Update weights and biases\n",
    "                layer.update(lr)\n",
    "                # Update previous gradients for the next iteration\n",
    "                layer.previous_dW = dW\n",
    "                layer.previous_db = db\n",
    "\n",
    "    def fit(self,\n",
    "            task_type:str,\n",
    "            epochs:int,\n",
    "            train_dataset:list,\n",
    "            loss_f,\n",
    "            lr,\n",
    "            optimizer:str,\n",
    "            batch_size:int=None,\n",
    "            val_dataset:list=None\n",
    "        ):\n",
    "\n",
    "        self.task_type = task_type\n",
    "        \n",
    "        for epoch in range(1, epochs+1):            \n",
    "            if optimizer == 'sgd':\n",
    "                for sample in range(len(train_dataset[0])):\n",
    "                    random_sample = np.random.randint(0, len(train_dataset[0]))\n",
    "                    xb = train_dataset[0][random_sample:random_sample+1]\n",
    "                    yb = train_dataset[1][random_sample:random_sample+1]\n",
    "                    # forward pass\n",
    "                    p = self.forward(xb)\n",
    "                    # backward pass\n",
    "                    loss = loss_f.forward(p, np.array(yb).reshape(-1))\n",
    "                    dp = loss_f.backward()  # передаем прогнозы и метки в метод backward\n",
    "                    # if self.task_type == 'regression':\n",
    "                    #     dp = dp[0].reshape(-1,1)\n",
    "                    dz = self.backward(dp)\n",
    "                    # update\n",
    "                    self.update(lr)\n",
    "            elif optimizer == 'minibatch_sgd':\n",
    "                for batch in range(0, len(train_dataset[0]), batch_size):\n",
    "                    random_sample = np.random.randint(0, len(train_dataset[0]))\n",
    "                    xb = train_dataset[0][random_sample:random_sample+batch_size]\n",
    "                    yb = train_dataset[1][random_sample:random_sample+batch_size] \n",
    "                    # forward pass\n",
    "                    p = self.forward(xb)\n",
    "                    # backward pass\n",
    "                    loss = loss_f.forward(p, np.array(yb).reshape(-1))\n",
    "                    dp = loss_f.backward()  # передаем прогнозы и метки в метод backward\n",
    "                    if self.task_type == 'regression':\n",
    "                        dp = dp.mean(axis=1).reshape(-1,1)\n",
    "                    dz = self.backward(dp)\n",
    "                    # update\n",
    "                    self.update(lr)\n",
    "            elif optimizer == 'momentum_sgd':\n",
    "                for batch in range(0, len(train_dataset[0]), batch_size):\n",
    "                    random_sample = np.random.randint(0, len(train_dataset[0]))\n",
    "                    xb = train_dataset[0][random_sample:random_sample+batch_size]\n",
    "                    yb = train_dataset[1][random_sample:random_sample+batch_size]\n",
    "\n",
    "                    # forward pass\n",
    "                    p = self.forward(xb)\n",
    "\n",
    "                    # backward pass\n",
    "                    loss = loss_f.forward(p, np.array(yb).reshape(-1))\n",
    "                    dp = loss_f.backward()\n",
    "                    if self.task_type == 'regression':\n",
    "                        dp = dp.mean(axis=1).reshape(-1,1)\n",
    "                    dz = self.backward(dp)\n",
    "\n",
    "                    # update\n",
    "                    self.update_momentum_sgd(lr)\n",
    "            elif optimizer == 'gd':\n",
    "                xb = train_dataset[0]\n",
    "                yb = train_dataset[1]\n",
    "                # forward pass\n",
    "                p = self.forward(xb)\n",
    "                # backward pass\n",
    "                loss = loss_f.forward(p, np.array(yb).reshape(-1))\n",
    "                dp = loss_f.backward()  # передаем прогнозы и метки в метод backward\n",
    "                if self.task_type == 'regression':\n",
    "                        dp = dp.mean(axis=1).reshape(-1,1)\n",
    "                dz = self.backward(dp)\n",
    "                # update\n",
    "                self.update(lr)\n",
    "\n",
    "            train_loss = self.get_loss(\n",
    "                x=train_dataset[0],\n",
    "                y=train_dataset[1],\n",
    "                loss_f=loss_f\n",
    "            )\n",
    "            self.train_loss_history.append(train_loss)\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            print(f\"train_loss = {train_loss:.4f}\")\n",
    "            if val_dataset:\n",
    "                test_loss = self.get_loss(\n",
    "                    x=val_dataset[0],\n",
    "                    y=val_dataset[1],\n",
    "                    loss_f=loss_f\n",
    "                )\n",
    "                self.test_loss_history.append(test_loss)\n",
    "                print(f\"test_loss = {test_loss:.4f}\")\n",
    "            print('****************************')\n",
    "\n",
    "            \n",
    "\n",
    "                    \n",
    "    def get_loss(self, x, y, loss_f):\n",
    "        p = self.forward(x)  # Прямой проход через сеть для получения предсказаний\n",
    "        l = loss_f.forward(p, np.array(y).reshape(-1))  # Вычисление потерь с помощью loss_f\n",
    "        return l\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        if self.task_type == 'regression':\n",
    "            y = np.array(y).reshape(-1)\n",
    "            pred = self.predict(x)\n",
    "            r2 = r2_score(y, pred)  # Вычисление коэффициента детерминации\n",
    "            mse = mean_squared_error(y, pred)  # Вычисление среднеквадратичной ошибки\n",
    "            mae = mean_absolute_error(y, pred)  # Вычисление средней абсолютной ошибки\n",
    "            mape = np.mean(np.abs((y - pred) / y)) * 100  # Вычисление средней абсолютной процентной ошибки\n",
    "            return r2, mse, mae, mape\n",
    "        elif self.task_type == 'classification':\n",
    "            probas = self.forward(x)  # Прямой проход через сеть для получения вероятностей\n",
    "            pred = np.argmax(probas, axis=1)  # Преобразование вероятностей в предсказанные классы\n",
    "            acc = round(accuracy_score(y, pred, normalize=True), 4)  # Вычисление средней точности\n",
    "            return acc\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if self.task_type == 'regression':\n",
    "            return self.forward(x)  # Прямой проход через сеть для получения прогнозов\n",
    "        elif self.task_type == 'classification':\n",
    "            probas = self.forward(x)  # Прямой проход через сеть для получения вероятностей\n",
    "            pred = np.argmax(probas, axis=1)  # Выбор класса с наибольшей вероятностью\n",
    "            return pred\n",
    "        \n",
    "    def print_loss_history(self):\n",
    "        plt.plot(self.train_loss_history, label='loss_train')\n",
    "        plt.plot(self.test_loss_history, label='loss_test')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss metric')\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "train_loss = 0.7063\n",
      "test_loss = 0.6997\n",
      "****************************\n",
      "Epoch: 2\n",
      "train_loss = 0.6673\n",
      "test_loss = 0.6570\n",
      "****************************\n",
      "Epoch: 3\n",
      "train_loss = 0.6291\n",
      "test_loss = 0.6176\n",
      "****************************\n",
      "Epoch: 4\n",
      "train_loss = 0.5785\n",
      "test_loss = 0.5691\n",
      "****************************\n",
      "Epoch: 5\n",
      "train_loss = 0.5197\n",
      "test_loss = 0.5122\n",
      "****************************\n",
      "Epoch: 6\n",
      "train_loss = 0.4652\n",
      "test_loss = 0.4627\n",
      "****************************\n",
      "Epoch: 7\n",
      "train_loss = 0.4254\n",
      "test_loss = 0.4263\n",
      "****************************\n",
      "Epoch: 8\n",
      "train_loss = 0.4009\n",
      "test_loss = 0.4046\n",
      "****************************\n",
      "Epoch: 9\n",
      "train_loss = 0.3841\n",
      "test_loss = 0.3902\n",
      "****************************\n",
      "Epoch: 10\n",
      "train_loss = 0.3723\n",
      "test_loss = 0.3800\n",
      "****************************\n",
      "Epoch: 11\n",
      "train_loss = 0.3639\n",
      "test_loss = 0.3742\n",
      "****************************\n",
      "Epoch: 12\n",
      "train_loss = 0.3567\n",
      "test_loss = 0.3684\n",
      "****************************\n",
      "Epoch: 13\n",
      "train_loss = 0.3519\n",
      "test_loss = 0.3662\n",
      "****************************\n",
      "Epoch: 14\n",
      "train_loss = 0.3493\n",
      "test_loss = 0.3644\n",
      "****************************\n",
      "Epoch: 15\n",
      "train_loss = 0.3457\n",
      "test_loss = 0.3621\n",
      "****************************\n",
      "Epoch: 16\n",
      "train_loss = 0.3438\n",
      "test_loss = 0.3612\n",
      "****************************\n",
      "Epoch: 17\n",
      "train_loss = 0.3431\n",
      "test_loss = 0.3615\n",
      "****************************\n",
      "Epoch: 18\n",
      "train_loss = 0.3401\n",
      "test_loss = 0.3597\n",
      "****************************\n",
      "Epoch: 19\n",
      "train_loss = 0.3383\n",
      "test_loss = 0.3565\n",
      "****************************\n",
      "Epoch: 20\n",
      "train_loss = 0.3372\n",
      "test_loss = 0.3558\n",
      "****************************\n",
      "Epoch: 21\n",
      "train_loss = 0.3375\n",
      "test_loss = 0.3577\n",
      "****************************\n",
      "Epoch: 22\n",
      "train_loss = 0.3368\n",
      "test_loss = 0.3561\n",
      "****************************\n",
      "Epoch: 23\n",
      "train_loss = 0.3364\n",
      "test_loss = 0.3557\n",
      "****************************\n",
      "Epoch: 24\n",
      "train_loss = 0.3346\n",
      "test_loss = 0.3550\n",
      "****************************\n",
      "Epoch: 25\n",
      "train_loss = 0.3340\n",
      "test_loss = 0.3549\n",
      "****************************\n",
      "Epoch: 26\n",
      "train_loss = 0.3338\n",
      "test_loss = 0.3527\n",
      "****************************\n",
      "Epoch: 27\n",
      "train_loss = 0.3342\n",
      "test_loss = 0.3545\n",
      "****************************\n",
      "Epoch: 28\n",
      "train_loss = 0.3330\n",
      "test_loss = 0.3531\n",
      "****************************\n",
      "Epoch: 29\n",
      "train_loss = 0.3329\n",
      "test_loss = 0.3534\n",
      "****************************\n",
      "Epoch: 30\n",
      "train_loss = 0.3327\n",
      "test_loss = 0.3527\n",
      "****************************\n",
      "Epoch: 31\n",
      "train_loss = 0.3320\n",
      "test_loss = 0.3533\n",
      "****************************\n",
      "Epoch: 32\n",
      "train_loss = 0.3320\n",
      "test_loss = 0.3542\n",
      "****************************\n",
      "Epoch: 33\n",
      "train_loss = 0.3316\n",
      "test_loss = 0.3538\n",
      "****************************\n",
      "Epoch: 34\n",
      "train_loss = 0.3310\n",
      "test_loss = 0.3522\n",
      "****************************\n",
      "Epoch: 35\n",
      "train_loss = 0.3312\n",
      "test_loss = 0.3534\n",
      "****************************\n",
      "Epoch: 36\n",
      "train_loss = 0.3303\n",
      "test_loss = 0.3522\n",
      "****************************\n",
      "Epoch: 37\n",
      "train_loss = 0.3305\n",
      "test_loss = 0.3517\n",
      "****************************\n",
      "Epoch: 38\n",
      "train_loss = 0.3301\n",
      "test_loss = 0.3512\n",
      "****************************\n",
      "Epoch: 39\n",
      "train_loss = 0.3303\n",
      "test_loss = 0.3521\n",
      "****************************\n",
      "Epoch: 40\n",
      "train_loss = 0.3298\n",
      "test_loss = 0.3511\n",
      "****************************\n",
      "Epoch: 41\n",
      "train_loss = 0.3296\n",
      "test_loss = 0.3496\n",
      "****************************\n",
      "Epoch: 42\n",
      "train_loss = 0.3297\n",
      "test_loss = 0.3489\n",
      "****************************\n",
      "Epoch: 43\n",
      "train_loss = 0.3295\n",
      "test_loss = 0.3498\n",
      "****************************\n",
      "Epoch: 44\n",
      "train_loss = 0.3288\n",
      "test_loss = 0.3499\n",
      "****************************\n",
      "Epoch: 45\n",
      "train_loss = 0.3287\n",
      "test_loss = 0.3493\n",
      "****************************\n",
      "Epoch: 46\n",
      "train_loss = 0.3287\n",
      "test_loss = 0.3498\n",
      "****************************\n",
      "Epoch: 47\n",
      "train_loss = 0.3293\n",
      "test_loss = 0.3513\n",
      "****************************\n",
      "Epoch: 48\n",
      "train_loss = 0.3290\n",
      "test_loss = 0.3502\n",
      "****************************\n",
      "Epoch: 49\n",
      "train_loss = 0.3294\n",
      "test_loss = 0.3506\n",
      "****************************\n",
      "Epoch: 50\n",
      "train_loss = 0.3280\n",
      "test_loss = 0.3491\n",
      "****************************\n",
      "Epoch: 51\n",
      "train_loss = 0.3279\n",
      "test_loss = 0.3492\n",
      "****************************\n",
      "Epoch: 52\n",
      "train_loss = 0.3278\n",
      "test_loss = 0.3494\n",
      "****************************\n",
      "Epoch: 53\n",
      "train_loss = 0.3295\n",
      "test_loss = 0.3507\n",
      "****************************\n",
      "Epoch: 54\n",
      "train_loss = 0.3282\n",
      "test_loss = 0.3496\n",
      "****************************\n",
      "Epoch: 55\n",
      "train_loss = 0.3277\n",
      "test_loss = 0.3490\n",
      "****************************\n",
      "Epoch: 56\n",
      "train_loss = 0.3278\n",
      "test_loss = 0.3493\n",
      "****************************\n",
      "Epoch: 57\n",
      "train_loss = 0.3273\n",
      "test_loss = 0.3475\n",
      "****************************\n",
      "Epoch: 58\n",
      "train_loss = 0.3278\n",
      "test_loss = 0.3490\n",
      "****************************\n",
      "Epoch: 59\n",
      "train_loss = 0.3273\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 60\n",
      "train_loss = 0.3269\n",
      "test_loss = 0.3472\n",
      "****************************\n",
      "Epoch: 61\n",
      "train_loss = 0.3277\n",
      "test_loss = 0.3475\n",
      "****************************\n",
      "Epoch: 62\n",
      "train_loss = 0.3275\n",
      "test_loss = 0.3462\n",
      "****************************\n",
      "Epoch: 63\n",
      "train_loss = 0.3279\n",
      "test_loss = 0.3482\n",
      "****************************\n",
      "Epoch: 64\n",
      "train_loss = 0.3269\n",
      "test_loss = 0.3463\n",
      "****************************\n",
      "Epoch: 65\n",
      "train_loss = 0.3270\n",
      "test_loss = 0.3469\n",
      "****************************\n",
      "Epoch: 66\n",
      "train_loss = 0.3285\n",
      "test_loss = 0.3494\n",
      "****************************\n",
      "Epoch: 67\n",
      "train_loss = 0.3286\n",
      "test_loss = 0.3493\n",
      "****************************\n",
      "Epoch: 68\n",
      "train_loss = 0.3274\n",
      "test_loss = 0.3479\n",
      "****************************\n",
      "Epoch: 69\n",
      "train_loss = 0.3272\n",
      "test_loss = 0.3477\n",
      "****************************\n",
      "Epoch: 70\n",
      "train_loss = 0.3269\n",
      "test_loss = 0.3465\n",
      "****************************\n",
      "Epoch: 71\n",
      "train_loss = 0.3277\n",
      "test_loss = 0.3468\n",
      "****************************\n",
      "Epoch: 72\n",
      "train_loss = 0.3282\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 73\n",
      "train_loss = 0.3272\n",
      "test_loss = 0.3482\n",
      "****************************\n",
      "Epoch: 74\n",
      "train_loss = 0.3266\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 75\n",
      "train_loss = 0.3265\n",
      "test_loss = 0.3487\n",
      "****************************\n",
      "Epoch: 76\n",
      "train_loss = 0.3266\n",
      "test_loss = 0.3491\n",
      "****************************\n",
      "Epoch: 77\n",
      "train_loss = 0.3261\n",
      "test_loss = 0.3478\n",
      "****************************\n",
      "Epoch: 78\n",
      "train_loss = 0.3264\n",
      "test_loss = 0.3486\n",
      "****************************\n",
      "Epoch: 79\n",
      "train_loss = 0.3263\n",
      "test_loss = 0.3486\n",
      "****************************\n",
      "Epoch: 80\n",
      "train_loss = 0.3263\n",
      "test_loss = 0.3482\n",
      "****************************\n",
      "Epoch: 81\n",
      "train_loss = 0.3262\n",
      "test_loss = 0.3478\n",
      "****************************\n",
      "Epoch: 82\n",
      "train_loss = 0.3261\n",
      "test_loss = 0.3483\n",
      "****************************\n",
      "Epoch: 83\n",
      "train_loss = 0.3259\n",
      "test_loss = 0.3480\n",
      "****************************\n",
      "Epoch: 84\n",
      "train_loss = 0.3256\n",
      "test_loss = 0.3476\n",
      "****************************\n",
      "Epoch: 85\n",
      "train_loss = 0.3258\n",
      "test_loss = 0.3472\n",
      "****************************\n",
      "Epoch: 86\n",
      "train_loss = 0.3258\n",
      "test_loss = 0.3465\n",
      "****************************\n",
      "Epoch: 87\n",
      "train_loss = 0.3260\n",
      "test_loss = 0.3469\n",
      "****************************\n",
      "Epoch: 88\n",
      "train_loss = 0.3255\n",
      "test_loss = 0.3468\n",
      "****************************\n",
      "Epoch: 89\n",
      "train_loss = 0.3255\n",
      "test_loss = 0.3466\n",
      "****************************\n",
      "Epoch: 90\n",
      "train_loss = 0.3256\n",
      "test_loss = 0.3461\n",
      "****************************\n",
      "Epoch: 91\n",
      "train_loss = 0.3256\n",
      "test_loss = 0.3467\n",
      "****************************\n",
      "Epoch: 92\n",
      "train_loss = 0.3257\n",
      "test_loss = 0.3467\n",
      "****************************\n",
      "Epoch: 93\n",
      "train_loss = 0.3256\n",
      "test_loss = 0.3475\n",
      "****************************\n",
      "Epoch: 94\n",
      "train_loss = 0.3269\n",
      "test_loss = 0.3488\n",
      "****************************\n",
      "Epoch: 95\n",
      "train_loss = 0.3257\n",
      "test_loss = 0.3470\n",
      "****************************\n",
      "Epoch: 96\n",
      "train_loss = 0.3259\n",
      "test_loss = 0.3458\n",
      "****************************\n",
      "Epoch: 97\n",
      "train_loss = 0.3256\n",
      "test_loss = 0.3456\n",
      "****************************\n",
      "Epoch: 98\n",
      "train_loss = 0.3253\n",
      "test_loss = 0.3456\n",
      "****************************\n",
      "Epoch: 99\n",
      "train_loss = 0.3252\n",
      "test_loss = 0.3448\n",
      "****************************\n",
      "Epoch: 100\n",
      "train_loss = 0.3261\n",
      "test_loss = 0.3458\n",
      "****************************\n",
      "Epoch: 101\n",
      "train_loss = 0.3251\n",
      "test_loss = 0.3454\n",
      "****************************\n",
      "Epoch: 102\n",
      "train_loss = 0.3253\n",
      "test_loss = 0.3452\n",
      "****************************\n",
      "Epoch: 103\n",
      "train_loss = 0.3256\n",
      "test_loss = 0.3465\n",
      "****************************\n",
      "Epoch: 104\n",
      "train_loss = 0.3255\n",
      "test_loss = 0.3460\n",
      "****************************\n",
      "Epoch: 105\n",
      "train_loss = 0.3295\n",
      "test_loss = 0.3518\n",
      "****************************\n",
      "Epoch: 106\n",
      "train_loss = 0.3255\n",
      "test_loss = 0.3484\n",
      "****************************\n",
      "Epoch: 107\n",
      "train_loss = 0.3251\n",
      "test_loss = 0.3474\n",
      "****************************\n",
      "Epoch: 108\n",
      "train_loss = 0.3250\n",
      "test_loss = 0.3464\n",
      "****************************\n",
      "Epoch: 109\n",
      "train_loss = 0.3256\n",
      "test_loss = 0.3465\n",
      "****************************\n",
      "Epoch: 110\n",
      "train_loss = 0.3246\n",
      "test_loss = 0.3465\n",
      "****************************\n",
      "Epoch: 111\n",
      "train_loss = 0.3245\n",
      "test_loss = 0.3464\n",
      "****************************\n",
      "Epoch: 112\n",
      "train_loss = 0.3253\n",
      "test_loss = 0.3482\n",
      "****************************\n",
      "Epoch: 113\n",
      "train_loss = 0.3254\n",
      "test_loss = 0.3491\n",
      "****************************\n",
      "Epoch: 114\n",
      "train_loss = 0.3251\n",
      "test_loss = 0.3482\n",
      "****************************\n",
      "Epoch: 115\n",
      "train_loss = 0.3248\n",
      "test_loss = 0.3478\n",
      "****************************\n",
      "Epoch: 116\n",
      "train_loss = 0.3246\n",
      "test_loss = 0.3471\n",
      "****************************\n",
      "Epoch: 117\n",
      "train_loss = 0.3253\n",
      "test_loss = 0.3466\n",
      "****************************\n",
      "Epoch: 118\n",
      "train_loss = 0.3250\n",
      "test_loss = 0.3468\n",
      "****************************\n",
      "Epoch: 119\n",
      "train_loss = 0.3254\n",
      "test_loss = 0.3479\n",
      "****************************\n",
      "Epoch: 120\n",
      "train_loss = 0.3247\n",
      "test_loss = 0.3478\n",
      "****************************\n",
      "Epoch: 121\n",
      "train_loss = 0.3252\n",
      "test_loss = 0.3478\n",
      "****************************\n",
      "Epoch: 122\n",
      "train_loss = 0.3258\n",
      "test_loss = 0.3478\n",
      "****************************\n",
      "Epoch: 123\n",
      "train_loss = 0.3250\n",
      "test_loss = 0.3484\n",
      "****************************\n",
      "Epoch: 124\n",
      "train_loss = 0.3249\n",
      "test_loss = 0.3484\n",
      "****************************\n",
      "Epoch: 125\n",
      "train_loss = 0.3244\n",
      "test_loss = 0.3475\n",
      "****************************\n",
      "Epoch: 126\n",
      "train_loss = 0.3245\n",
      "test_loss = 0.3485\n",
      "****************************\n",
      "Epoch: 127\n",
      "train_loss = 0.3250\n",
      "test_loss = 0.3488\n",
      "****************************\n",
      "Epoch: 128\n",
      "train_loss = 0.3251\n",
      "test_loss = 0.3487\n",
      "****************************\n",
      "Epoch: 129\n",
      "train_loss = 0.3256\n",
      "test_loss = 0.3496\n",
      "****************************\n",
      "Epoch: 130\n",
      "train_loss = 0.3247\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 131\n",
      "train_loss = 0.3252\n",
      "test_loss = 0.3497\n",
      "****************************\n",
      "Epoch: 132\n",
      "train_loss = 0.3244\n",
      "test_loss = 0.3484\n",
      "****************************\n",
      "Epoch: 133\n",
      "train_loss = 0.3247\n",
      "test_loss = 0.3487\n",
      "****************************\n",
      "Epoch: 134\n",
      "train_loss = 0.3244\n",
      "test_loss = 0.3493\n",
      "****************************\n",
      "Epoch: 135\n",
      "train_loss = 0.3245\n",
      "test_loss = 0.3498\n",
      "****************************\n",
      "Epoch: 136\n",
      "train_loss = 0.3245\n",
      "test_loss = 0.3487\n",
      "****************************\n",
      "Epoch: 137\n",
      "train_loss = 0.3244\n",
      "test_loss = 0.3482\n",
      "****************************\n",
      "Epoch: 138\n",
      "train_loss = 0.3243\n",
      "test_loss = 0.3476\n",
      "****************************\n",
      "Epoch: 139\n",
      "train_loss = 0.3242\n",
      "test_loss = 0.3474\n",
      "****************************\n",
      "Epoch: 140\n",
      "train_loss = 0.3241\n",
      "test_loss = 0.3467\n",
      "****************************\n",
      "Epoch: 141\n",
      "train_loss = 0.3240\n",
      "test_loss = 0.3467\n",
      "****************************\n",
      "Epoch: 142\n",
      "train_loss = 0.3242\n",
      "test_loss = 0.3455\n",
      "****************************\n",
      "Epoch: 143\n",
      "train_loss = 0.3238\n",
      "test_loss = 0.3463\n",
      "****************************\n",
      "Epoch: 144\n",
      "train_loss = 0.3243\n",
      "test_loss = 0.3474\n",
      "****************************\n",
      "Epoch: 145\n",
      "train_loss = 0.3243\n",
      "test_loss = 0.3470\n",
      "****************************\n",
      "Epoch: 146\n",
      "train_loss = 0.3252\n",
      "test_loss = 0.3486\n",
      "****************************\n",
      "Epoch: 147\n",
      "train_loss = 0.3245\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 148\n",
      "train_loss = 0.3240\n",
      "test_loss = 0.3483\n",
      "****************************\n",
      "Epoch: 149\n",
      "train_loss = 0.3243\n",
      "test_loss = 0.3490\n",
      "****************************\n",
      "Epoch: 150\n",
      "train_loss = 0.3237\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 151\n",
      "train_loss = 0.3236\n",
      "test_loss = 0.3476\n",
      "****************************\n",
      "Epoch: 152\n",
      "train_loss = 0.3237\n",
      "test_loss = 0.3482\n",
      "****************************\n",
      "Epoch: 153\n",
      "train_loss = 0.3237\n",
      "test_loss = 0.3476\n",
      "****************************\n",
      "Epoch: 154\n",
      "train_loss = 0.3238\n",
      "test_loss = 0.3476\n",
      "****************************\n",
      "Epoch: 155\n",
      "train_loss = 0.3236\n",
      "test_loss = 0.3475\n",
      "****************************\n",
      "Epoch: 156\n",
      "train_loss = 0.3235\n",
      "test_loss = 0.3468\n",
      "****************************\n",
      "Epoch: 157\n",
      "train_loss = 0.3236\n",
      "test_loss = 0.3468\n",
      "****************************\n",
      "Epoch: 158\n",
      "train_loss = 0.3233\n",
      "test_loss = 0.3466\n",
      "****************************\n",
      "Epoch: 159\n",
      "train_loss = 0.3237\n",
      "test_loss = 0.3471\n",
      "****************************\n",
      "Epoch: 160\n",
      "train_loss = 0.3233\n",
      "test_loss = 0.3462\n",
      "****************************\n",
      "Epoch: 161\n",
      "train_loss = 0.3232\n",
      "test_loss = 0.3454\n",
      "****************************\n",
      "Epoch: 162\n",
      "train_loss = 0.3233\n",
      "test_loss = 0.3451\n",
      "****************************\n",
      "Epoch: 163\n",
      "train_loss = 0.3236\n",
      "test_loss = 0.3464\n",
      "****************************\n",
      "Epoch: 164\n",
      "train_loss = 0.3234\n",
      "test_loss = 0.3457\n",
      "****************************\n",
      "Epoch: 165\n",
      "train_loss = 0.3231\n",
      "test_loss = 0.3464\n",
      "****************************\n",
      "Epoch: 166\n",
      "train_loss = 0.3232\n",
      "test_loss = 0.3467\n",
      "****************************\n",
      "Epoch: 167\n",
      "train_loss = 0.3239\n",
      "test_loss = 0.3477\n",
      "****************************\n",
      "Epoch: 168\n",
      "train_loss = 0.3235\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 169\n",
      "train_loss = 0.3233\n",
      "test_loss = 0.3469\n",
      "****************************\n",
      "Epoch: 170\n",
      "train_loss = 0.3239\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 171\n",
      "train_loss = 0.3231\n",
      "test_loss = 0.3472\n",
      "****************************\n",
      "Epoch: 172\n",
      "train_loss = 0.3238\n",
      "test_loss = 0.3494\n",
      "****************************\n",
      "Epoch: 173\n",
      "train_loss = 0.3236\n",
      "test_loss = 0.3491\n",
      "****************************\n",
      "Epoch: 174\n",
      "train_loss = 0.3232\n",
      "test_loss = 0.3475\n",
      "****************************\n",
      "Epoch: 175\n",
      "train_loss = 0.3230\n",
      "test_loss = 0.3475\n",
      "****************************\n",
      "Epoch: 176\n",
      "train_loss = 0.3229\n",
      "test_loss = 0.3466\n",
      "****************************\n",
      "Epoch: 177\n",
      "train_loss = 0.3234\n",
      "test_loss = 0.3468\n",
      "****************************\n",
      "Epoch: 178\n",
      "train_loss = 0.3238\n",
      "test_loss = 0.3465\n",
      "****************************\n",
      "Epoch: 179\n",
      "train_loss = 0.3231\n",
      "test_loss = 0.3457\n",
      "****************************\n",
      "Epoch: 180\n",
      "train_loss = 0.3235\n",
      "test_loss = 0.3470\n",
      "****************************\n",
      "Epoch: 181\n",
      "train_loss = 0.3234\n",
      "test_loss = 0.3471\n",
      "****************************\n",
      "Epoch: 182\n",
      "train_loss = 0.3230\n",
      "test_loss = 0.3459\n",
      "****************************\n",
      "Epoch: 183\n",
      "train_loss = 0.3228\n",
      "test_loss = 0.3460\n",
      "****************************\n",
      "Epoch: 184\n",
      "train_loss = 0.3228\n",
      "test_loss = 0.3458\n",
      "****************************\n",
      "Epoch: 185\n",
      "train_loss = 0.3229\n",
      "test_loss = 0.3463\n",
      "****************************\n",
      "Epoch: 186\n",
      "train_loss = 0.3226\n",
      "test_loss = 0.3461\n",
      "****************************\n",
      "Epoch: 187\n",
      "train_loss = 0.3236\n",
      "test_loss = 0.3460\n",
      "****************************\n",
      "Epoch: 188\n",
      "train_loss = 0.3232\n",
      "test_loss = 0.3462\n",
      "****************************\n",
      "Epoch: 189\n",
      "train_loss = 0.3229\n",
      "test_loss = 0.3468\n",
      "****************************\n",
      "Epoch: 190\n",
      "train_loss = 0.3227\n",
      "test_loss = 0.3461\n",
      "****************************\n",
      "Epoch: 191\n",
      "train_loss = 0.3224\n",
      "test_loss = 0.3459\n",
      "****************************\n",
      "Epoch: 192\n",
      "train_loss = 0.3230\n",
      "test_loss = 0.3476\n",
      "****************************\n",
      "Epoch: 193\n",
      "train_loss = 0.3222\n",
      "test_loss = 0.3470\n",
      "****************************\n",
      "Epoch: 194\n",
      "train_loss = 0.3223\n",
      "test_loss = 0.3461\n",
      "****************************\n",
      "Epoch: 195\n",
      "train_loss = 0.3222\n",
      "test_loss = 0.3460\n",
      "****************************\n",
      "Epoch: 196\n",
      "train_loss = 0.3229\n",
      "test_loss = 0.3474\n",
      "****************************\n",
      "Epoch: 197\n",
      "train_loss = 0.3229\n",
      "test_loss = 0.3479\n",
      "****************************\n",
      "Epoch: 198\n",
      "train_loss = 0.3229\n",
      "test_loss = 0.3481\n",
      "****************************\n",
      "Epoch: 199\n",
      "train_loss = 0.3252\n",
      "test_loss = 0.3499\n",
      "****************************\n",
      "Epoch: 200\n",
      "train_loss = 0.3235\n",
      "test_loss = 0.3490\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid\n",
    "net = Net()\n",
    "net.add('Linear', train_x.shape[1], 2, momentum=0.2)\n",
    "net.add('Sigmoid')\n",
    "net.add('Linear', 2, 2)\n",
    "net.add('Sigmoid')\n",
    "loss = net.BinaryCrossEntropyLoss()\n",
    "\n",
    "net.fit(\n",
    "    task_type='classification',\n",
    "    train_dataset=[train_x, train_labels],\n",
    "    val_dataset=[test_x, test_labels],\n",
    "    loss_f=loss,\n",
    "    epochs=200,\n",
    "    batch_size=4,\n",
    "    lr=0.1,\n",
    "    optimizer='minibatch_sgd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.845"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, net.predict(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Загрузка датасета Ирис\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Разделение данных на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Кодирование меток классов\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "train_loss = 4.3535\n",
      "test_loss = 4.5011\n",
      "****************************\n",
      "Epoch: 2\n",
      "train_loss = 3.6368\n",
      "test_loss = 3.6920\n",
      "****************************\n",
      "Epoch: 3\n",
      "train_loss = 2.9451\n",
      "test_loss = 2.9356\n",
      "****************************\n",
      "Epoch: 4\n",
      "train_loss = 2.3730\n",
      "test_loss = 2.3466\n",
      "****************************\n",
      "Epoch: 5\n",
      "train_loss = 2.0133\n",
      "test_loss = 1.9673\n",
      "****************************\n",
      "Epoch: 6\n",
      "train_loss = 1.7751\n",
      "test_loss = 1.7251\n",
      "****************************\n",
      "Epoch: 7\n",
      "train_loss = 1.5823\n",
      "test_loss = 1.5233\n",
      "****************************\n",
      "Epoch: 8\n",
      "train_loss = 1.4514\n",
      "test_loss = 1.3851\n",
      "****************************\n",
      "Epoch: 9\n",
      "train_loss = 1.3581\n",
      "test_loss = 1.2826\n",
      "****************************\n",
      "Epoch: 10\n",
      "train_loss = 1.2882\n",
      "test_loss = 1.2079\n",
      "****************************\n",
      "Epoch: 11\n",
      "train_loss = 1.2129\n",
      "test_loss = 1.1339\n",
      "****************************\n",
      "Epoch: 12\n",
      "train_loss = 1.1434\n",
      "test_loss = 1.0647\n",
      "****************************\n",
      "Epoch: 13\n",
      "train_loss = 1.0848\n",
      "test_loss = 0.9969\n",
      "****************************\n",
      "Epoch: 14\n",
      "train_loss = 1.0454\n",
      "test_loss = 0.9502\n",
      "****************************\n",
      "Epoch: 15\n",
      "train_loss = 0.9978\n",
      "test_loss = 0.8982\n",
      "****************************\n",
      "Epoch: 16\n",
      "train_loss = 0.9554\n",
      "test_loss = 0.8494\n",
      "****************************\n",
      "Epoch: 17\n",
      "train_loss = 0.9128\n",
      "test_loss = 0.7998\n",
      "****************************\n",
      "Epoch: 18\n",
      "train_loss = 0.8822\n",
      "test_loss = 0.7645\n",
      "****************************\n",
      "Epoch: 19\n",
      "train_loss = 0.8474\n",
      "test_loss = 0.7329\n",
      "****************************\n",
      "Epoch: 20\n",
      "train_loss = 0.8158\n",
      "test_loss = 0.6935\n",
      "****************************\n",
      "Epoch: 21\n",
      "train_loss = 0.7875\n",
      "test_loss = 0.6614\n",
      "****************************\n",
      "Epoch: 22\n",
      "train_loss = 0.7559\n",
      "test_loss = 0.6215\n",
      "****************************\n",
      "Epoch: 23\n",
      "train_loss = 0.7304\n",
      "test_loss = 0.5921\n",
      "****************************\n",
      "Epoch: 24\n",
      "train_loss = 0.7189\n",
      "test_loss = 0.5741\n",
      "****************************\n",
      "Epoch: 25\n",
      "train_loss = 0.6990\n",
      "test_loss = 0.5528\n",
      "****************************\n",
      "Epoch: 26\n",
      "train_loss = 0.6746\n",
      "test_loss = 0.5232\n",
      "****************************\n",
      "Epoch: 27\n",
      "train_loss = 0.6610\n",
      "test_loss = 0.4994\n",
      "****************************\n",
      "Epoch: 28\n",
      "train_loss = 0.6464\n",
      "test_loss = 0.4841\n",
      "****************************\n",
      "Epoch: 29\n",
      "train_loss = 0.6266\n",
      "test_loss = 0.4607\n",
      "****************************\n",
      "Epoch: 30\n",
      "train_loss = 0.6123\n",
      "test_loss = 0.4500\n",
      "****************************\n",
      "Epoch: 31\n",
      "train_loss = 0.5983\n",
      "test_loss = 0.4350\n",
      "****************************\n",
      "Epoch: 32\n",
      "train_loss = 0.5841\n",
      "test_loss = 0.4239\n",
      "****************************\n",
      "Epoch: 33\n",
      "train_loss = 0.5671\n",
      "test_loss = 0.4080\n",
      "****************************\n",
      "Epoch: 34\n",
      "train_loss = 0.5569\n",
      "test_loss = 0.3990\n",
      "****************************\n",
      "Epoch: 35\n",
      "train_loss = 0.5471\n",
      "test_loss = 0.3914\n",
      "****************************\n",
      "Epoch: 36\n",
      "train_loss = 0.5319\n",
      "test_loss = 0.3795\n",
      "****************************\n",
      "Epoch: 37\n",
      "train_loss = 0.5265\n",
      "test_loss = 0.3766\n",
      "****************************\n",
      "Epoch: 38\n",
      "train_loss = 0.5140\n",
      "test_loss = 0.3692\n",
      "****************************\n",
      "Epoch: 39\n",
      "train_loss = 0.5003\n",
      "test_loss = 0.3614\n",
      "****************************\n",
      "Epoch: 40\n",
      "train_loss = 0.4881\n",
      "test_loss = 0.3534\n",
      "****************************\n",
      "Epoch: 41\n",
      "train_loss = 0.4770\n",
      "test_loss = 0.3443\n",
      "****************************\n",
      "Epoch: 42\n",
      "train_loss = 0.4711\n",
      "test_loss = 0.3423\n",
      "****************************\n",
      "Epoch: 43\n",
      "train_loss = 0.4585\n",
      "test_loss = 0.3332\n",
      "****************************\n",
      "Epoch: 44\n",
      "train_loss = 0.4494\n",
      "test_loss = 0.3272\n",
      "****************************\n",
      "Epoch: 45\n",
      "train_loss = 0.4460\n",
      "test_loss = 0.3251\n",
      "****************************\n",
      "Epoch: 46\n",
      "train_loss = 0.4351\n",
      "test_loss = 0.3154\n",
      "****************************\n",
      "Epoch: 47\n",
      "train_loss = 0.4276\n",
      "test_loss = 0.3097\n",
      "****************************\n",
      "Epoch: 48\n",
      "train_loss = 0.4211\n",
      "test_loss = 0.3023\n",
      "****************************\n",
      "Epoch: 49\n",
      "train_loss = 0.4110\n",
      "test_loss = 0.2939\n",
      "****************************\n",
      "Epoch: 50\n",
      "train_loss = 0.4016\n",
      "test_loss = 0.2858\n",
      "****************************\n",
      "Epoch: 51\n",
      "train_loss = 0.3962\n",
      "test_loss = 0.2785\n",
      "****************************\n",
      "Epoch: 52\n",
      "train_loss = 0.3892\n",
      "test_loss = 0.2715\n",
      "****************************\n",
      "Epoch: 53\n",
      "train_loss = 0.3798\n",
      "test_loss = 0.2632\n",
      "****************************\n",
      "Epoch: 54\n",
      "train_loss = 0.3737\n",
      "test_loss = 0.2556\n",
      "****************************\n",
      "Epoch: 55\n",
      "train_loss = 0.3684\n",
      "test_loss = 0.2525\n",
      "****************************\n",
      "Epoch: 56\n",
      "train_loss = 0.3637\n",
      "test_loss = 0.2462\n",
      "****************************\n",
      "Epoch: 57\n",
      "train_loss = 0.3585\n",
      "test_loss = 0.2409\n",
      "****************************\n",
      "Epoch: 58\n",
      "train_loss = 0.3535\n",
      "test_loss = 0.2372\n",
      "****************************\n",
      "Epoch: 59\n",
      "train_loss = 0.3488\n",
      "test_loss = 0.2330\n",
      "****************************\n",
      "Epoch: 60\n",
      "train_loss = 0.3409\n",
      "test_loss = 0.2277\n",
      "****************************\n",
      "Epoch: 61\n",
      "train_loss = 0.3356\n",
      "test_loss = 0.2225\n",
      "****************************\n",
      "Epoch: 62\n",
      "train_loss = 0.3308\n",
      "test_loss = 0.2201\n",
      "****************************\n",
      "Epoch: 63\n",
      "train_loss = 0.3266\n",
      "test_loss = 0.2180\n",
      "****************************\n",
      "Epoch: 64\n",
      "train_loss = 0.3214\n",
      "test_loss = 0.2144\n",
      "****************************\n",
      "Epoch: 65\n",
      "train_loss = 0.3165\n",
      "test_loss = 0.2122\n",
      "****************************\n",
      "Epoch: 66\n",
      "train_loss = 0.3124\n",
      "test_loss = 0.2069\n",
      "****************************\n",
      "Epoch: 67\n",
      "train_loss = 0.3091\n",
      "test_loss = 0.2040\n",
      "****************************\n",
      "Epoch: 68\n",
      "train_loss = 0.3063\n",
      "test_loss = 0.2016\n",
      "****************************\n",
      "Epoch: 69\n",
      "train_loss = 0.3037\n",
      "test_loss = 0.2006\n",
      "****************************\n",
      "Epoch: 70\n",
      "train_loss = 0.2997\n",
      "test_loss = 0.2001\n",
      "****************************\n",
      "Epoch: 71\n",
      "train_loss = 0.2962\n",
      "test_loss = 0.1986\n",
      "****************************\n",
      "Epoch: 72\n",
      "train_loss = 0.2927\n",
      "test_loss = 0.1945\n",
      "****************************\n",
      "Epoch: 73\n",
      "train_loss = 0.2896\n",
      "test_loss = 0.1931\n",
      "****************************\n",
      "Epoch: 74\n",
      "train_loss = 0.2861\n",
      "test_loss = 0.1913\n",
      "****************************\n",
      "Epoch: 75\n",
      "train_loss = 0.2830\n",
      "test_loss = 0.1874\n",
      "****************************\n",
      "Epoch: 76\n",
      "train_loss = 0.2808\n",
      "test_loss = 0.1869\n",
      "****************************\n",
      "Epoch: 77\n",
      "train_loss = 0.2794\n",
      "test_loss = 0.1857\n",
      "****************************\n",
      "Epoch: 78\n",
      "train_loss = 0.2767\n",
      "test_loss = 0.1829\n",
      "****************************\n",
      "Epoch: 79\n",
      "train_loss = 0.2743\n",
      "test_loss = 0.1827\n",
      "****************************\n",
      "Epoch: 80\n",
      "train_loss = 0.2728\n",
      "test_loss = 0.1811\n",
      "****************************\n",
      "Epoch: 81\n",
      "train_loss = 0.2700\n",
      "test_loss = 0.1804\n",
      "****************************\n",
      "Epoch: 82\n",
      "train_loss = 0.2669\n",
      "test_loss = 0.1778\n",
      "****************************\n",
      "Epoch: 83\n",
      "train_loss = 0.2647\n",
      "test_loss = 0.1757\n",
      "****************************\n",
      "Epoch: 84\n",
      "train_loss = 0.2615\n",
      "test_loss = 0.1705\n",
      "****************************\n",
      "Epoch: 85\n",
      "train_loss = 0.2589\n",
      "test_loss = 0.1697\n",
      "****************************\n",
      "Epoch: 86\n",
      "train_loss = 0.2572\n",
      "test_loss = 0.1667\n",
      "****************************\n",
      "Epoch: 87\n",
      "train_loss = 0.2548\n",
      "test_loss = 0.1668\n",
      "****************************\n",
      "Epoch: 88\n",
      "train_loss = 0.2529\n",
      "test_loss = 0.1651\n",
      "****************************\n",
      "Epoch: 89\n",
      "train_loss = 0.2507\n",
      "test_loss = 0.1614\n",
      "****************************\n",
      "Epoch: 90\n",
      "train_loss = 0.2488\n",
      "test_loss = 0.1587\n",
      "****************************\n",
      "Epoch: 91\n",
      "train_loss = 0.2466\n",
      "test_loss = 0.1576\n",
      "****************************\n",
      "Epoch: 92\n",
      "train_loss = 0.2443\n",
      "test_loss = 0.1560\n",
      "****************************\n",
      "Epoch: 93\n",
      "train_loss = 0.2430\n",
      "test_loss = 0.1553\n",
      "****************************\n",
      "Epoch: 94\n",
      "train_loss = 0.2409\n",
      "test_loss = 0.1551\n",
      "****************************\n",
      "Epoch: 95\n",
      "train_loss = 0.2394\n",
      "test_loss = 0.1541\n",
      "****************************\n",
      "Epoch: 96\n",
      "train_loss = 0.2379\n",
      "test_loss = 0.1526\n",
      "****************************\n",
      "Epoch: 97\n",
      "train_loss = 0.2368\n",
      "test_loss = 0.1502\n",
      "****************************\n",
      "Epoch: 98\n",
      "train_loss = 0.2353\n",
      "test_loss = 0.1499\n",
      "****************************\n",
      "Epoch: 99\n",
      "train_loss = 0.2337\n",
      "test_loss = 0.1487\n",
      "****************************\n",
      "Epoch: 100\n",
      "train_loss = 0.2324\n",
      "test_loss = 0.1469\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.add('Linear', X_train_scaled.shape[1], 4, momentum=0.9)\n",
    "net.add('ReLU')\n",
    "net.add('Linear', 4, 10, momentum=0.9)\n",
    "net.add('ReLU')\n",
    "net.add('Linear', 10, len(np.unique(y_train_encoded)), momentum=0.9)\n",
    "net.add('Softmax')\n",
    "loss = net.CrossEntropyLoss()\n",
    "\n",
    "net.fit(\n",
    "    task_type='classification',\n",
    "    train_dataset=[X_train_scaled, y_train_encoded],\n",
    "    val_dataset=[X_test_scaled, y_test_encoded],\n",
    "    loss_f=loss,\n",
    "    epochs=100,\n",
    "    batch_size=12,\n",
    "    lr=2e-3,\n",
    "    optimizer='momentum_sgd'\n",
    "    # optimizer='sgd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1469\n"
     ]
    }
   ],
   "source": [
    "# Оценка производительности нейросети на тестовых данных\n",
    "test_loss = net.get_loss(X_test_scaled, y_test_encoded, loss)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(X_test_scaled, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict([5.1, 3.5, 1.4, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.print_loss_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Загрузка данных\u001b[39;00m\n\u001b[0;32m      4\u001b[0m (train_x, train_y), (test_x, test_y) \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _tf_keras\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\_tf_keras\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\activations\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03msince your modifications would be overwritten.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\activations\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m elu\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exponential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\activations\\activations.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m result_type\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasTensor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m any_symbolic_tensors\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_keras_tensor\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_name\n\u001b[0;32m      6\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.KerasTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mKerasTensor\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tree.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Register backend-specific node classes\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrackable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_structures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListWrapper\n\u001b[0;32m     14\u001b[0m     optree\u001b[38;5;241m.\u001b[39mregister_pytree_node(\n\u001b[0;32m     15\u001b[0m         ListWrapper,\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: (x, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m metadata, children: ListWrapper(\u001b[38;5;28mlist\u001b[39m(children)),\n\u001b[0;32m     18\u001b[0m         namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.tree.is_nested\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_nested\u001b[39m(structure):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msite\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_site\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Загрузка данных\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "\n",
    "# Предварительная обработка данных (например, нормализация)\n",
    "train_x = train_x.reshape(train_x.shape[0], -1) / 255.0\n",
    "test_x = test_x.reshape(test_x.shape[0], -1) / 255.0\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 5 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Вывод первого изображения\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mtrain_x\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_y[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 5 into shape (28,28)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Вывод первого изображения\n",
    "plt.imshow(train_x[150].reshape(28, 28), cmap='gray')\n",
    "plt.title(f'Label: {train_y[0]}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "train_loss = 3.7955\n",
      "test_loss = 3.8999\n",
      "****************************\n",
      "Epoch: 2\n",
      "train_loss = 2.4668\n",
      "test_loss = 2.6235\n",
      "****************************\n",
      "Epoch: 3\n",
      "train_loss = 1.8432\n",
      "test_loss = 2.0642\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Создание и обучение нейронной сети\n",
    "net = Net()\n",
    "net.add('Linear', train_x.shape[1], 128, momentum=0.9)\n",
    "net.add('ReLU')\n",
    "net.add('Linear', 128, 10)\n",
    "net.add('Softmax')\n",
    "loss = net.CrossEntropyLoss()\n",
    "\n",
    "net.fit(\n",
    "    task_type='classification',\n",
    "    train_dataset=[train_x, train_y],\n",
    "    val_dataset=[val_x, val_y],\n",
    "    loss_f=loss,\n",
    "    epochs=3,\n",
    "    batch_size=32,\n",
    "    lr=0.01,\n",
    "    optimizer='momentum_sgd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m net\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mval_x\u001b[49m, val_y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_x' is not defined"
     ]
    }
   ],
   "source": [
    "net.evaluate(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Истинное число: 5\n",
      "Предсказанное моделью: 5\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(val_x[130].reshape(28, 28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f'Истинное число: {val_y[130]}')\n",
    "print(f\"Предсказанное моделью: {net.predict(val_x[130])[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mlen\u001b[39m(val_x))\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_y[n]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; Pred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnet\u001b[38;5;241m.\u001b[39mpredict(val_x[n])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    n = np.random.randint(len(val_x))\n",
    "    print(f\"True: {val_y[n]}; Pred: {net.predict(val_x[n])[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "# Разделение на признаки и метки\n",
    "X = data.drop('medv', axis=1)\n",
    "y = data['medv']\n",
    "\n",
    "# Масштабирование признаков\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "train_loss = 243.1649\n",
      "test_loss = 234.7462\n",
      "****************************\n",
      "Epoch: 2\n",
      "train_loss = 164.1303\n",
      "test_loss = 151.1816\n",
      "****************************\n",
      "Epoch: 3\n",
      "train_loss = 139.9840\n",
      "test_loss = 130.5259\n",
      "****************************\n",
      "Epoch: 4\n",
      "train_loss = 130.1047\n",
      "test_loss = 124.0293\n",
      "****************************\n",
      "Epoch: 5\n",
      "train_loss = 123.1679\n",
      "test_loss = 118.4679\n",
      "****************************\n",
      "Epoch: 6\n",
      "train_loss = 117.9689\n",
      "test_loss = 113.7348\n",
      "****************************\n",
      "Epoch: 7\n",
      "train_loss = 113.8305\n",
      "test_loss = 109.6212\n",
      "****************************\n",
      "Epoch: 8\n",
      "train_loss = 111.6598\n",
      "test_loss = 106.8034\n",
      "****************************\n",
      "Epoch: 9\n",
      "train_loss = 110.4366\n",
      "test_loss = 108.3845\n",
      "****************************\n",
      "Epoch: 10\n",
      "train_loss = 107.6747\n",
      "test_loss = 103.5663\n",
      "****************************\n",
      "Epoch: 11\n",
      "train_loss = 107.5188\n",
      "test_loss = 104.3760\n",
      "****************************\n",
      "Epoch: 12\n",
      "train_loss = 105.7457\n",
      "test_loss = 100.9406\n",
      "****************************\n",
      "Epoch: 13\n",
      "train_loss = 104.3292\n",
      "test_loss = 96.6468\n",
      "****************************\n",
      "Epoch: 14\n",
      "train_loss = 103.3051\n",
      "test_loss = 96.1105\n",
      "****************************\n",
      "Epoch: 15\n",
      "train_loss = 103.8409\n",
      "test_loss = 97.4229\n",
      "****************************\n",
      "Epoch: 16\n",
      "train_loss = 104.4837\n",
      "test_loss = 95.1092\n",
      "****************************\n",
      "Epoch: 17\n",
      "train_loss = 105.3540\n",
      "test_loss = 100.9047\n",
      "****************************\n",
      "Epoch: 18\n",
      "train_loss = 101.0560\n",
      "test_loss = 92.0171\n",
      "****************************\n",
      "Epoch: 19\n",
      "train_loss = 100.0511\n",
      "test_loss = 91.8978\n",
      "****************************\n",
      "Epoch: 20\n",
      "train_loss = 100.5645\n",
      "test_loss = 90.3758\n",
      "****************************\n",
      "Epoch: 21\n",
      "train_loss = 99.1895\n",
      "test_loss = 90.4070\n",
      "****************************\n",
      "Epoch: 22\n",
      "train_loss = 99.1708\n",
      "test_loss = 91.3308\n",
      "****************************\n",
      "Epoch: 23\n",
      "train_loss = 100.5297\n",
      "test_loss = 94.7591\n",
      "****************************\n",
      "Epoch: 24\n",
      "train_loss = 98.0253\n",
      "test_loss = 90.1218\n",
      "****************************\n",
      "Epoch: 25\n",
      "train_loss = 98.3528\n",
      "test_loss = 91.7389\n",
      "****************************\n",
      "Epoch: 26\n",
      "train_loss = 97.9041\n",
      "test_loss = 87.4256\n",
      "****************************\n",
      "Epoch: 27\n",
      "train_loss = 97.3192\n",
      "test_loss = 87.6727\n",
      "****************************\n",
      "Epoch: 28\n",
      "train_loss = 99.5855\n",
      "test_loss = 86.0798\n",
      "****************************\n",
      "Epoch: 29\n",
      "train_loss = 97.6330\n",
      "test_loss = 89.9765\n",
      "****************************\n",
      "Epoch: 30\n",
      "train_loss = 96.4422\n",
      "test_loss = 86.9114\n",
      "****************************\n",
      "Epoch: 31\n",
      "train_loss = 97.7869\n",
      "test_loss = 90.9218\n",
      "****************************\n",
      "Epoch: 32\n",
      "train_loss = 104.0767\n",
      "test_loss = 99.7126\n",
      "****************************\n",
      "Epoch: 33\n",
      "train_loss = 96.2341\n",
      "test_loss = 84.8550\n",
      "****************************\n",
      "Epoch: 34\n",
      "train_loss = 97.1617\n",
      "test_loss = 88.8006\n",
      "****************************\n",
      "Epoch: 35\n",
      "train_loss = 95.8179\n",
      "test_loss = 85.4444\n",
      "****************************\n",
      "Epoch: 36\n",
      "train_loss = 95.6419\n",
      "test_loss = 85.4814\n",
      "****************************\n",
      "Epoch: 37\n",
      "train_loss = 98.3851\n",
      "test_loss = 91.4004\n",
      "****************************\n",
      "Epoch: 38\n",
      "train_loss = 97.5440\n",
      "test_loss = 89.8140\n",
      "****************************\n",
      "Epoch: 39\n",
      "train_loss = 95.5217\n",
      "test_loss = 86.6048\n",
      "****************************\n",
      "Epoch: 40\n",
      "train_loss = 95.7288\n",
      "test_loss = 86.6743\n",
      "****************************\n",
      "Epoch: 41\n",
      "train_loss = 95.9436\n",
      "test_loss = 82.7211\n",
      "****************************\n",
      "Epoch: 42\n",
      "train_loss = 99.4044\n",
      "test_loss = 91.8207\n",
      "****************************\n",
      "Epoch: 43\n",
      "train_loss = 95.4066\n",
      "test_loss = 83.4757\n",
      "****************************\n",
      "Epoch: 44\n",
      "train_loss = 95.6360\n",
      "test_loss = 83.2273\n",
      "****************************\n",
      "Epoch: 45\n",
      "train_loss = 95.0713\n",
      "test_loss = 84.7112\n",
      "****************************\n",
      "Epoch: 46\n",
      "train_loss = 94.8101\n",
      "test_loss = 83.1745\n",
      "****************************\n",
      "Epoch: 47\n",
      "train_loss = 94.5114\n",
      "test_loss = 83.6424\n",
      "****************************\n",
      "Epoch: 48\n",
      "train_loss = 94.4075\n",
      "test_loss = 83.4370\n",
      "****************************\n",
      "Epoch: 49\n",
      "train_loss = 94.3826\n",
      "test_loss = 82.5964\n",
      "****************************\n",
      "Epoch: 50\n",
      "train_loss = 95.7526\n",
      "test_loss = 89.1022\n",
      "****************************\n",
      "Epoch: 51\n",
      "train_loss = 94.3254\n",
      "test_loss = 82.3699\n",
      "****************************\n",
      "Epoch: 52\n",
      "train_loss = 93.8594\n",
      "test_loss = 82.7042\n",
      "****************************\n",
      "Epoch: 53\n",
      "train_loss = 96.2765\n",
      "test_loss = 89.4321\n",
      "****************************\n",
      "Epoch: 54\n",
      "train_loss = 93.4347\n",
      "test_loss = 83.2581\n",
      "****************************\n",
      "Epoch: 55\n",
      "train_loss = 95.7693\n",
      "test_loss = 88.6849\n",
      "****************************\n",
      "Epoch: 56\n",
      "train_loss = 93.2479\n",
      "test_loss = 83.1527\n",
      "****************************\n",
      "Epoch: 57\n",
      "train_loss = 93.3896\n",
      "test_loss = 83.4728\n",
      "****************************\n",
      "Epoch: 58\n",
      "train_loss = 94.8008\n",
      "test_loss = 87.3245\n",
      "****************************\n",
      "Epoch: 59\n",
      "train_loss = 100.5208\n",
      "test_loss = 95.3825\n",
      "****************************\n",
      "Epoch: 60\n",
      "train_loss = 94.1060\n",
      "test_loss = 86.5252\n",
      "****************************\n",
      "Epoch: 61\n",
      "train_loss = 92.9606\n",
      "test_loss = 82.7688\n",
      "****************************\n",
      "Epoch: 62\n",
      "train_loss = 93.1393\n",
      "test_loss = 84.5209\n",
      "****************************\n",
      "Epoch: 63\n",
      "train_loss = 93.6210\n",
      "test_loss = 80.4717\n",
      "****************************\n",
      "Epoch: 64\n",
      "train_loss = 92.8672\n",
      "test_loss = 81.1806\n",
      "****************************\n",
      "Epoch: 65\n",
      "train_loss = 92.6576\n",
      "test_loss = 82.0096\n",
      "****************************\n",
      "Epoch: 66\n",
      "train_loss = 94.1128\n",
      "test_loss = 85.9077\n",
      "****************************\n",
      "Epoch: 67\n",
      "train_loss = 92.5295\n",
      "test_loss = 81.8304\n",
      "****************************\n",
      "Epoch: 68\n",
      "train_loss = 95.7372\n",
      "test_loss = 82.6379\n",
      "****************************\n",
      "Epoch: 69\n",
      "train_loss = 92.4783\n",
      "test_loss = 82.3665\n",
      "****************************\n",
      "Epoch: 70\n",
      "train_loss = 95.3444\n",
      "test_loss = 88.2346\n",
      "****************************\n",
      "Epoch: 71\n",
      "train_loss = 92.5821\n",
      "test_loss = 83.6646\n",
      "****************************\n",
      "Epoch: 72\n",
      "train_loss = 92.1919\n",
      "test_loss = 81.8712\n",
      "****************************\n",
      "Epoch: 73\n",
      "train_loss = 92.6705\n",
      "test_loss = 80.5344\n",
      "****************************\n",
      "Epoch: 74\n",
      "train_loss = 92.8699\n",
      "test_loss = 80.3144\n",
      "****************************\n",
      "Epoch: 75\n",
      "train_loss = 93.4992\n",
      "test_loss = 84.4051\n",
      "****************************\n",
      "Epoch: 76\n",
      "train_loss = 92.1088\n",
      "test_loss = 80.7176\n",
      "****************************\n",
      "Epoch: 77\n",
      "train_loss = 92.4740\n",
      "test_loss = 79.9139\n",
      "****************************\n",
      "Epoch: 78\n",
      "train_loss = 92.2037\n",
      "test_loss = 81.6495\n",
      "****************************\n",
      "Epoch: 79\n",
      "train_loss = 92.9288\n",
      "test_loss = 83.8538\n",
      "****************************\n",
      "Epoch: 80\n",
      "train_loss = 92.4640\n",
      "test_loss = 82.2882\n",
      "****************************\n",
      "Epoch: 81\n",
      "train_loss = 91.8909\n",
      "test_loss = 80.6672\n",
      "****************************\n",
      "Epoch: 82\n",
      "train_loss = 92.0728\n",
      "test_loss = 79.9543\n",
      "****************************\n",
      "Epoch: 83\n",
      "train_loss = 91.9691\n",
      "test_loss = 80.0867\n",
      "****************************\n",
      "Epoch: 84\n",
      "train_loss = 92.0306\n",
      "test_loss = 79.3755\n",
      "****************************\n",
      "Epoch: 85\n",
      "train_loss = 91.6425\n",
      "test_loss = 80.3871\n",
      "****************************\n",
      "Epoch: 86\n",
      "train_loss = 92.6288\n",
      "test_loss = 83.2268\n",
      "****************************\n",
      "Epoch: 87\n",
      "train_loss = 91.9140\n",
      "test_loss = 81.8346\n",
      "****************************\n",
      "Epoch: 88\n",
      "train_loss = 91.9825\n",
      "test_loss = 79.5602\n",
      "****************************\n",
      "Epoch: 89\n",
      "train_loss = 91.9348\n",
      "test_loss = 82.1533\n",
      "****************************\n",
      "Epoch: 90\n",
      "train_loss = 91.5503\n",
      "test_loss = 81.2690\n",
      "****************************\n",
      "Epoch: 91\n",
      "train_loss = 92.5834\n",
      "test_loss = 79.2361\n",
      "****************************\n",
      "Epoch: 92\n",
      "train_loss = 92.8265\n",
      "test_loss = 78.8677\n",
      "****************************\n",
      "Epoch: 93\n",
      "train_loss = 91.4526\n",
      "test_loss = 80.4278\n",
      "****************************\n",
      "Epoch: 94\n",
      "train_loss = 91.7900\n",
      "test_loss = 79.0813\n",
      "****************************\n",
      "Epoch: 95\n",
      "train_loss = 92.9887\n",
      "test_loss = 78.5897\n",
      "****************************\n",
      "Epoch: 96\n",
      "train_loss = 91.6507\n",
      "test_loss = 81.3996\n",
      "****************************\n",
      "Epoch: 97\n",
      "train_loss = 91.3517\n",
      "test_loss = 81.2053\n",
      "****************************\n",
      "Epoch: 98\n",
      "train_loss = 92.1938\n",
      "test_loss = 83.4653\n",
      "****************************\n",
      "Epoch: 99\n",
      "train_loss = 91.1396\n",
      "test_loss = 79.7867\n",
      "****************************\n",
      "Epoch: 100\n",
      "train_loss = 91.1796\n",
      "test_loss = 80.5649\n",
      "****************************\n",
      "Epoch: 101\n",
      "train_loss = 91.0559\n",
      "test_loss = 79.7988\n",
      "****************************\n",
      "Epoch: 102\n",
      "train_loss = 91.7423\n",
      "test_loss = 78.8870\n",
      "****************************\n",
      "Epoch: 103\n",
      "train_loss = 91.0961\n",
      "test_loss = 79.2319\n",
      "****************************\n",
      "Epoch: 104\n",
      "train_loss = 92.0394\n",
      "test_loss = 82.6402\n",
      "****************************\n",
      "Epoch: 105\n",
      "train_loss = 105.0205\n",
      "test_loss = 85.4328\n",
      "****************************\n",
      "Epoch: 106\n",
      "train_loss = 91.2490\n",
      "test_loss = 79.3328\n",
      "****************************\n",
      "Epoch: 107\n",
      "train_loss = 91.4465\n",
      "test_loss = 81.0244\n",
      "****************************\n",
      "Epoch: 108\n",
      "train_loss = 91.1113\n",
      "test_loss = 79.5992\n",
      "****************************\n",
      "Epoch: 109\n",
      "train_loss = 92.5040\n",
      "test_loss = 78.4175\n",
      "****************************\n",
      "Epoch: 110\n",
      "train_loss = 90.9213\n",
      "test_loss = 79.3633\n",
      "****************************\n",
      "Epoch: 111\n",
      "train_loss = 92.5941\n",
      "test_loss = 78.3978\n",
      "****************************\n",
      "Epoch: 112\n",
      "train_loss = 90.8298\n",
      "test_loss = 79.4876\n",
      "****************************\n",
      "Epoch: 113\n",
      "train_loss = 90.7584\n",
      "test_loss = 79.7115\n",
      "****************************\n",
      "Epoch: 114\n",
      "train_loss = 92.4463\n",
      "test_loss = 84.1102\n",
      "****************************\n",
      "Epoch: 115\n",
      "train_loss = 90.7605\n",
      "test_loss = 79.2868\n",
      "****************************\n",
      "Epoch: 116\n",
      "train_loss = 91.1704\n",
      "test_loss = 78.5355\n",
      "****************************\n",
      "Epoch: 117\n",
      "train_loss = 90.7726\n",
      "test_loss = 80.1669\n",
      "****************************\n",
      "Epoch: 118\n",
      "train_loss = 90.7628\n",
      "test_loss = 79.5715\n",
      "****************************\n",
      "Epoch: 119\n",
      "train_loss = 90.7550\n",
      "test_loss = 80.6220\n",
      "****************************\n",
      "Epoch: 120\n",
      "train_loss = 90.9236\n",
      "test_loss = 78.5374\n",
      "****************************\n",
      "Epoch: 121\n",
      "train_loss = 90.8871\n",
      "test_loss = 80.0567\n",
      "****************************\n",
      "Epoch: 122\n",
      "train_loss = 92.1647\n",
      "test_loss = 77.9422\n",
      "****************************\n",
      "Epoch: 123\n",
      "train_loss = 90.7135\n",
      "test_loss = 78.6357\n",
      "****************************\n",
      "Epoch: 124\n",
      "train_loss = 90.6519\n",
      "test_loss = 79.9562\n",
      "****************************\n",
      "Epoch: 125\n",
      "train_loss = 91.6499\n",
      "test_loss = 77.8620\n",
      "****************************\n",
      "Epoch: 126\n",
      "train_loss = 90.5962\n",
      "test_loss = 80.1058\n",
      "****************************\n",
      "Epoch: 127\n",
      "train_loss = 90.5755\n",
      "test_loss = 80.3363\n",
      "****************************\n",
      "Epoch: 128\n",
      "train_loss = 92.0653\n",
      "test_loss = 83.5696\n",
      "****************************\n",
      "Epoch: 129\n",
      "train_loss = 90.4216\n",
      "test_loss = 78.9535\n",
      "****************************\n",
      "Epoch: 130\n",
      "train_loss = 91.1841\n",
      "test_loss = 77.9687\n",
      "****************************\n",
      "Epoch: 131\n",
      "train_loss = 90.6975\n",
      "test_loss = 79.8787\n",
      "****************************\n",
      "Epoch: 132\n",
      "train_loss = 90.7951\n",
      "test_loss = 79.7008\n",
      "****************************\n",
      "Epoch: 133\n",
      "train_loss = 90.7902\n",
      "test_loss = 80.4305\n",
      "****************************\n",
      "Epoch: 134\n",
      "train_loss = 90.5046\n",
      "test_loss = 78.1932\n",
      "****************************\n",
      "Epoch: 135\n",
      "train_loss = 90.4091\n",
      "test_loss = 79.9209\n",
      "****************************\n",
      "Epoch: 136\n",
      "train_loss = 91.7760\n",
      "test_loss = 77.9472\n",
      "****************************\n",
      "Epoch: 137\n",
      "train_loss = 90.2513\n",
      "test_loss = 78.7549\n",
      "****************************\n",
      "Epoch: 138\n",
      "train_loss = 90.5597\n",
      "test_loss = 80.4118\n",
      "****************************\n",
      "Epoch: 139\n",
      "train_loss = 90.2360\n",
      "test_loss = 79.0701\n",
      "****************************\n",
      "Epoch: 140\n",
      "train_loss = 92.0332\n",
      "test_loss = 77.5097\n",
      "****************************\n",
      "Epoch: 141\n",
      "train_loss = 90.2965\n",
      "test_loss = 79.5753\n",
      "****************************\n",
      "Epoch: 142\n",
      "train_loss = 90.9727\n",
      "test_loss = 81.1602\n",
      "****************************\n",
      "Epoch: 143\n",
      "train_loss = 90.7323\n",
      "test_loss = 77.6190\n",
      "****************************\n",
      "Epoch: 144\n",
      "train_loss = 91.0285\n",
      "test_loss = 81.4232\n",
      "****************************\n",
      "Epoch: 145\n",
      "train_loss = 90.2723\n",
      "test_loss = 78.1286\n",
      "****************************\n",
      "Epoch: 146\n",
      "train_loss = 91.0606\n",
      "test_loss = 77.4659\n",
      "****************************\n",
      "Epoch: 147\n",
      "train_loss = 90.5061\n",
      "test_loss = 77.7663\n",
      "****************************\n",
      "Epoch: 148\n",
      "train_loss = 90.1939\n",
      "test_loss = 77.9843\n",
      "****************************\n",
      "Epoch: 149\n",
      "train_loss = 92.4189\n",
      "test_loss = 83.5293\n",
      "****************************\n",
      "Epoch: 150\n",
      "train_loss = 90.2137\n",
      "test_loss = 78.6485\n",
      "****************************\n",
      "Epoch: 151\n",
      "train_loss = 91.2091\n",
      "test_loss = 81.6254\n",
      "****************************\n",
      "Epoch: 152\n",
      "train_loss = 92.9159\n",
      "test_loss = 84.7197\n",
      "****************************\n",
      "Epoch: 153\n",
      "train_loss = 90.9894\n",
      "test_loss = 77.1650\n",
      "****************************\n",
      "Epoch: 154\n",
      "train_loss = 90.5849\n",
      "test_loss = 80.0682\n",
      "****************************\n",
      "Epoch: 155\n",
      "train_loss = 90.1255\n",
      "test_loss = 78.2396\n",
      "****************************\n",
      "Epoch: 156\n",
      "train_loss = 90.0874\n",
      "test_loss = 77.8638\n",
      "****************************\n",
      "Epoch: 157\n",
      "train_loss = 91.3242\n",
      "test_loss = 77.2778\n",
      "****************************\n",
      "Epoch: 158\n",
      "train_loss = 90.2630\n",
      "test_loss = 80.0985\n",
      "****************************\n",
      "Epoch: 159\n",
      "train_loss = 90.2945\n",
      "test_loss = 79.8753\n",
      "****************************\n",
      "Epoch: 160\n",
      "train_loss = 89.9716\n",
      "test_loss = 78.3380\n",
      "****************************\n",
      "Epoch: 161\n",
      "train_loss = 90.5910\n",
      "test_loss = 77.5229\n",
      "****************************\n",
      "Epoch: 162\n",
      "train_loss = 89.9014\n",
      "test_loss = 78.1735\n",
      "****************************\n",
      "Epoch: 163\n",
      "train_loss = 90.2577\n",
      "test_loss = 77.4025\n",
      "****************************\n",
      "Epoch: 164\n",
      "train_loss = 91.0555\n",
      "test_loss = 76.9414\n",
      "****************************\n",
      "Epoch: 165\n",
      "train_loss = 89.9758\n",
      "test_loss = 77.5823\n",
      "****************************\n",
      "Epoch: 166\n",
      "train_loss = 89.8905\n",
      "test_loss = 78.1342\n",
      "****************************\n",
      "Epoch: 167\n",
      "train_loss = 91.1862\n",
      "test_loss = 76.9693\n",
      "****************************\n",
      "Epoch: 168\n",
      "train_loss = 90.0683\n",
      "test_loss = 79.7833\n",
      "****************************\n",
      "Epoch: 169\n",
      "train_loss = 89.9906\n",
      "test_loss = 79.9181\n",
      "****************************\n",
      "Epoch: 170\n",
      "train_loss = 89.9716\n",
      "test_loss = 79.5908\n",
      "****************************\n",
      "Epoch: 171\n",
      "train_loss = 90.0802\n",
      "test_loss = 80.0857\n",
      "****************************\n",
      "Epoch: 172\n",
      "train_loss = 89.7172\n",
      "test_loss = 78.2959\n",
      "****************************\n",
      "Epoch: 173\n",
      "train_loss = 89.9286\n",
      "test_loss = 79.6668\n",
      "****************************\n",
      "Epoch: 174\n",
      "train_loss = 90.3870\n",
      "test_loss = 77.1824\n",
      "****************************\n",
      "Epoch: 175\n",
      "train_loss = 91.1237\n",
      "test_loss = 76.8186\n",
      "****************************\n",
      "Epoch: 176\n",
      "train_loss = 90.2866\n",
      "test_loss = 78.7598\n",
      "****************************\n",
      "Epoch: 177\n",
      "train_loss = 89.8932\n",
      "test_loss = 78.2403\n",
      "****************************\n",
      "Epoch: 178\n",
      "train_loss = 89.7894\n",
      "test_loss = 78.1659\n",
      "****************************\n",
      "Epoch: 179\n",
      "train_loss = 90.1289\n",
      "test_loss = 79.3212\n",
      "****************************\n",
      "Epoch: 180\n",
      "train_loss = 90.3350\n",
      "test_loss = 77.0346\n",
      "****************************\n",
      "Epoch: 181\n",
      "train_loss = 91.2412\n",
      "test_loss = 81.7875\n",
      "****************************\n",
      "Epoch: 182\n",
      "train_loss = 89.7524\n",
      "test_loss = 78.3345\n",
      "****************************\n",
      "Epoch: 183\n",
      "train_loss = 89.9070\n",
      "test_loss = 77.3626\n",
      "****************************\n",
      "Epoch: 184\n",
      "train_loss = 89.6491\n",
      "test_loss = 77.6729\n",
      "****************************\n",
      "Epoch: 185\n",
      "train_loss = 93.3627\n",
      "test_loss = 85.4102\n",
      "****************************\n",
      "Epoch: 186\n",
      "train_loss = 90.9738\n",
      "test_loss = 81.8309\n",
      "****************************\n",
      "Epoch: 187\n",
      "train_loss = 90.4232\n",
      "test_loss = 81.0395\n",
      "****************************\n",
      "Epoch: 188\n",
      "train_loss = 89.5933\n",
      "test_loss = 78.4740\n",
      "****************************\n",
      "Epoch: 189\n",
      "train_loss = 89.5909\n",
      "test_loss = 78.5405\n",
      "****************************\n",
      "Epoch: 190\n",
      "train_loss = 89.7639\n",
      "test_loss = 77.2722\n",
      "****************************\n",
      "Epoch: 191\n",
      "train_loss = 89.5072\n",
      "test_loss = 78.5307\n",
      "****************************\n",
      "Epoch: 192\n",
      "train_loss = 90.0112\n",
      "test_loss = 77.1857\n",
      "****************************\n",
      "Epoch: 193\n",
      "train_loss = 90.0425\n",
      "test_loss = 76.8791\n",
      "****************************\n",
      "Epoch: 194\n",
      "train_loss = 90.8405\n",
      "test_loss = 80.9239\n",
      "****************************\n",
      "Epoch: 195\n",
      "train_loss = 90.1365\n",
      "test_loss = 76.8384\n",
      "****************************\n",
      "Epoch: 196\n",
      "train_loss = 89.7056\n",
      "test_loss = 79.1263\n",
      "****************************\n",
      "Epoch: 197\n",
      "train_loss = 89.6283\n",
      "test_loss = 78.8371\n",
      "****************************\n",
      "Epoch: 198\n",
      "train_loss = 89.5017\n",
      "test_loss = 77.6374\n",
      "****************************\n",
      "Epoch: 199\n",
      "train_loss = 89.6215\n",
      "test_loss = 77.1965\n",
      "****************************\n",
      "Epoch: 200\n",
      "train_loss = 89.4847\n",
      "test_loss = 78.0036\n",
      "****************************\n",
      "Epoch: 201\n",
      "train_loss = 92.9569\n",
      "test_loss = 84.2239\n",
      "****************************\n",
      "Epoch: 202\n",
      "train_loss = 90.0725\n",
      "test_loss = 76.6357\n",
      "****************************\n",
      "Epoch: 203\n",
      "train_loss = 90.8202\n",
      "test_loss = 82.1553\n",
      "****************************\n",
      "Epoch: 204\n",
      "train_loss = 89.9218\n",
      "test_loss = 79.5599\n",
      "****************************\n",
      "Epoch: 205\n",
      "train_loss = 89.5403\n",
      "test_loss = 78.4160\n",
      "****************************\n",
      "Epoch: 206\n",
      "train_loss = 89.5249\n",
      "test_loss = 78.6625\n",
      "****************************\n",
      "Epoch: 207\n",
      "train_loss = 89.7849\n",
      "test_loss = 76.9692\n",
      "****************************\n",
      "Epoch: 208\n",
      "train_loss = 89.3994\n",
      "test_loss = 77.9312\n",
      "****************************\n",
      "Epoch: 209\n",
      "train_loss = 89.6019\n",
      "test_loss = 79.0890\n",
      "****************************\n",
      "Epoch: 210\n",
      "train_loss = 89.5319\n",
      "test_loss = 77.3169\n",
      "****************************\n",
      "Epoch: 211\n",
      "train_loss = 89.4317\n",
      "test_loss = 78.0506\n",
      "****************************\n",
      "Epoch: 212\n",
      "train_loss = 90.1901\n",
      "test_loss = 80.0786\n",
      "****************************\n",
      "Epoch: 213\n",
      "train_loss = 89.6944\n",
      "test_loss = 78.6329\n",
      "****************************\n",
      "Epoch: 214\n",
      "train_loss = 90.8623\n",
      "test_loss = 76.3718\n",
      "****************************\n",
      "Epoch: 215\n",
      "train_loss = 89.5690\n",
      "test_loss = 78.8755\n",
      "****************************\n",
      "Epoch: 216\n",
      "train_loss = 89.3504\n",
      "test_loss = 77.5825\n",
      "****************************\n",
      "Epoch: 217\n",
      "train_loss = 90.2402\n",
      "test_loss = 80.8559\n",
      "****************************\n",
      "Epoch: 218\n",
      "train_loss = 89.7561\n",
      "test_loss = 76.9592\n",
      "****************************\n",
      "Epoch: 219\n",
      "train_loss = 89.5237\n",
      "test_loss = 77.0876\n",
      "****************************\n",
      "Epoch: 220\n",
      "train_loss = 91.2365\n",
      "test_loss = 82.2895\n",
      "****************************\n",
      "Epoch: 221\n",
      "train_loss = 89.3116\n",
      "test_loss = 78.0713\n",
      "****************************\n",
      "Epoch: 222\n",
      "train_loss = 89.7068\n",
      "test_loss = 76.9640\n",
      "****************************\n",
      "Epoch: 223\n",
      "train_loss = 89.2944\n",
      "test_loss = 77.5564\n",
      "****************************\n",
      "Epoch: 224\n",
      "train_loss = 89.3999\n",
      "test_loss = 77.0937\n",
      "****************************\n",
      "Epoch: 225\n",
      "train_loss = 89.4786\n",
      "test_loss = 77.3092\n",
      "****************************\n",
      "Epoch: 226\n",
      "train_loss = 93.3219\n",
      "test_loss = 84.6419\n",
      "****************************\n",
      "Epoch: 227\n",
      "train_loss = 89.4806\n",
      "test_loss = 77.4173\n",
      "****************************\n",
      "Epoch: 228\n",
      "train_loss = 89.7697\n",
      "test_loss = 76.5721\n",
      "****************************\n",
      "Epoch: 229\n",
      "train_loss = 90.0381\n",
      "test_loss = 80.0544\n",
      "****************************\n",
      "Epoch: 230\n",
      "train_loss = 90.0464\n",
      "test_loss = 76.9792\n",
      "****************************\n",
      "Epoch: 231\n",
      "train_loss = 90.0961\n",
      "test_loss = 76.6763\n",
      "****************************\n",
      "Epoch: 232\n",
      "train_loss = 89.7410\n",
      "test_loss = 76.6936\n",
      "****************************\n",
      "Epoch: 233\n",
      "train_loss = 89.7908\n",
      "test_loss = 76.5989\n",
      "****************************\n",
      "Epoch: 234\n",
      "train_loss = 89.3426\n",
      "test_loss = 78.0207\n",
      "****************************\n",
      "Epoch: 235\n",
      "train_loss = 90.2589\n",
      "test_loss = 76.6450\n",
      "****************************\n",
      "Epoch: 236\n",
      "train_loss = 89.5834\n",
      "test_loss = 77.2045\n",
      "****************************\n",
      "Epoch: 237\n",
      "train_loss = 89.3801\n",
      "test_loss = 78.2205\n",
      "****************************\n",
      "Epoch: 238\n",
      "train_loss = 90.3764\n",
      "test_loss = 76.3505\n",
      "****************************\n",
      "Epoch: 239\n",
      "train_loss = 89.4586\n",
      "test_loss = 78.7851\n",
      "****************************\n",
      "Epoch: 240\n",
      "train_loss = 89.5701\n",
      "test_loss = 76.6847\n",
      "****************************\n",
      "Epoch: 241\n",
      "train_loss = 90.6798\n",
      "test_loss = 76.8387\n",
      "****************************\n",
      "Epoch: 242\n",
      "train_loss = 89.7826\n",
      "test_loss = 79.1635\n",
      "****************************\n",
      "Epoch: 243\n",
      "train_loss = 94.6210\n",
      "test_loss = 87.1030\n",
      "****************************\n",
      "Epoch: 244\n",
      "train_loss = 89.4051\n",
      "test_loss = 78.4903\n",
      "****************************\n",
      "Epoch: 245\n",
      "train_loss = 89.2043\n",
      "test_loss = 77.3690\n",
      "****************************\n",
      "Epoch: 246\n",
      "train_loss = 89.3244\n",
      "test_loss = 78.0631\n",
      "****************************\n",
      "Epoch: 247\n",
      "train_loss = 89.5593\n",
      "test_loss = 76.4974\n",
      "****************************\n",
      "Epoch: 248\n",
      "train_loss = 89.3765\n",
      "test_loss = 78.7615\n",
      "****************************\n",
      "Epoch: 249\n",
      "train_loss = 91.1787\n",
      "test_loss = 76.3243\n",
      "****************************\n",
      "Epoch: 250\n",
      "train_loss = 89.2412\n",
      "test_loss = 77.8617\n",
      "****************************\n",
      "Epoch: 251\n",
      "train_loss = 95.6581\n",
      "test_loss = 88.5598\n",
      "****************************\n",
      "Epoch: 252\n",
      "train_loss = 89.4046\n",
      "test_loss = 76.7421\n",
      "****************************\n",
      "Epoch: 253\n",
      "train_loss = 89.1613\n",
      "test_loss = 78.3611\n",
      "****************************\n",
      "Epoch: 254\n",
      "train_loss = 89.1663\n",
      "test_loss = 77.0788\n",
      "****************************\n",
      "Epoch: 255\n",
      "train_loss = 89.2900\n",
      "test_loss = 77.8792\n",
      "****************************\n",
      "Epoch: 256\n",
      "train_loss = 89.9967\n",
      "test_loss = 76.1814\n",
      "****************************\n",
      "Epoch: 257\n",
      "train_loss = 89.5108\n",
      "test_loss = 79.0860\n",
      "****************************\n",
      "Epoch: 258\n",
      "train_loss = 89.3000\n",
      "test_loss = 78.8657\n",
      "****************************\n",
      "Epoch: 259\n",
      "train_loss = 89.0523\n",
      "test_loss = 77.6579\n",
      "****************************\n",
      "Epoch: 260\n",
      "train_loss = 89.8269\n",
      "test_loss = 79.8070\n",
      "****************************\n",
      "Epoch: 261\n",
      "train_loss = 90.1826\n",
      "test_loss = 76.0568\n",
      "****************************\n",
      "Epoch: 262\n",
      "train_loss = 89.4173\n",
      "test_loss = 78.7864\n",
      "****************************\n",
      "Epoch: 263\n",
      "train_loss = 89.1248\n",
      "test_loss = 76.8464\n",
      "****************************\n",
      "Epoch: 264\n",
      "train_loss = 89.9507\n",
      "test_loss = 80.2070\n",
      "****************************\n",
      "Epoch: 265\n",
      "train_loss = 90.2769\n",
      "test_loss = 80.9881\n",
      "****************************\n",
      "Epoch: 266\n",
      "train_loss = 88.9753\n",
      "test_loss = 77.3758\n",
      "****************************\n",
      "Epoch: 267\n",
      "train_loss = 89.1246\n",
      "test_loss = 76.7454\n",
      "****************************\n",
      "Epoch: 268\n",
      "train_loss = 90.3500\n",
      "test_loss = 81.0402\n",
      "****************************\n",
      "Epoch: 269\n",
      "train_loss = 89.1373\n",
      "test_loss = 78.4000\n",
      "****************************\n",
      "Epoch: 270\n",
      "train_loss = 89.4441\n",
      "test_loss = 76.3446\n",
      "****************************\n",
      "Epoch: 271\n",
      "train_loss = 88.9609\n",
      "test_loss = 77.9339\n",
      "****************************\n",
      "Epoch: 272\n",
      "train_loss = 90.7852\n",
      "test_loss = 76.1397\n",
      "****************************\n",
      "Epoch: 273\n",
      "train_loss = 89.0176\n",
      "test_loss = 77.9993\n",
      "****************************\n",
      "Epoch: 274\n",
      "train_loss = 89.4582\n",
      "test_loss = 79.6114\n",
      "****************************\n",
      "Epoch: 275\n",
      "train_loss = 88.9528\n",
      "test_loss = 77.1197\n",
      "****************************\n",
      "Epoch: 276\n",
      "train_loss = 88.9583\n",
      "test_loss = 77.2495\n",
      "****************************\n",
      "Epoch: 277\n",
      "train_loss = 89.4153\n",
      "test_loss = 76.4113\n",
      "****************************\n",
      "Epoch: 278\n",
      "train_loss = 89.0762\n",
      "test_loss = 78.5421\n",
      "****************************\n",
      "Epoch: 279\n",
      "train_loss = 89.2854\n",
      "test_loss = 76.2956\n",
      "****************************\n",
      "Epoch: 280\n",
      "train_loss = 89.4268\n",
      "test_loss = 79.0422\n",
      "****************************\n",
      "Epoch: 281\n",
      "train_loss = 89.0124\n",
      "test_loss = 77.8201\n",
      "****************************\n",
      "Epoch: 282\n",
      "train_loss = 89.7360\n",
      "test_loss = 79.9918\n",
      "****************************\n",
      "Epoch: 283\n",
      "train_loss = 88.9046\n",
      "test_loss = 77.2708\n",
      "****************************\n",
      "Epoch: 284\n",
      "train_loss = 88.9565\n",
      "test_loss = 76.9439\n",
      "****************************\n",
      "Epoch: 285\n",
      "train_loss = 89.0237\n",
      "test_loss = 76.7149\n",
      "****************************\n",
      "Epoch: 286\n",
      "train_loss = 88.9122\n",
      "test_loss = 77.3042\n",
      "****************************\n",
      "Epoch: 287\n",
      "train_loss = 89.7225\n",
      "test_loss = 75.9038\n",
      "****************************\n",
      "Epoch: 288\n",
      "train_loss = 88.9941\n",
      "test_loss = 78.2223\n",
      "****************************\n",
      "Epoch: 289\n",
      "train_loss = 89.6317\n",
      "test_loss = 75.9531\n",
      "****************************\n",
      "Epoch: 290\n",
      "train_loss = 88.9354\n",
      "test_loss = 76.9714\n",
      "****************************\n",
      "Epoch: 291\n",
      "train_loss = 90.3793\n",
      "test_loss = 75.7620\n",
      "****************************\n",
      "Epoch: 292\n",
      "train_loss = 88.9175\n",
      "test_loss = 77.3519\n",
      "****************************\n",
      "Epoch: 293\n",
      "train_loss = 88.9767\n",
      "test_loss = 76.5935\n",
      "****************************\n",
      "Epoch: 294\n",
      "train_loss = 89.6782\n",
      "test_loss = 76.0785\n",
      "****************************\n",
      "Epoch: 295\n",
      "train_loss = 89.6132\n",
      "test_loss = 79.9377\n",
      "****************************\n",
      "Epoch: 296\n",
      "train_loss = 89.0797\n",
      "test_loss = 76.7022\n",
      "****************************\n",
      "Epoch: 297\n",
      "train_loss = 89.4306\n",
      "test_loss = 79.2384\n",
      "****************************\n",
      "Epoch: 298\n",
      "train_loss = 88.8790\n",
      "test_loss = 76.7034\n",
      "****************************\n",
      "Epoch: 299\n",
      "train_loss = 88.8897\n",
      "test_loss = 76.8213\n",
      "****************************\n",
      "Epoch: 300\n",
      "train_loss = 89.3419\n",
      "test_loss = 79.5123\n",
      "****************************\n",
      "Epoch: 301\n",
      "train_loss = 88.9473\n",
      "test_loss = 77.3290\n",
      "****************************\n",
      "Epoch: 302\n",
      "train_loss = 88.8933\n",
      "test_loss = 78.0207\n",
      "****************************\n",
      "Epoch: 303\n",
      "train_loss = 89.0473\n",
      "test_loss = 78.5421\n",
      "****************************\n",
      "Epoch: 304\n",
      "train_loss = 88.9245\n",
      "test_loss = 76.5623\n",
      "****************************\n",
      "Epoch: 305\n",
      "train_loss = 88.7986\n",
      "test_loss = 77.1448\n",
      "****************************\n",
      "Epoch: 306\n",
      "train_loss = 101.6765\n",
      "test_loss = 81.4204\n",
      "****************************\n",
      "Epoch: 307\n",
      "train_loss = 88.8783\n",
      "test_loss = 77.4181\n",
      "****************************\n",
      "Epoch: 308\n",
      "train_loss = 88.8303\n",
      "test_loss = 76.9896\n",
      "****************************\n",
      "Epoch: 309\n",
      "train_loss = 89.3608\n",
      "test_loss = 79.6417\n",
      "****************************\n",
      "Epoch: 310\n",
      "train_loss = 88.8354\n",
      "test_loss = 77.6076\n",
      "****************************\n",
      "Epoch: 311\n",
      "train_loss = 90.0004\n",
      "test_loss = 75.7675\n",
      "****************************\n",
      "Epoch: 312\n",
      "train_loss = 89.2100\n",
      "test_loss = 76.1692\n",
      "****************************\n",
      "Epoch: 313\n",
      "train_loss = 88.9844\n",
      "test_loss = 77.3161\n",
      "****************************\n",
      "Epoch: 314\n",
      "train_loss = 89.7150\n",
      "test_loss = 75.9531\n",
      "****************************\n",
      "Epoch: 315\n",
      "train_loss = 89.1539\n",
      "test_loss = 78.5320\n",
      "****************************\n",
      "Epoch: 316\n",
      "train_loss = 92.5794\n",
      "test_loss = 83.9475\n",
      "****************************\n",
      "Epoch: 317\n",
      "train_loss = 89.1891\n",
      "test_loss = 76.1126\n",
      "****************************\n",
      "Epoch: 318\n",
      "train_loss = 88.8898\n",
      "test_loss = 77.0571\n",
      "****************************\n",
      "Epoch: 319\n",
      "train_loss = 88.8264\n",
      "test_loss = 77.4784\n",
      "****************************\n",
      "Epoch: 320\n",
      "train_loss = 88.8923\n",
      "test_loss = 77.7505\n",
      "****************************\n",
      "Epoch: 321\n",
      "train_loss = 89.6081\n",
      "test_loss = 75.8872\n",
      "****************************\n",
      "Epoch: 322\n",
      "train_loss = 91.6671\n",
      "test_loss = 76.0142\n",
      "****************************\n",
      "Epoch: 323\n",
      "train_loss = 88.7951\n",
      "test_loss = 76.7861\n",
      "****************************\n",
      "Epoch: 324\n",
      "train_loss = 88.9022\n",
      "test_loss = 77.5354\n",
      "****************************\n",
      "Epoch: 325\n",
      "train_loss = 94.7399\n",
      "test_loss = 87.2092\n",
      "****************************\n",
      "Epoch: 326\n",
      "train_loss = 89.1332\n",
      "test_loss = 78.1484\n",
      "****************************\n",
      "Epoch: 327\n",
      "train_loss = 88.8596\n",
      "test_loss = 77.1985\n",
      "****************************\n",
      "Epoch: 328\n",
      "train_loss = 88.8743\n",
      "test_loss = 78.0018\n",
      "****************************\n",
      "Epoch: 329\n",
      "train_loss = 88.8852\n",
      "test_loss = 78.1861\n",
      "****************************\n",
      "Epoch: 330\n",
      "train_loss = 88.8660\n",
      "test_loss = 77.1875\n",
      "****************************\n",
      "Epoch: 331\n",
      "train_loss = 88.7698\n",
      "test_loss = 76.9903\n",
      "****************************\n",
      "Epoch: 332\n",
      "train_loss = 88.8898\n",
      "test_loss = 78.2119\n",
      "****************************\n",
      "Epoch: 333\n",
      "train_loss = 89.3051\n",
      "test_loss = 75.8855\n",
      "****************************\n",
      "Epoch: 334\n",
      "train_loss = 89.4058\n",
      "test_loss = 79.4765\n",
      "****************************\n",
      "Epoch: 335\n",
      "train_loss = 88.9248\n",
      "test_loss = 78.2214\n",
      "****************************\n",
      "Epoch: 336\n",
      "train_loss = 88.8095\n",
      "test_loss = 77.8497\n",
      "****************************\n",
      "Epoch: 337\n",
      "train_loss = 88.7056\n",
      "test_loss = 76.9908\n",
      "****************************\n",
      "Epoch: 338\n",
      "train_loss = 88.7129\n",
      "test_loss = 76.9600\n",
      "****************************\n",
      "Epoch: 339\n",
      "train_loss = 89.3800\n",
      "test_loss = 76.0235\n",
      "****************************\n",
      "Epoch: 340\n",
      "train_loss = 88.9506\n",
      "test_loss = 76.4621\n",
      "****************************\n",
      "Epoch: 341\n",
      "train_loss = 88.8014\n",
      "test_loss = 77.2685\n",
      "****************************\n",
      "Epoch: 342\n",
      "train_loss = 90.0382\n",
      "test_loss = 78.2826\n",
      "****************************\n",
      "Epoch: 343\n",
      "train_loss = 89.1560\n",
      "test_loss = 78.1130\n",
      "****************************\n",
      "Epoch: 344\n",
      "train_loss = 89.2298\n",
      "test_loss = 76.0062\n",
      "****************************\n",
      "Epoch: 345\n",
      "train_loss = 88.9910\n",
      "test_loss = 78.2280\n",
      "****************************\n",
      "Epoch: 346\n",
      "train_loss = 90.0220\n",
      "test_loss = 80.8568\n",
      "****************************\n",
      "Epoch: 347\n",
      "train_loss = 88.9205\n",
      "test_loss = 76.1584\n",
      "****************************\n",
      "Epoch: 348\n",
      "train_loss = 89.7562\n",
      "test_loss = 75.6006\n",
      "****************************\n",
      "Epoch: 349\n",
      "train_loss = 89.7985\n",
      "test_loss = 75.6339\n",
      "****************************\n",
      "Epoch: 350\n",
      "train_loss = 89.6470\n",
      "test_loss = 80.2201\n",
      "****************************\n",
      "Epoch: 351\n",
      "train_loss = 91.6723\n",
      "test_loss = 83.6717\n",
      "****************************\n",
      "Epoch: 352\n",
      "train_loss = 89.4645\n",
      "test_loss = 79.5469\n",
      "****************************\n",
      "Epoch: 353\n",
      "train_loss = 88.7944\n",
      "test_loss = 76.2707\n",
      "****************************\n",
      "Epoch: 354\n",
      "train_loss = 88.9221\n",
      "test_loss = 78.3975\n",
      "****************************\n",
      "Epoch: 355\n",
      "train_loss = 88.6797\n",
      "test_loss = 77.5558\n",
      "****************************\n",
      "Epoch: 356\n",
      "train_loss = 88.7063\n",
      "test_loss = 76.4967\n",
      "****************************\n",
      "Epoch: 357\n",
      "train_loss = 88.6865\n",
      "test_loss = 77.0781\n",
      "****************************\n",
      "Epoch: 358\n",
      "train_loss = 88.7000\n",
      "test_loss = 77.1528\n",
      "****************************\n",
      "Epoch: 359\n",
      "train_loss = 88.7371\n",
      "test_loss = 76.2497\n",
      "****************************\n",
      "Epoch: 360\n",
      "train_loss = 88.7956\n",
      "test_loss = 76.2122\n",
      "****************************\n",
      "Epoch: 361\n",
      "train_loss = 90.1468\n",
      "test_loss = 81.1455\n",
      "****************************\n",
      "Epoch: 362\n",
      "train_loss = 89.0152\n",
      "test_loss = 76.7552\n",
      "****************************\n",
      "Epoch: 363\n",
      "train_loss = 88.8104\n",
      "test_loss = 77.2893\n",
      "****************************\n",
      "Epoch: 364\n",
      "train_loss = 89.3341\n",
      "test_loss = 79.0462\n",
      "****************************\n",
      "Epoch: 365\n",
      "train_loss = 88.9171\n",
      "test_loss = 76.0328\n",
      "****************************\n",
      "Epoch: 366\n",
      "train_loss = 88.9707\n",
      "test_loss = 77.3687\n",
      "****************************\n",
      "Epoch: 367\n",
      "train_loss = 88.7858\n",
      "test_loss = 76.4274\n",
      "****************************\n",
      "Epoch: 368\n",
      "train_loss = 88.7756\n",
      "test_loss = 77.8734\n",
      "****************************\n",
      "Epoch: 369\n",
      "train_loss = 92.8291\n",
      "test_loss = 84.9520\n",
      "****************************\n",
      "Epoch: 370\n",
      "train_loss = 88.7072\n",
      "test_loss = 76.4686\n",
      "****************************\n",
      "Epoch: 371\n",
      "train_loss = 88.7056\n",
      "test_loss = 77.1085\n",
      "****************************\n",
      "Epoch: 372\n",
      "train_loss = 89.4735\n",
      "test_loss = 75.7971\n",
      "****************************\n",
      "Epoch: 373\n",
      "train_loss = 89.2521\n",
      "test_loss = 79.1074\n",
      "****************************\n",
      "Epoch: 374\n",
      "train_loss = 88.6997\n",
      "test_loss = 76.2420\n",
      "****************************\n",
      "Epoch: 375\n",
      "train_loss = 88.7005\n",
      "test_loss = 77.2497\n",
      "****************************\n",
      "Epoch: 376\n",
      "train_loss = 88.6437\n",
      "test_loss = 77.7516\n",
      "****************************\n",
      "Epoch: 377\n",
      "train_loss = 88.5587\n",
      "test_loss = 77.2385\n",
      "****************************\n",
      "Epoch: 378\n",
      "train_loss = 89.8775\n",
      "test_loss = 75.5559\n",
      "****************************\n",
      "Epoch: 379\n",
      "train_loss = 88.6503\n",
      "test_loss = 77.7551\n",
      "****************************\n",
      "Epoch: 380\n",
      "train_loss = 88.5788\n",
      "test_loss = 76.5178\n",
      "****************************\n",
      "Epoch: 381\n",
      "train_loss = 88.5847\n",
      "test_loss = 76.4071\n",
      "****************************\n",
      "Epoch: 382\n",
      "train_loss = 88.8073\n",
      "test_loss = 75.8887\n",
      "****************************\n",
      "Epoch: 383\n",
      "train_loss = 90.6421\n",
      "test_loss = 75.4673\n",
      "****************************\n",
      "Epoch: 384\n",
      "train_loss = 94.5064\n",
      "test_loss = 87.4962\n",
      "****************************\n",
      "Epoch: 385\n",
      "train_loss = 89.7501\n",
      "test_loss = 75.5284\n",
      "****************************\n",
      "Epoch: 386\n",
      "train_loss = 88.7751\n",
      "test_loss = 76.0861\n",
      "****************************\n",
      "Epoch: 387\n",
      "train_loss = 89.3612\n",
      "test_loss = 75.6691\n",
      "****************************\n",
      "Epoch: 388\n",
      "train_loss = 89.1959\n",
      "test_loss = 75.6839\n",
      "****************************\n",
      "Epoch: 389\n",
      "train_loss = 89.3439\n",
      "test_loss = 79.4356\n",
      "****************************\n",
      "Epoch: 390\n",
      "train_loss = 88.5430\n",
      "test_loss = 77.1821\n",
      "****************************\n",
      "Epoch: 391\n",
      "train_loss = 89.0522\n",
      "test_loss = 78.8109\n",
      "****************************\n",
      "Epoch: 392\n",
      "train_loss = 88.7122\n",
      "test_loss = 77.8955\n",
      "****************************\n",
      "Epoch: 393\n",
      "train_loss = 89.3949\n",
      "test_loss = 79.9805\n",
      "****************************\n",
      "Epoch: 394\n",
      "train_loss = 88.5208\n",
      "test_loss = 76.6859\n",
      "****************************\n",
      "Epoch: 395\n",
      "train_loss = 90.0544\n",
      "test_loss = 75.4043\n",
      "****************************\n",
      "Epoch: 396\n",
      "train_loss = 90.2296\n",
      "test_loss = 75.3460\n",
      "****************************\n",
      "Epoch: 397\n",
      "train_loss = 88.6858\n",
      "test_loss = 75.9180\n",
      "****************************\n",
      "Epoch: 398\n",
      "train_loss = 88.6613\n",
      "test_loss = 75.9419\n",
      "****************************\n",
      "Epoch: 399\n",
      "train_loss = 88.5336\n",
      "test_loss = 76.6493\n",
      "****************************\n",
      "Epoch: 400\n",
      "train_loss = 91.5345\n",
      "test_loss = 82.8583\n",
      "****************************\n",
      "Epoch: 401\n",
      "train_loss = 88.7467\n",
      "test_loss = 75.8777\n",
      "****************************\n",
      "Epoch: 402\n",
      "train_loss = 88.5291\n",
      "test_loss = 76.6728\n",
      "****************************\n",
      "Epoch: 403\n",
      "train_loss = 88.5238\n",
      "test_loss = 76.5877\n",
      "****************************\n",
      "Epoch: 404\n",
      "train_loss = 88.4859\n",
      "test_loss = 76.6600\n",
      "****************************\n",
      "Epoch: 405\n",
      "train_loss = 91.1247\n",
      "test_loss = 75.5195\n",
      "****************************\n",
      "Epoch: 406\n",
      "train_loss = 88.6035\n",
      "test_loss = 76.1910\n",
      "****************************\n",
      "Epoch: 407\n",
      "train_loss = 88.6285\n",
      "test_loss = 78.0428\n",
      "****************************\n",
      "Epoch: 408\n",
      "train_loss = 89.8532\n",
      "test_loss = 80.8387\n",
      "****************************\n",
      "Epoch: 409\n",
      "train_loss = 88.4248\n",
      "test_loss = 77.0461\n",
      "****************************\n",
      "Epoch: 410\n",
      "train_loss = 88.5569\n",
      "test_loss = 76.1139\n",
      "****************************\n",
      "Epoch: 411\n",
      "train_loss = 89.0160\n",
      "test_loss = 75.6097\n",
      "****************************\n",
      "Epoch: 412\n",
      "train_loss = 90.3498\n",
      "test_loss = 75.5021\n",
      "****************************\n",
      "Epoch: 413\n",
      "train_loss = 88.9379\n",
      "test_loss = 78.8923\n",
      "****************************\n",
      "Epoch: 414\n",
      "train_loss = 89.7538\n",
      "test_loss = 75.4525\n",
      "****************************\n",
      "Epoch: 415\n",
      "train_loss = 90.0651\n",
      "test_loss = 75.4389\n",
      "****************************\n",
      "Epoch: 416\n",
      "train_loss = 88.5488\n",
      "test_loss = 77.4140\n",
      "****************************\n",
      "Epoch: 417\n",
      "train_loss = 88.5526\n",
      "test_loss = 77.3343\n",
      "****************************\n",
      "Epoch: 418\n",
      "train_loss = 89.7664\n",
      "test_loss = 80.5884\n",
      "****************************\n",
      "Epoch: 419\n",
      "train_loss = 88.4361\n",
      "test_loss = 76.5877\n",
      "****************************\n",
      "Epoch: 420\n",
      "train_loss = 89.3091\n",
      "test_loss = 79.1060\n",
      "****************************\n",
      "Epoch: 421\n",
      "train_loss = 88.4857\n",
      "test_loss = 76.6846\n",
      "****************************\n",
      "Epoch: 422\n",
      "train_loss = 88.8062\n",
      "test_loss = 77.6833\n",
      "****************************\n",
      "Epoch: 423\n",
      "train_loss = 88.6956\n",
      "test_loss = 77.4987\n",
      "****************************\n",
      "Epoch: 424\n",
      "train_loss = 89.1391\n",
      "test_loss = 78.9247\n",
      "****************************\n",
      "Epoch: 425\n",
      "train_loss = 88.4363\n",
      "test_loss = 76.6734\n",
      "****************************\n",
      "Epoch: 426\n",
      "train_loss = 90.7545\n",
      "test_loss = 75.4042\n",
      "****************************\n",
      "Epoch: 427\n",
      "train_loss = 89.1327\n",
      "test_loss = 78.0394\n",
      "****************************\n",
      "Epoch: 428\n",
      "train_loss = 88.5490\n",
      "test_loss = 76.7775\n",
      "****************************\n",
      "Epoch: 429\n",
      "train_loss = 89.0635\n",
      "test_loss = 78.2759\n",
      "****************************\n",
      "Epoch: 430\n",
      "train_loss = 88.4751\n",
      "test_loss = 76.6196\n",
      "****************************\n",
      "Epoch: 431\n",
      "train_loss = 88.5080\n",
      "test_loss = 77.3973\n",
      "****************************\n",
      "Epoch: 432\n",
      "train_loss = 88.5946\n",
      "test_loss = 76.0891\n",
      "****************************\n",
      "Epoch: 433\n",
      "train_loss = 88.4683\n",
      "test_loss = 77.1088\n",
      "****************************\n",
      "Epoch: 434\n",
      "train_loss = 88.7612\n",
      "test_loss = 75.6023\n",
      "****************************\n",
      "Epoch: 435\n",
      "train_loss = 89.0607\n",
      "test_loss = 75.4459\n",
      "****************************\n",
      "Epoch: 436\n",
      "train_loss = 89.5243\n",
      "test_loss = 79.7738\n",
      "****************************\n",
      "Epoch: 437\n",
      "train_loss = 89.3594\n",
      "test_loss = 79.7070\n",
      "****************************\n",
      "Epoch: 438\n",
      "train_loss = 93.0833\n",
      "test_loss = 85.2844\n",
      "****************************\n",
      "Epoch: 439\n",
      "train_loss = 89.7096\n",
      "test_loss = 79.9401\n",
      "****************************\n",
      "Epoch: 440\n",
      "train_loss = 88.7381\n",
      "test_loss = 78.0431\n",
      "****************************\n",
      "Epoch: 441\n",
      "train_loss = 88.9366\n",
      "test_loss = 75.5363\n",
      "****************************\n",
      "Epoch: 442\n",
      "train_loss = 88.4293\n",
      "test_loss = 76.9566\n",
      "****************************\n",
      "Epoch: 443\n",
      "train_loss = 88.4041\n",
      "test_loss = 77.0784\n",
      "****************************\n",
      "Epoch: 444\n",
      "train_loss = 89.1131\n",
      "test_loss = 79.5446\n",
      "****************************\n",
      "Epoch: 445\n",
      "train_loss = 88.5642\n",
      "test_loss = 77.7309\n",
      "****************************\n",
      "Epoch: 446\n",
      "train_loss = 88.6068\n",
      "test_loss = 77.9103\n",
      "****************************\n",
      "Epoch: 447\n",
      "train_loss = 88.9887\n",
      "test_loss = 78.9853\n",
      "****************************\n",
      "Epoch: 448\n",
      "train_loss = 88.7944\n",
      "test_loss = 78.8208\n",
      "****************************\n",
      "Epoch: 449\n",
      "train_loss = 88.3318\n",
      "test_loss = 76.7738\n",
      "****************************\n",
      "Epoch: 450\n",
      "train_loss = 89.3648\n",
      "test_loss = 79.9151\n",
      "****************************\n",
      "Epoch: 451\n",
      "train_loss = 88.3551\n",
      "test_loss = 76.6165\n",
      "****************************\n",
      "Epoch: 452\n",
      "train_loss = 88.5260\n",
      "test_loss = 77.8994\n",
      "****************************\n",
      "Epoch: 453\n",
      "train_loss = 89.3023\n",
      "test_loss = 79.7643\n",
      "****************************\n",
      "Epoch: 454\n",
      "train_loss = 88.4752\n",
      "test_loss = 76.3003\n",
      "****************************\n",
      "Epoch: 455\n",
      "train_loss = 89.5386\n",
      "test_loss = 79.9884\n",
      "****************************\n",
      "Epoch: 456\n",
      "train_loss = 88.6400\n",
      "test_loss = 75.7868\n",
      "****************************\n",
      "Epoch: 457\n",
      "train_loss = 88.5614\n",
      "test_loss = 75.9213\n",
      "****************************\n",
      "Epoch: 458\n",
      "train_loss = 88.4579\n",
      "test_loss = 76.0413\n",
      "****************************\n",
      "Epoch: 459\n",
      "train_loss = 88.5289\n",
      "test_loss = 75.9568\n",
      "****************************\n",
      "Epoch: 460\n",
      "train_loss = 89.0732\n",
      "test_loss = 78.2189\n",
      "****************************\n",
      "Epoch: 461\n",
      "train_loss = 88.4555\n",
      "test_loss = 77.2608\n",
      "****************************\n",
      "Epoch: 462\n",
      "train_loss = 88.4258\n",
      "test_loss = 76.2176\n",
      "****************************\n",
      "Epoch: 463\n",
      "train_loss = 89.1904\n",
      "test_loss = 75.4784\n",
      "****************************\n",
      "Epoch: 464\n",
      "train_loss = 88.4340\n",
      "test_loss = 76.0649\n",
      "****************************\n",
      "Epoch: 465\n",
      "train_loss = 90.0353\n",
      "test_loss = 75.2351\n",
      "****************************\n",
      "Epoch: 466\n",
      "train_loss = 88.3571\n",
      "test_loss = 76.5049\n",
      "****************************\n",
      "Epoch: 467\n",
      "train_loss = 88.6350\n",
      "test_loss = 77.4996\n",
      "****************************\n",
      "Epoch: 468\n",
      "train_loss = 89.6369\n",
      "test_loss = 75.3030\n",
      "****************************\n",
      "Epoch: 469\n",
      "train_loss = 88.4922\n",
      "test_loss = 77.3909\n",
      "****************************\n",
      "Epoch: 470\n",
      "train_loss = 88.7155\n",
      "test_loss = 75.6466\n",
      "****************************\n",
      "Epoch: 471\n",
      "train_loss = 92.6777\n",
      "test_loss = 84.9066\n",
      "****************************\n",
      "Epoch: 472\n",
      "train_loss = 88.3256\n",
      "test_loss = 76.7038\n",
      "****************************\n",
      "Epoch: 473\n",
      "train_loss = 88.3076\n",
      "test_loss = 77.0308\n",
      "****************************\n",
      "Epoch: 474\n",
      "train_loss = 88.3402\n",
      "test_loss = 77.4034\n",
      "****************************\n",
      "Epoch: 475\n",
      "train_loss = 88.4144\n",
      "test_loss = 77.7478\n",
      "****************************\n",
      "Epoch: 476\n",
      "train_loss = 89.1095\n",
      "test_loss = 75.3159\n",
      "****************************\n",
      "Epoch: 477\n",
      "train_loss = 88.3824\n",
      "test_loss = 76.6518\n",
      "****************************\n",
      "Epoch: 478\n",
      "train_loss = 88.9624\n",
      "test_loss = 75.3722\n",
      "****************************\n",
      "Epoch: 479\n",
      "train_loss = 88.4195\n",
      "test_loss = 77.5143\n",
      "****************************\n",
      "Epoch: 480\n",
      "train_loss = 88.5052\n",
      "test_loss = 77.2438\n",
      "****************************\n",
      "Epoch: 481\n",
      "train_loss = 88.4123\n",
      "test_loss = 76.9095\n",
      "****************************\n",
      "Epoch: 482\n",
      "train_loss = 90.7290\n",
      "test_loss = 82.2028\n",
      "****************************\n",
      "Epoch: 483\n",
      "train_loss = 89.6833\n",
      "test_loss = 75.2112\n",
      "****************************\n",
      "Epoch: 484\n",
      "train_loss = 90.0347\n",
      "test_loss = 75.1530\n",
      "****************************\n",
      "Epoch: 485\n",
      "train_loss = 88.3540\n",
      "test_loss = 76.3893\n",
      "****************************\n",
      "Epoch: 486\n",
      "train_loss = 88.3739\n",
      "test_loss = 77.3332\n",
      "****************************\n",
      "Epoch: 487\n",
      "train_loss = 88.3046\n",
      "test_loss = 76.6119\n",
      "****************************\n",
      "Epoch: 488\n",
      "train_loss = 88.8242\n",
      "test_loss = 78.8488\n",
      "****************************\n",
      "Epoch: 489\n",
      "train_loss = 89.4499\n",
      "test_loss = 79.9497\n",
      "****************************\n",
      "Epoch: 490\n",
      "train_loss = 88.9090\n",
      "test_loss = 75.3399\n",
      "****************************\n",
      "Epoch: 491\n",
      "train_loss = 90.6668\n",
      "test_loss = 75.2753\n",
      "****************************\n",
      "Epoch: 492\n",
      "train_loss = 89.0129\n",
      "test_loss = 75.2577\n",
      "****************************\n",
      "Epoch: 493\n",
      "train_loss = 88.4725\n",
      "test_loss = 75.7184\n",
      "****************************\n",
      "Epoch: 494\n",
      "train_loss = 88.6326\n",
      "test_loss = 75.5913\n",
      "****************************\n",
      "Epoch: 495\n",
      "train_loss = 92.3639\n",
      "test_loss = 84.1489\n",
      "****************************\n",
      "Epoch: 496\n",
      "train_loss = 89.0240\n",
      "test_loss = 79.1311\n",
      "****************************\n",
      "Epoch: 497\n",
      "train_loss = 88.3661\n",
      "test_loss = 77.3655\n",
      "****************************\n",
      "Epoch: 498\n",
      "train_loss = 91.7536\n",
      "test_loss = 83.5505\n",
      "****************************\n",
      "Epoch: 499\n",
      "train_loss = 88.9181\n",
      "test_loss = 78.7405\n",
      "****************************\n",
      "Epoch: 500\n",
      "train_loss = 88.6381\n",
      "test_loss = 78.2666\n",
      "****************************\n",
      "Epoch: 501\n",
      "train_loss = 88.7876\n",
      "test_loss = 75.8493\n",
      "****************************\n",
      "Epoch: 502\n",
      "train_loss = 88.8107\n",
      "test_loss = 78.6576\n",
      "****************************\n",
      "Epoch: 503\n",
      "train_loss = 88.3335\n",
      "test_loss = 75.9205\n",
      "****************************\n",
      "Epoch: 504\n",
      "train_loss = 88.3286\n",
      "test_loss = 75.9134\n",
      "****************************\n",
      "Epoch: 505\n",
      "train_loss = 88.4244\n",
      "test_loss = 77.0358\n",
      "****************************\n",
      "Epoch: 506\n",
      "train_loss = 88.4349\n",
      "test_loss = 77.6305\n",
      "****************************\n",
      "Epoch: 507\n",
      "train_loss = 89.5703\n",
      "test_loss = 75.1000\n",
      "****************************\n",
      "Epoch: 508\n",
      "train_loss = 88.5894\n",
      "test_loss = 78.2067\n",
      "****************************\n",
      "Epoch: 509\n",
      "train_loss = 89.6699\n",
      "test_loss = 80.4684\n",
      "****************************\n",
      "Epoch: 510\n",
      "train_loss = 89.3859\n",
      "test_loss = 75.1439\n",
      "****************************\n",
      "Epoch: 511\n",
      "train_loss = 90.3648\n",
      "test_loss = 75.1567\n",
      "****************************\n",
      "Epoch: 512\n",
      "train_loss = 88.3463\n",
      "test_loss = 77.5757\n",
      "****************************\n",
      "Epoch: 513\n",
      "train_loss = 88.3862\n",
      "test_loss = 75.7637\n",
      "****************************\n",
      "Epoch: 514\n",
      "train_loss = 88.6088\n",
      "test_loss = 78.4044\n",
      "****************************\n",
      "Epoch: 515\n",
      "train_loss = 89.1431\n",
      "test_loss = 75.1736\n",
      "****************************\n",
      "Epoch: 516\n",
      "train_loss = 88.3161\n",
      "test_loss = 76.4355\n",
      "****************************\n",
      "Epoch: 517\n",
      "train_loss = 88.3684\n",
      "test_loss = 77.1355\n",
      "****************************\n",
      "Epoch: 518\n",
      "train_loss = 88.5542\n",
      "test_loss = 78.2237\n",
      "****************************\n",
      "Epoch: 519\n",
      "train_loss = 88.3350\n",
      "test_loss = 76.2698\n",
      "****************************\n",
      "Epoch: 520\n",
      "train_loss = 88.2935\n",
      "test_loss = 77.3280\n",
      "****************************\n",
      "Epoch: 521\n",
      "train_loss = 88.4860\n",
      "test_loss = 75.6814\n",
      "****************************\n",
      "Epoch: 522\n",
      "train_loss = 88.5023\n",
      "test_loss = 77.8225\n",
      "****************************\n",
      "Epoch: 523\n",
      "train_loss = 89.6234\n",
      "test_loss = 75.0879\n",
      "****************************\n",
      "Epoch: 524\n",
      "train_loss = 89.5419\n",
      "test_loss = 80.1285\n",
      "****************************\n",
      "Epoch: 525\n",
      "train_loss = 88.5246\n",
      "test_loss = 75.5286\n",
      "****************************\n",
      "Epoch: 526\n",
      "train_loss = 88.5278\n",
      "test_loss = 78.2016\n",
      "****************************\n",
      "Epoch: 527\n",
      "train_loss = 88.5194\n",
      "test_loss = 75.4602\n",
      "****************************\n",
      "Epoch: 528\n",
      "train_loss = 88.2453\n",
      "test_loss = 76.7979\n",
      "****************************\n",
      "Epoch: 529\n",
      "train_loss = 88.1859\n",
      "test_loss = 76.6356\n",
      "****************************\n",
      "Epoch: 530\n",
      "train_loss = 89.7164\n",
      "test_loss = 75.0626\n",
      "****************************\n",
      "Epoch: 531\n",
      "train_loss = 89.4555\n",
      "test_loss = 79.9268\n",
      "****************************\n",
      "Epoch: 532\n",
      "train_loss = 88.2942\n",
      "test_loss = 76.2028\n",
      "****************************\n",
      "Epoch: 533\n",
      "train_loss = 88.2804\n",
      "test_loss = 77.1198\n",
      "****************************\n",
      "Epoch: 534\n",
      "train_loss = 88.2421\n",
      "test_loss = 76.3838\n",
      "****************************\n",
      "Epoch: 535\n",
      "train_loss = 90.4023\n",
      "test_loss = 75.2053\n",
      "****************************\n",
      "Epoch: 536\n",
      "train_loss = 88.2243\n",
      "test_loss = 76.5451\n",
      "****************************\n",
      "Epoch: 537\n",
      "train_loss = 88.8691\n",
      "test_loss = 75.3374\n",
      "****************************\n",
      "Epoch: 538\n",
      "train_loss = 88.8361\n",
      "test_loss = 75.2961\n",
      "****************************\n",
      "Epoch: 539\n",
      "train_loss = 89.3963\n",
      "test_loss = 75.1387\n",
      "****************************\n",
      "Epoch: 540\n",
      "train_loss = 89.0422\n",
      "test_loss = 76.6303\n",
      "****************************\n",
      "Epoch: 541\n",
      "train_loss = 89.6242\n",
      "test_loss = 80.2573\n",
      "****************************\n",
      "Epoch: 542\n",
      "train_loss = 88.2899\n",
      "test_loss = 76.6352\n",
      "****************************\n",
      "Epoch: 543\n",
      "train_loss = 89.1406\n",
      "test_loss = 75.2852\n",
      "****************************\n",
      "Epoch: 544\n",
      "train_loss = 88.2378\n",
      "test_loss = 76.8993\n",
      "****************************\n",
      "Epoch: 545\n",
      "train_loss = 88.3465\n",
      "test_loss = 75.8886\n",
      "****************************\n",
      "Epoch: 546\n",
      "train_loss = 88.3535\n",
      "test_loss = 77.5060\n",
      "****************************\n",
      "Epoch: 547\n",
      "train_loss = 89.3547\n",
      "test_loss = 79.7883\n",
      "****************************\n",
      "Epoch: 548\n",
      "train_loss = 88.6455\n",
      "test_loss = 75.4729\n",
      "****************************\n",
      "Epoch: 549\n",
      "train_loss = 88.2015\n",
      "test_loss = 76.7568\n",
      "****************************\n",
      "Epoch: 550\n",
      "train_loss = 92.3327\n",
      "test_loss = 84.3152\n",
      "****************************\n",
      "Epoch: 551\n",
      "train_loss = 88.3869\n",
      "test_loss = 77.3556\n",
      "****************************\n",
      "Epoch: 552\n",
      "train_loss = 88.3711\n",
      "test_loss = 75.7505\n",
      "****************************\n",
      "Epoch: 553\n",
      "train_loss = 88.3636\n",
      "test_loss = 77.6959\n",
      "****************************\n",
      "Epoch: 554\n",
      "train_loss = 88.1652\n",
      "test_loss = 76.2772\n",
      "****************************\n",
      "Epoch: 555\n",
      "train_loss = 88.4201\n",
      "test_loss = 77.5416\n",
      "****************************\n",
      "Epoch: 556\n",
      "train_loss = 88.7286\n",
      "test_loss = 78.2741\n",
      "****************************\n",
      "Epoch: 557\n",
      "train_loss = 88.2385\n",
      "test_loss = 76.7246\n",
      "****************************\n",
      "Epoch: 558\n",
      "train_loss = 88.1996\n",
      "test_loss = 76.2567\n",
      "****************************\n",
      "Epoch: 559\n",
      "train_loss = 88.3323\n",
      "test_loss = 75.6227\n",
      "****************************\n",
      "Epoch: 560\n",
      "train_loss = 88.1277\n",
      "test_loss = 76.6571\n",
      "****************************\n",
      "Epoch: 561\n",
      "train_loss = 88.4908\n",
      "test_loss = 78.1449\n",
      "****************************\n",
      "Epoch: 562\n",
      "train_loss = 90.7484\n",
      "test_loss = 82.3635\n",
      "****************************\n",
      "Epoch: 563\n",
      "train_loss = 89.6937\n",
      "test_loss = 75.0627\n",
      "****************************\n",
      "Epoch: 564\n",
      "train_loss = 89.0526\n",
      "test_loss = 79.0115\n",
      "****************************\n",
      "Epoch: 565\n",
      "train_loss = 88.6677\n",
      "test_loss = 78.2208\n",
      "****************************\n",
      "Epoch: 566\n",
      "train_loss = 88.6972\n",
      "test_loss = 78.1327\n",
      "****************************\n",
      "Epoch: 567\n",
      "train_loss = 89.0226\n",
      "test_loss = 79.2161\n",
      "****************************\n",
      "Epoch: 568\n",
      "train_loss = 88.2316\n",
      "test_loss = 77.2745\n",
      "****************************\n",
      "Epoch: 569\n",
      "train_loss = 88.5969\n",
      "test_loss = 78.4750\n",
      "****************************\n",
      "Epoch: 570\n",
      "train_loss = 88.2466\n",
      "test_loss = 77.4602\n",
      "****************************\n",
      "Epoch: 571\n",
      "train_loss = 88.3460\n",
      "test_loss = 75.6324\n",
      "****************************\n",
      "Epoch: 572\n",
      "train_loss = 88.1795\n",
      "test_loss = 76.5975\n",
      "****************************\n",
      "Epoch: 573\n",
      "train_loss = 88.2500\n",
      "test_loss = 77.1016\n",
      "****************************\n",
      "Epoch: 574\n",
      "train_loss = 88.5562\n",
      "test_loss = 75.5509\n",
      "****************************\n",
      "Epoch: 575\n",
      "train_loss = 88.6139\n",
      "test_loss = 75.5991\n",
      "****************************\n",
      "Epoch: 576\n",
      "train_loss = 88.2298\n",
      "test_loss = 76.8870\n",
      "****************************\n",
      "Epoch: 577\n",
      "train_loss = 89.2684\n",
      "test_loss = 79.5303\n",
      "****************************\n",
      "Epoch: 578\n",
      "train_loss = 90.2206\n",
      "test_loss = 75.0743\n",
      "****************************\n",
      "Epoch: 579\n",
      "train_loss = 88.7455\n",
      "test_loss = 75.3716\n",
      "****************************\n",
      "Epoch: 580\n",
      "train_loss = 88.2010\n",
      "test_loss = 76.4739\n",
      "****************************\n",
      "Epoch: 581\n",
      "train_loss = 88.8962\n",
      "test_loss = 78.7964\n",
      "****************************\n",
      "Epoch: 582\n",
      "train_loss = 89.9359\n",
      "test_loss = 80.5939\n",
      "****************************\n",
      "Epoch: 583\n",
      "train_loss = 88.7043\n",
      "test_loss = 78.3793\n",
      "****************************\n",
      "Epoch: 584\n",
      "train_loss = 88.2732\n",
      "test_loss = 77.1888\n",
      "****************************\n",
      "Epoch: 585\n",
      "train_loss = 88.2644\n",
      "test_loss = 76.7187\n",
      "****************************\n",
      "Epoch: 586\n",
      "train_loss = 88.1977\n",
      "test_loss = 76.0093\n",
      "****************************\n",
      "Epoch: 587\n",
      "train_loss = 88.3224\n",
      "test_loss = 75.5998\n",
      "****************************\n",
      "Epoch: 588\n",
      "train_loss = 88.1843\n",
      "test_loss = 76.4699\n",
      "****************************\n",
      "Epoch: 589\n",
      "train_loss = 88.2230\n",
      "test_loss = 76.9258\n",
      "****************************\n",
      "Epoch: 590\n",
      "train_loss = 88.8112\n",
      "test_loss = 78.8495\n",
      "****************************\n",
      "Epoch: 591\n",
      "train_loss = 88.1620\n",
      "test_loss = 76.8919\n",
      "****************************\n",
      "Epoch: 592\n",
      "train_loss = 89.3721\n",
      "test_loss = 75.0377\n",
      "****************************\n",
      "Epoch: 593\n",
      "train_loss = 91.0782\n",
      "test_loss = 75.1409\n",
      "****************************\n",
      "Epoch: 594\n",
      "train_loss = 88.1294\n",
      "test_loss = 76.0754\n",
      "****************************\n",
      "Epoch: 595\n",
      "train_loss = 89.2400\n",
      "test_loss = 74.9618\n",
      "****************************\n",
      "Epoch: 596\n",
      "train_loss = 88.6861\n",
      "test_loss = 78.2510\n",
      "****************************\n",
      "Epoch: 597\n",
      "train_loss = 88.2586\n",
      "test_loss = 77.3273\n",
      "****************************\n",
      "Epoch: 598\n",
      "train_loss = 88.2648\n",
      "test_loss = 75.7757\n",
      "****************************\n",
      "Epoch: 599\n",
      "train_loss = 88.3520\n",
      "test_loss = 75.6019\n",
      "****************************\n",
      "Epoch: 600\n",
      "train_loss = 88.0777\n",
      "test_loss = 76.3710\n",
      "****************************\n",
      "Epoch: 601\n",
      "train_loss = 88.7394\n",
      "test_loss = 75.1265\n",
      "****************************\n",
      "Epoch: 602\n",
      "train_loss = 88.4898\n",
      "test_loss = 78.1627\n",
      "****************************\n",
      "Epoch: 603\n",
      "train_loss = 88.6611\n",
      "test_loss = 78.7249\n",
      "****************************\n",
      "Epoch: 604\n",
      "train_loss = 88.4390\n",
      "test_loss = 75.3624\n",
      "****************************\n",
      "Epoch: 605\n",
      "train_loss = 88.1577\n",
      "test_loss = 75.8845\n",
      "****************************\n",
      "Epoch: 606\n",
      "train_loss = 88.1714\n",
      "test_loss = 75.8557\n",
      "****************************\n",
      "Epoch: 607\n",
      "train_loss = 91.8859\n",
      "test_loss = 75.3020\n",
      "****************************\n",
      "Epoch: 608\n",
      "train_loss = 88.2705\n",
      "test_loss = 77.4484\n",
      "****************************\n",
      "Epoch: 609\n",
      "train_loss = 88.1632\n",
      "test_loss = 75.9942\n",
      "****************************\n",
      "Epoch: 610\n",
      "train_loss = 88.1657\n",
      "test_loss = 77.2459\n",
      "****************************\n",
      "Epoch: 611\n",
      "train_loss = 88.5832\n",
      "test_loss = 78.5266\n",
      "****************************\n",
      "Epoch: 612\n",
      "train_loss = 89.3312\n",
      "test_loss = 80.0877\n",
      "****************************\n",
      "Epoch: 613\n",
      "train_loss = 88.5229\n",
      "test_loss = 75.3348\n",
      "****************************\n",
      "Epoch: 614\n",
      "train_loss = 89.2575\n",
      "test_loss = 75.2954\n",
      "****************************\n",
      "Epoch: 615\n",
      "train_loss = 88.6373\n",
      "test_loss = 77.9781\n",
      "****************************\n",
      "Epoch: 616\n",
      "train_loss = 88.1884\n",
      "test_loss = 77.1026\n",
      "****************************\n",
      "Epoch: 617\n",
      "train_loss = 88.3853\n",
      "test_loss = 77.7915\n",
      "****************************\n",
      "Epoch: 618\n",
      "train_loss = 88.2651\n",
      "test_loss = 77.5888\n",
      "****************************\n",
      "Epoch: 619\n",
      "train_loss = 88.2505\n",
      "test_loss = 77.7184\n",
      "****************************\n",
      "Epoch: 620\n",
      "train_loss = 88.2706\n",
      "test_loss = 75.4963\n",
      "****************************\n",
      "Epoch: 621\n",
      "train_loss = 88.3299\n",
      "test_loss = 77.3180\n",
      "****************************\n",
      "Epoch: 622\n",
      "train_loss = 88.4400\n",
      "test_loss = 77.9618\n",
      "****************************\n",
      "Epoch: 623\n",
      "train_loss = 88.2109\n",
      "test_loss = 75.7005\n",
      "****************************\n",
      "Epoch: 624\n",
      "train_loss = 88.8399\n",
      "test_loss = 75.0485\n",
      "****************************\n",
      "Epoch: 625\n",
      "train_loss = 88.1726\n",
      "test_loss = 75.9672\n",
      "****************************\n",
      "Epoch: 626\n",
      "train_loss = 88.1839\n",
      "test_loss = 75.8603\n",
      "****************************\n",
      "Epoch: 627\n",
      "train_loss = 88.1082\n",
      "test_loss = 76.4725\n",
      "****************************\n",
      "Epoch: 628\n",
      "train_loss = 88.1534\n",
      "test_loss = 75.7836\n",
      "****************************\n",
      "Epoch: 629\n",
      "train_loss = 88.0959\n",
      "test_loss = 76.9929\n",
      "****************************\n",
      "Epoch: 630\n",
      "train_loss = 88.6093\n",
      "test_loss = 75.1456\n",
      "****************************\n",
      "Epoch: 631\n",
      "train_loss = 88.1306\n",
      "test_loss = 77.0001\n",
      "****************************\n",
      "Epoch: 632\n",
      "train_loss = 98.5488\n",
      "test_loss = 78.9336\n",
      "****************************\n",
      "Epoch: 633\n",
      "train_loss = 88.2130\n",
      "test_loss = 75.7438\n",
      "****************************\n",
      "Epoch: 634\n",
      "train_loss = 88.6024\n",
      "test_loss = 75.1352\n",
      "****************************\n",
      "Epoch: 635\n",
      "train_loss = 88.5657\n",
      "test_loss = 75.1702\n",
      "****************************\n",
      "Epoch: 636\n",
      "train_loss = 88.7235\n",
      "test_loss = 75.0695\n",
      "****************************\n",
      "Epoch: 637\n",
      "train_loss = 88.2465\n",
      "test_loss = 75.5168\n",
      "****************************\n",
      "Epoch: 638\n",
      "train_loss = 88.1527\n",
      "test_loss = 75.7645\n",
      "****************************\n",
      "Epoch: 639\n",
      "train_loss = 88.2707\n",
      "test_loss = 75.4437\n",
      "****************************\n",
      "Epoch: 640\n",
      "train_loss = 88.4245\n",
      "test_loss = 78.0090\n",
      "****************************\n",
      "Epoch: 641\n",
      "train_loss = 88.0534\n",
      "test_loss = 76.1671\n",
      "****************************\n",
      "Epoch: 642\n",
      "train_loss = 88.4074\n",
      "test_loss = 75.2162\n",
      "****************************\n",
      "Epoch: 643\n",
      "train_loss = 88.0290\n",
      "test_loss = 76.4743\n",
      "****************************\n",
      "Epoch: 644\n",
      "train_loss = 88.2292\n",
      "test_loss = 77.5032\n",
      "****************************\n",
      "Epoch: 645\n",
      "train_loss = 88.0688\n",
      "test_loss = 76.1910\n",
      "****************************\n",
      "Epoch: 646\n",
      "train_loss = 90.9291\n",
      "test_loss = 82.4347\n",
      "****************************\n",
      "Epoch: 647\n",
      "train_loss = 88.4423\n",
      "test_loss = 78.1969\n",
      "****************************\n",
      "Epoch: 648\n",
      "train_loss = 88.0900\n",
      "test_loss = 76.0270\n",
      "****************************\n",
      "Epoch: 649\n",
      "train_loss = 89.3602\n",
      "test_loss = 74.8986\n",
      "****************************\n",
      "Epoch: 650\n",
      "train_loss = 88.4103\n",
      "test_loss = 75.3257\n",
      "****************************\n",
      "Epoch: 651\n",
      "train_loss = 88.1573\n",
      "test_loss = 76.9262\n",
      "****************************\n",
      "Epoch: 652\n",
      "train_loss = 88.2566\n",
      "test_loss = 75.4661\n",
      "****************************\n",
      "Epoch: 653\n",
      "train_loss = 88.1068\n",
      "test_loss = 75.8197\n",
      "****************************\n",
      "Epoch: 654\n",
      "train_loss = 89.0713\n",
      "test_loss = 74.8956\n",
      "****************************\n",
      "Epoch: 655\n",
      "train_loss = 88.0505\n",
      "test_loss = 76.0479\n",
      "****************************\n",
      "Epoch: 656\n",
      "train_loss = 88.4450\n",
      "test_loss = 75.1499\n",
      "****************************\n",
      "Epoch: 657\n",
      "train_loss = 88.3602\n",
      "test_loss = 75.2573\n",
      "****************************\n",
      "Epoch: 658\n",
      "train_loss = 88.1231\n",
      "test_loss = 75.6612\n",
      "****************************\n",
      "Epoch: 659\n",
      "train_loss = 88.0664\n",
      "test_loss = 75.7077\n",
      "****************************\n",
      "Epoch: 660\n",
      "train_loss = 88.5827\n",
      "test_loss = 75.0011\n",
      "****************************\n",
      "Epoch: 661\n",
      "train_loss = 88.1058\n",
      "test_loss = 75.6614\n",
      "****************************\n",
      "Epoch: 662\n",
      "train_loss = 89.0536\n",
      "test_loss = 79.0953\n",
      "****************************\n",
      "Epoch: 663\n",
      "train_loss = 88.6882\n",
      "test_loss = 75.0174\n",
      "****************************\n",
      "Epoch: 664\n",
      "train_loss = 88.1272\n",
      "test_loss = 75.5148\n",
      "****************************\n",
      "Epoch: 665\n",
      "train_loss = 88.3782\n",
      "test_loss = 75.1963\n",
      "****************************\n",
      "Epoch: 666\n",
      "train_loss = 89.4182\n",
      "test_loss = 74.8293\n",
      "****************************\n",
      "Epoch: 667\n",
      "train_loss = 88.1499\n",
      "test_loss = 77.0553\n",
      "****************************\n",
      "Epoch: 668\n",
      "train_loss = 88.7915\n",
      "test_loss = 74.9135\n",
      "****************************\n",
      "Epoch: 669\n",
      "train_loss = 88.1896\n",
      "test_loss = 77.1296\n",
      "****************************\n",
      "Epoch: 670\n",
      "train_loss = 88.2854\n",
      "test_loss = 77.3309\n",
      "****************************\n",
      "Epoch: 671\n",
      "train_loss = 88.3006\n",
      "test_loss = 77.6006\n",
      "****************************\n",
      "Epoch: 672\n",
      "train_loss = 88.2677\n",
      "test_loss = 77.4778\n",
      "****************************\n",
      "Epoch: 673\n",
      "train_loss = 88.0060\n",
      "test_loss = 76.0647\n",
      "****************************\n",
      "Epoch: 674\n",
      "train_loss = 88.1782\n",
      "test_loss = 75.3911\n",
      "****************************\n",
      "Epoch: 675\n",
      "train_loss = 88.0191\n",
      "test_loss = 76.3989\n",
      "****************************\n",
      "Epoch: 676\n",
      "train_loss = 88.0407\n",
      "test_loss = 76.3359\n",
      "****************************\n",
      "Epoch: 677\n",
      "train_loss = 88.1128\n",
      "test_loss = 75.6658\n",
      "****************************\n",
      "Epoch: 678\n",
      "train_loss = 88.9546\n",
      "test_loss = 74.8702\n",
      "****************************\n",
      "Epoch: 679\n",
      "train_loss = 88.7054\n",
      "test_loss = 74.9043\n",
      "****************************\n",
      "Epoch: 680\n",
      "train_loss = 87.9964\n",
      "test_loss = 76.0364\n",
      "****************************\n",
      "Epoch: 681\n",
      "train_loss = 88.2036\n",
      "test_loss = 75.4669\n",
      "****************************\n",
      "Epoch: 682\n",
      "train_loss = 88.6723\n",
      "test_loss = 74.9420\n",
      "****************************\n",
      "Epoch: 683\n",
      "train_loss = 88.8280\n",
      "test_loss = 78.6023\n",
      "****************************\n",
      "Epoch: 684\n",
      "train_loss = 89.0568\n",
      "test_loss = 78.6343\n",
      "****************************\n",
      "Epoch: 685\n",
      "train_loss = 88.0409\n",
      "test_loss = 76.1475\n",
      "****************************\n",
      "Epoch: 686\n",
      "train_loss = 88.0372\n",
      "test_loss = 76.5418\n",
      "****************************\n",
      "Epoch: 687\n",
      "train_loss = 88.4060\n",
      "test_loss = 75.1482\n",
      "****************************\n",
      "Epoch: 688\n",
      "train_loss = 88.0782\n",
      "test_loss = 76.5170\n",
      "****************************\n",
      "Epoch: 689\n",
      "train_loss = 89.7204\n",
      "test_loss = 80.4312\n",
      "****************************\n",
      "Epoch: 690\n",
      "train_loss = 88.3532\n",
      "test_loss = 77.7813\n",
      "****************************\n",
      "Epoch: 691\n",
      "train_loss = 88.0731\n",
      "test_loss = 76.2161\n",
      "****************************\n",
      "Epoch: 692\n",
      "train_loss = 88.4134\n",
      "test_loss = 75.3784\n",
      "****************************\n",
      "Epoch: 693\n",
      "train_loss = 88.1095\n",
      "test_loss = 76.5373\n",
      "****************************\n",
      "Epoch: 694\n",
      "train_loss = 88.2250\n",
      "test_loss = 75.4135\n",
      "****************************\n",
      "Epoch: 695\n",
      "train_loss = 88.1006\n",
      "test_loss = 75.7536\n",
      "****************************\n",
      "Epoch: 696\n",
      "train_loss = 89.0345\n",
      "test_loss = 79.1516\n",
      "****************************\n",
      "Epoch: 697\n",
      "train_loss = 88.2182\n",
      "test_loss = 77.1093\n",
      "****************************\n",
      "Epoch: 698\n",
      "train_loss = 88.1662\n",
      "test_loss = 75.5100\n",
      "****************************\n",
      "Epoch: 699\n",
      "train_loss = 88.9012\n",
      "test_loss = 74.8765\n",
      "****************************\n",
      "Epoch: 700\n",
      "train_loss = 88.5494\n",
      "test_loss = 75.0354\n",
      "****************************\n",
      "Epoch: 701\n",
      "train_loss = 88.1024\n",
      "test_loss = 77.0009\n",
      "****************************\n",
      "Epoch: 702\n",
      "train_loss = 94.7003\n",
      "test_loss = 87.8857\n",
      "****************************\n",
      "Epoch: 703\n",
      "train_loss = 88.3521\n",
      "test_loss = 77.7729\n",
      "****************************\n",
      "Epoch: 704\n",
      "train_loss = 89.2605\n",
      "test_loss = 74.7048\n",
      "****************************\n",
      "Epoch: 705\n",
      "train_loss = 91.9549\n",
      "test_loss = 84.0354\n",
      "****************************\n",
      "Epoch: 706\n",
      "train_loss = 88.0162\n",
      "test_loss = 75.8314\n",
      "****************************\n",
      "Epoch: 707\n",
      "train_loss = 88.4834\n",
      "test_loss = 78.2156\n",
      "****************************\n",
      "Epoch: 708\n",
      "train_loss = 88.1320\n",
      "test_loss = 77.4192\n",
      "****************************\n",
      "Epoch: 709\n",
      "train_loss = 87.9867\n",
      "test_loss = 76.3936\n",
      "****************************\n",
      "Epoch: 710\n",
      "train_loss = 88.0488\n",
      "test_loss = 76.3390\n",
      "****************************\n",
      "Epoch: 711\n",
      "train_loss = 88.7312\n",
      "test_loss = 74.9137\n",
      "****************************\n",
      "Epoch: 712\n",
      "train_loss = 90.2462\n",
      "test_loss = 74.9973\n",
      "****************************\n",
      "Epoch: 713\n",
      "train_loss = 88.1195\n",
      "test_loss = 75.9229\n",
      "****************************\n",
      "Epoch: 714\n",
      "train_loss = 88.0809\n",
      "test_loss = 76.0756\n",
      "****************************\n",
      "Epoch: 715\n",
      "train_loss = 88.5608\n",
      "test_loss = 75.0378\n",
      "****************************\n",
      "Epoch: 716\n",
      "train_loss = 88.9778\n",
      "test_loss = 74.9862\n",
      "****************************\n",
      "Epoch: 717\n",
      "train_loss = 88.2081\n",
      "test_loss = 75.4744\n",
      "****************************\n",
      "Epoch: 718\n",
      "train_loss = 89.4775\n",
      "test_loss = 74.8018\n",
      "****************************\n",
      "Epoch: 719\n",
      "train_loss = 88.0839\n",
      "test_loss = 76.1134\n",
      "****************************\n",
      "Epoch: 720\n",
      "train_loss = 92.7550\n",
      "test_loss = 84.8445\n",
      "****************************\n",
      "Epoch: 721\n",
      "train_loss = 88.1156\n",
      "test_loss = 75.6482\n",
      "****************************\n",
      "Epoch: 722\n",
      "train_loss = 88.6876\n",
      "test_loss = 75.4057\n",
      "****************************\n",
      "Epoch: 723\n",
      "train_loss = 88.0351\n",
      "test_loss = 76.6009\n",
      "****************************\n",
      "Epoch: 724\n",
      "train_loss = 88.0636\n",
      "test_loss = 75.7149\n",
      "****************************\n",
      "Epoch: 725\n",
      "train_loss = 88.1048\n",
      "test_loss = 75.5928\n",
      "****************************\n",
      "Epoch: 726\n",
      "train_loss = 89.3201\n",
      "test_loss = 79.7882\n",
      "****************************\n",
      "Epoch: 727\n",
      "train_loss = 89.2561\n",
      "test_loss = 74.8117\n",
      "****************************\n",
      "Epoch: 728\n",
      "train_loss = 88.3991\n",
      "test_loss = 78.0109\n",
      "****************************\n",
      "Epoch: 729\n",
      "train_loss = 89.1517\n",
      "test_loss = 79.4998\n",
      "****************************\n",
      "Epoch: 730\n",
      "train_loss = 88.0087\n",
      "test_loss = 76.1299\n",
      "****************************\n",
      "Epoch: 731\n",
      "train_loss = 88.4175\n",
      "test_loss = 77.9192\n",
      "****************************\n",
      "Epoch: 732\n",
      "train_loss = 88.3874\n",
      "test_loss = 77.8999\n",
      "****************************\n",
      "Epoch: 733\n",
      "train_loss = 88.0219\n",
      "test_loss = 75.6870\n",
      "****************************\n",
      "Epoch: 734\n",
      "train_loss = 88.0449\n",
      "test_loss = 76.7263\n",
      "****************************\n",
      "Epoch: 735\n",
      "train_loss = 88.0825\n",
      "test_loss = 75.6176\n",
      "****************************\n",
      "Epoch: 736\n",
      "train_loss = 94.6975\n",
      "test_loss = 77.5882\n",
      "****************************\n",
      "Epoch: 737\n",
      "train_loss = 88.1923\n",
      "test_loss = 77.1084\n",
      "****************************\n",
      "Epoch: 738\n",
      "train_loss = 88.0930\n",
      "test_loss = 75.7418\n",
      "****************************\n",
      "Epoch: 739\n",
      "train_loss = 88.0609\n",
      "test_loss = 76.3239\n",
      "****************************\n",
      "Epoch: 740\n",
      "train_loss = 88.0247\n",
      "test_loss = 75.9040\n",
      "****************************\n",
      "Epoch: 741\n",
      "train_loss = 88.1328\n",
      "test_loss = 77.1027\n",
      "****************************\n",
      "Epoch: 742\n",
      "train_loss = 88.2589\n",
      "test_loss = 76.9789\n",
      "****************************\n",
      "Epoch: 743\n",
      "train_loss = 88.0669\n",
      "test_loss = 76.1503\n",
      "****************************\n",
      "Epoch: 744\n",
      "train_loss = 88.4348\n",
      "test_loss = 78.0881\n",
      "****************************\n",
      "Epoch: 745\n",
      "train_loss = 88.0400\n",
      "test_loss = 75.8177\n",
      "****************************\n",
      "Epoch: 746\n",
      "train_loss = 88.5217\n",
      "test_loss = 78.0175\n",
      "****************************\n",
      "Epoch: 747\n",
      "train_loss = 88.0646\n",
      "test_loss = 76.3091\n",
      "****************************\n",
      "Epoch: 748\n",
      "train_loss = 88.3610\n",
      "test_loss = 78.0176\n",
      "****************************\n",
      "Epoch: 749\n",
      "train_loss = 88.4313\n",
      "test_loss = 75.1560\n",
      "****************************\n",
      "Epoch: 750\n",
      "train_loss = 88.5288\n",
      "test_loss = 75.5757\n",
      "****************************\n",
      "Epoch: 751\n",
      "train_loss = 88.6313\n",
      "test_loss = 76.6233\n",
      "****************************\n",
      "Epoch: 752\n",
      "train_loss = 89.0240\n",
      "test_loss = 79.2245\n",
      "****************************\n",
      "Epoch: 753\n",
      "train_loss = 90.4533\n",
      "test_loss = 81.7807\n",
      "****************************\n",
      "Epoch: 754\n",
      "train_loss = 88.5347\n",
      "test_loss = 78.3998\n",
      "****************************\n",
      "Epoch: 755\n",
      "train_loss = 88.7660\n",
      "test_loss = 76.2002\n",
      "****************************\n",
      "Epoch: 756\n",
      "train_loss = 88.0698\n",
      "test_loss = 76.1284\n",
      "****************************\n",
      "Epoch: 757\n",
      "train_loss = 88.1349\n",
      "test_loss = 75.5399\n",
      "****************************\n",
      "Epoch: 758\n",
      "train_loss = 88.5273\n",
      "test_loss = 75.0494\n",
      "****************************\n",
      "Epoch: 759\n",
      "train_loss = 87.9552\n",
      "test_loss = 76.3741\n",
      "****************************\n",
      "Epoch: 760\n",
      "train_loss = 88.3017\n",
      "test_loss = 75.2263\n",
      "****************************\n",
      "Epoch: 761\n",
      "train_loss = 90.2362\n",
      "test_loss = 74.7604\n",
      "****************************\n",
      "Epoch: 762\n",
      "train_loss = 87.9813\n",
      "test_loss = 76.2711\n",
      "****************************\n",
      "Epoch: 763\n",
      "train_loss = 88.2134\n",
      "test_loss = 77.6848\n",
      "****************************\n",
      "Epoch: 764\n",
      "train_loss = 88.6986\n",
      "test_loss = 74.8128\n",
      "****************************\n",
      "Epoch: 765\n",
      "train_loss = 88.1011\n",
      "test_loss = 77.2096\n",
      "****************************\n",
      "Epoch: 766\n",
      "train_loss = 88.2817\n",
      "test_loss = 75.1052\n",
      "****************************\n",
      "Epoch: 767\n",
      "train_loss = 87.9661\n",
      "test_loss = 75.6753\n",
      "****************************\n",
      "Epoch: 768\n",
      "train_loss = 90.9196\n",
      "test_loss = 82.5814\n",
      "****************************\n",
      "Epoch: 769\n",
      "train_loss = 88.8455\n",
      "test_loss = 78.8684\n",
      "****************************\n",
      "Epoch: 770\n",
      "train_loss = 87.9902\n",
      "test_loss = 76.8028\n",
      "****************************\n",
      "Epoch: 771\n",
      "train_loss = 88.1387\n",
      "test_loss = 77.3001\n",
      "****************************\n",
      "Epoch: 772\n",
      "train_loss = 88.4792\n",
      "test_loss = 77.8377\n",
      "****************************\n",
      "Epoch: 773\n",
      "train_loss = 88.0331\n",
      "test_loss = 76.5409\n",
      "****************************\n",
      "Epoch: 774\n",
      "train_loss = 88.1408\n",
      "test_loss = 75.5998\n",
      "****************************\n",
      "Epoch: 775\n",
      "train_loss = 88.0005\n",
      "test_loss = 76.5150\n",
      "****************************\n",
      "Epoch: 776\n",
      "train_loss = 88.3860\n",
      "test_loss = 78.0006\n",
      "****************************\n",
      "Epoch: 777\n",
      "train_loss = 87.9615\n",
      "test_loss = 75.9280\n",
      "****************************\n",
      "Epoch: 778\n",
      "train_loss = 88.7989\n",
      "test_loss = 74.8950\n",
      "****************************\n",
      "Epoch: 779\n",
      "train_loss = 88.0349\n",
      "test_loss = 75.6945\n",
      "****************************\n",
      "Epoch: 780\n",
      "train_loss = 88.3353\n",
      "test_loss = 75.0735\n",
      "****************************\n",
      "Epoch: 781\n",
      "train_loss = 88.0496\n",
      "test_loss = 76.8416\n",
      "****************************\n",
      "Epoch: 782\n",
      "train_loss = 87.9429\n",
      "test_loss = 76.2168\n",
      "****************************\n",
      "Epoch: 783\n",
      "train_loss = 88.0301\n",
      "test_loss = 76.5039\n",
      "****************************\n",
      "Epoch: 784\n",
      "train_loss = 87.9623\n",
      "test_loss = 76.2891\n",
      "****************************\n",
      "Epoch: 785\n",
      "train_loss = 88.1869\n",
      "test_loss = 75.2321\n",
      "****************************\n",
      "Epoch: 786\n",
      "train_loss = 88.2604\n",
      "test_loss = 75.1504\n",
      "****************************\n",
      "Epoch: 787\n",
      "train_loss = 88.2062\n",
      "test_loss = 75.3758\n",
      "****************************\n",
      "Epoch: 788\n",
      "train_loss = 89.0275\n",
      "test_loss = 79.2111\n",
      "****************************\n",
      "Epoch: 789\n",
      "train_loss = 88.0083\n",
      "test_loss = 76.7428\n",
      "****************************\n",
      "Epoch: 790\n",
      "train_loss = 87.9800\n",
      "test_loss = 75.9556\n",
      "****************************\n",
      "Epoch: 791\n",
      "train_loss = 88.0541\n",
      "test_loss = 77.1064\n",
      "****************************\n",
      "Epoch: 792\n",
      "train_loss = 87.9821\n",
      "test_loss = 76.7791\n",
      "****************************\n",
      "Epoch: 793\n",
      "train_loss = 88.3006\n",
      "test_loss = 77.9340\n",
      "****************************\n",
      "Epoch: 794\n",
      "train_loss = 90.4846\n",
      "test_loss = 81.7227\n",
      "****************************\n",
      "Epoch: 795\n",
      "train_loss = 88.9450\n",
      "test_loss = 79.3124\n",
      "****************************\n",
      "Epoch: 796\n",
      "train_loss = 88.8238\n",
      "test_loss = 74.8033\n",
      "****************************\n",
      "Epoch: 797\n",
      "train_loss = 87.9148\n",
      "test_loss = 76.2840\n",
      "****************************\n",
      "Epoch: 798\n",
      "train_loss = 87.9286\n",
      "test_loss = 75.7082\n",
      "****************************\n",
      "Epoch: 799\n",
      "train_loss = 89.4075\n",
      "test_loss = 74.7281\n",
      "****************************\n",
      "Epoch: 800\n",
      "train_loss = 87.9487\n",
      "test_loss = 75.6516\n",
      "****************************\n",
      "Epoch: 801\n",
      "train_loss = 88.0560\n",
      "test_loss = 77.3010\n",
      "****************************\n",
      "Epoch: 802\n",
      "train_loss = 88.0258\n",
      "test_loss = 75.4257\n",
      "****************************\n",
      "Epoch: 803\n",
      "train_loss = 87.9558\n",
      "test_loss = 75.9622\n",
      "****************************\n",
      "Epoch: 804\n",
      "train_loss = 88.1900\n",
      "test_loss = 75.1911\n",
      "****************************\n",
      "Epoch: 805\n",
      "train_loss = 87.9117\n",
      "test_loss = 76.0146\n",
      "****************************\n",
      "Epoch: 806\n",
      "train_loss = 88.0010\n",
      "test_loss = 76.9384\n",
      "****************************\n",
      "Epoch: 807\n",
      "train_loss = 88.4658\n",
      "test_loss = 78.3717\n",
      "****************************\n",
      "Epoch: 808\n",
      "train_loss = 89.0760\n",
      "test_loss = 79.2665\n",
      "****************************\n",
      "Epoch: 809\n",
      "train_loss = 88.1000\n",
      "test_loss = 75.4317\n",
      "****************************\n",
      "Epoch: 810\n",
      "train_loss = 88.0532\n",
      "test_loss = 75.3915\n",
      "****************************\n",
      "Epoch: 811\n",
      "train_loss = 88.0069\n",
      "test_loss = 75.3949\n",
      "****************************\n",
      "Epoch: 812\n",
      "train_loss = 89.0708\n",
      "test_loss = 79.4911\n",
      "****************************\n",
      "Epoch: 813\n",
      "train_loss = 89.3854\n",
      "test_loss = 74.7437\n",
      "****************************\n",
      "Epoch: 814\n",
      "train_loss = 88.0990\n",
      "test_loss = 76.6401\n",
      "****************************\n",
      "Epoch: 815\n",
      "train_loss = 88.0699\n",
      "test_loss = 76.4073\n",
      "****************************\n",
      "Epoch: 816\n",
      "train_loss = 88.0908\n",
      "test_loss = 75.2893\n",
      "****************************\n",
      "Epoch: 817\n",
      "train_loss = 88.0977\n",
      "test_loss = 75.4603\n",
      "****************************\n",
      "Epoch: 818\n",
      "train_loss = 88.8016\n",
      "test_loss = 74.8777\n",
      "****************************\n",
      "Epoch: 819\n",
      "train_loss = 88.2704\n",
      "test_loss = 77.6960\n",
      "****************************\n",
      "Epoch: 820\n",
      "train_loss = 88.0097\n",
      "test_loss = 76.7680\n",
      "****************************\n",
      "Epoch: 821\n",
      "train_loss = 88.4040\n",
      "test_loss = 77.8925\n",
      "****************************\n",
      "Epoch: 822\n",
      "train_loss = 87.9491\n",
      "test_loss = 75.7063\n",
      "****************************\n",
      "Epoch: 823\n",
      "train_loss = 88.1731\n",
      "test_loss = 75.1777\n",
      "****************************\n",
      "Epoch: 824\n",
      "train_loss = 87.9908\n",
      "test_loss = 75.6294\n",
      "****************************\n",
      "Epoch: 825\n",
      "train_loss = 87.9796\n",
      "test_loss = 75.5902\n",
      "****************************\n",
      "Epoch: 826\n",
      "train_loss = 87.9559\n",
      "test_loss = 76.7050\n",
      "****************************\n",
      "Epoch: 827\n",
      "train_loss = 87.9245\n",
      "test_loss = 75.7061\n",
      "****************************\n",
      "Epoch: 828\n",
      "train_loss = 87.9170\n",
      "test_loss = 75.9694\n",
      "****************************\n",
      "Epoch: 829\n",
      "train_loss = 88.4059\n",
      "test_loss = 74.9453\n",
      "****************************\n",
      "Epoch: 830\n",
      "train_loss = 87.9035\n",
      "test_loss = 76.4678\n",
      "****************************\n",
      "Epoch: 831\n",
      "train_loss = 88.1139\n",
      "test_loss = 75.2411\n",
      "****************************\n",
      "Epoch: 832\n",
      "train_loss = 89.9634\n",
      "test_loss = 74.7028\n",
      "****************************\n",
      "Epoch: 833\n",
      "train_loss = 88.0156\n",
      "test_loss = 75.3333\n",
      "****************************\n",
      "Epoch: 834\n",
      "train_loss = 87.9869\n",
      "test_loss = 76.7798\n",
      "****************************\n",
      "Epoch: 835\n",
      "train_loss = 88.4051\n",
      "test_loss = 78.3021\n",
      "****************************\n",
      "Epoch: 836\n",
      "train_loss = 87.8945\n",
      "test_loss = 76.2878\n",
      "****************************\n",
      "Epoch: 837\n",
      "train_loss = 88.3464\n",
      "test_loss = 77.9654\n",
      "****************************\n",
      "Epoch: 838\n",
      "train_loss = 87.8731\n",
      "test_loss = 76.3262\n",
      "****************************\n",
      "Epoch: 839\n",
      "train_loss = 87.9053\n",
      "test_loss = 75.5799\n",
      "****************************\n",
      "Epoch: 840\n",
      "train_loss = 88.7550\n",
      "test_loss = 78.9489\n",
      "****************************\n",
      "Epoch: 841\n",
      "train_loss = 87.9396\n",
      "test_loss = 75.4413\n",
      "****************************\n",
      "Epoch: 842\n",
      "train_loss = 87.8920\n",
      "test_loss = 76.5311\n",
      "****************************\n",
      "Epoch: 843\n",
      "train_loss = 88.0791\n",
      "test_loss = 75.1680\n",
      "****************************\n",
      "Epoch: 844\n",
      "train_loss = 87.8763\n",
      "test_loss = 75.7206\n",
      "****************************\n",
      "Epoch: 845\n",
      "train_loss = 88.4068\n",
      "test_loss = 78.1192\n",
      "****************************\n",
      "Epoch: 846\n",
      "train_loss = 88.0862\n",
      "test_loss = 77.1884\n",
      "****************************\n",
      "Epoch: 847\n",
      "train_loss = 88.8056\n",
      "test_loss = 74.6637\n",
      "****************************\n",
      "Epoch: 848\n",
      "train_loss = 87.9597\n",
      "test_loss = 75.7771\n",
      "****************************\n",
      "Epoch: 849\n",
      "train_loss = 88.3484\n",
      "test_loss = 74.9336\n",
      "****************************\n",
      "Epoch: 850\n",
      "train_loss = 88.0953\n",
      "test_loss = 77.0289\n",
      "****************************\n",
      "Epoch: 851\n",
      "train_loss = 87.8747\n",
      "test_loss = 76.1200\n",
      "****************************\n",
      "Epoch: 852\n",
      "train_loss = 87.8896\n",
      "test_loss = 76.0660\n",
      "****************************\n",
      "Epoch: 853\n",
      "train_loss = 87.9404\n",
      "test_loss = 75.8276\n",
      "****************************\n",
      "Epoch: 854\n",
      "train_loss = 88.8566\n",
      "test_loss = 74.7546\n",
      "****************************\n",
      "Epoch: 855\n",
      "train_loss = 88.5068\n",
      "test_loss = 77.8870\n",
      "****************************\n",
      "Epoch: 856\n",
      "train_loss = 95.4946\n",
      "test_loss = 77.6173\n",
      "****************************\n",
      "Epoch: 857\n",
      "train_loss = 88.6755\n",
      "test_loss = 74.8477\n",
      "****************************\n",
      "Epoch: 858\n",
      "train_loss = 90.3130\n",
      "test_loss = 81.4900\n",
      "****************************\n",
      "Epoch: 859\n",
      "train_loss = 88.1309\n",
      "test_loss = 77.2347\n",
      "****************************\n",
      "Epoch: 860\n",
      "train_loss = 89.1422\n",
      "test_loss = 79.5312\n",
      "****************************\n",
      "Epoch: 861\n",
      "train_loss = 87.9257\n",
      "test_loss = 75.8805\n",
      "****************************\n",
      "Epoch: 862\n",
      "train_loss = 88.0302\n",
      "test_loss = 75.3535\n",
      "****************************\n",
      "Epoch: 863\n",
      "train_loss = 88.2170\n",
      "test_loss = 75.0218\n",
      "****************************\n",
      "Epoch: 864\n",
      "train_loss = 90.7487\n",
      "test_loss = 82.1788\n",
      "****************************\n",
      "Epoch: 865\n",
      "train_loss = 89.1433\n",
      "test_loss = 79.6742\n",
      "****************************\n",
      "Epoch: 866\n",
      "train_loss = 88.1225\n",
      "test_loss = 75.2004\n",
      "****************************\n",
      "Epoch: 867\n",
      "train_loss = 87.9201\n",
      "test_loss = 76.7578\n",
      "****************************\n",
      "Epoch: 868\n",
      "train_loss = 87.8402\n",
      "test_loss = 76.2112\n",
      "****************************\n",
      "Epoch: 869\n",
      "train_loss = 88.6205\n",
      "test_loss = 78.6122\n",
      "****************************\n",
      "Epoch: 870\n",
      "train_loss = 88.3073\n",
      "test_loss = 78.0085\n",
      "****************************\n",
      "Epoch: 871\n",
      "train_loss = 88.6284\n",
      "test_loss = 78.6651\n",
      "****************************\n",
      "Epoch: 872\n",
      "train_loss = 87.8598\n",
      "test_loss = 76.4151\n",
      "****************************\n",
      "Epoch: 873\n",
      "train_loss = 88.1822\n",
      "test_loss = 75.0554\n",
      "****************************\n",
      "Epoch: 874\n",
      "train_loss = 87.8667\n",
      "test_loss = 75.8139\n",
      "****************************\n",
      "Epoch: 875\n",
      "train_loss = 88.4255\n",
      "test_loss = 78.0966\n",
      "****************************\n",
      "Epoch: 876\n",
      "train_loss = 88.6834\n",
      "test_loss = 74.6443\n",
      "****************************\n",
      "Epoch: 877\n",
      "train_loss = 87.9131\n",
      "test_loss = 76.4752\n",
      "****************************\n",
      "Epoch: 878\n",
      "train_loss = 87.8609\n",
      "test_loss = 76.0237\n",
      "****************************\n",
      "Epoch: 879\n",
      "train_loss = 88.1682\n",
      "test_loss = 74.9025\n",
      "****************************\n",
      "Epoch: 880\n",
      "train_loss = 88.2725\n",
      "test_loss = 74.8307\n",
      "****************************\n",
      "Epoch: 881\n",
      "train_loss = 88.6967\n",
      "test_loss = 78.7922\n",
      "****************************\n",
      "Epoch: 882\n",
      "train_loss = 87.8004\n",
      "test_loss = 75.7726\n",
      "****************************\n",
      "Epoch: 883\n",
      "train_loss = 88.2753\n",
      "test_loss = 74.7981\n",
      "****************************\n",
      "Epoch: 884\n",
      "train_loss = 87.9540\n",
      "test_loss = 76.8100\n",
      "****************************\n",
      "Epoch: 885\n",
      "train_loss = 87.8029\n",
      "test_loss = 76.1162\n",
      "****************************\n",
      "Epoch: 886\n",
      "train_loss = 88.1437\n",
      "test_loss = 77.4774\n",
      "****************************\n",
      "Epoch: 887\n",
      "train_loss = 88.3488\n",
      "test_loss = 74.7910\n",
      "****************************\n",
      "Epoch: 888\n",
      "train_loss = 87.8571\n",
      "test_loss = 75.5297\n",
      "****************************\n",
      "Epoch: 889\n",
      "train_loss = 88.0499\n",
      "test_loss = 77.1723\n",
      "****************************\n",
      "Epoch: 890\n",
      "train_loss = 88.2663\n",
      "test_loss = 74.8222\n",
      "****************************\n",
      "Epoch: 891\n",
      "train_loss = 87.8856\n",
      "test_loss = 76.6001\n",
      "****************************\n",
      "Epoch: 892\n",
      "train_loss = 87.9651\n",
      "test_loss = 75.2633\n",
      "****************************\n",
      "Epoch: 893\n",
      "train_loss = 88.5515\n",
      "test_loss = 78.2692\n",
      "****************************\n",
      "Epoch: 894\n",
      "train_loss = 87.9358\n",
      "test_loss = 76.5033\n",
      "****************************\n",
      "Epoch: 895\n",
      "train_loss = 87.9399\n",
      "test_loss = 75.5020\n",
      "****************************\n",
      "Epoch: 896\n",
      "train_loss = 88.9835\n",
      "test_loss = 74.5806\n",
      "****************************\n",
      "Epoch: 897\n",
      "train_loss = 88.3665\n",
      "test_loss = 74.7971\n",
      "****************************\n",
      "Epoch: 898\n",
      "train_loss = 87.8176\n",
      "test_loss = 76.1971\n",
      "****************************\n",
      "Epoch: 899\n",
      "train_loss = 88.2700\n",
      "test_loss = 77.9028\n",
      "****************************\n",
      "Epoch: 900\n",
      "train_loss = 87.8707\n",
      "test_loss = 75.6431\n",
      "****************************\n",
      "Epoch: 901\n",
      "train_loss = 87.8077\n",
      "test_loss = 75.7657\n",
      "****************************\n",
      "Epoch: 902\n",
      "train_loss = 88.0692\n",
      "test_loss = 75.0159\n",
      "****************************\n",
      "Epoch: 903\n",
      "train_loss = 87.8442\n",
      "test_loss = 75.5411\n",
      "****************************\n",
      "Epoch: 904\n",
      "train_loss = 88.3336\n",
      "test_loss = 74.7849\n",
      "****************************\n",
      "Epoch: 905\n",
      "train_loss = 87.8952\n",
      "test_loss = 75.5122\n",
      "****************************\n",
      "Epoch: 906\n",
      "train_loss = 91.0546\n",
      "test_loss = 82.4653\n",
      "****************************\n",
      "Epoch: 907\n",
      "train_loss = 87.9875\n",
      "test_loss = 75.2555\n",
      "****************************\n",
      "Epoch: 908\n",
      "train_loss = 87.8634\n",
      "test_loss = 76.5813\n",
      "****************************\n",
      "Epoch: 909\n",
      "train_loss = 87.8936\n",
      "test_loss = 76.3907\n",
      "****************************\n",
      "Epoch: 910\n",
      "train_loss = 87.9715\n",
      "test_loss = 76.7841\n",
      "****************************\n",
      "Epoch: 911\n",
      "train_loss = 87.8223\n",
      "test_loss = 76.2682\n",
      "****************************\n",
      "Epoch: 912\n",
      "train_loss = 87.9409\n",
      "test_loss = 75.1987\n",
      "****************************\n",
      "Epoch: 913\n",
      "train_loss = 87.9718\n",
      "test_loss = 76.9380\n",
      "****************************\n",
      "Epoch: 914\n",
      "train_loss = 87.8156\n",
      "test_loss = 75.5503\n",
      "****************************\n",
      "Epoch: 915\n",
      "train_loss = 88.0582\n",
      "test_loss = 77.2670\n",
      "****************************\n",
      "Epoch: 916\n",
      "train_loss = 88.0686\n",
      "test_loss = 75.0994\n",
      "****************************\n",
      "Epoch: 917\n",
      "train_loss = 87.7784\n",
      "test_loss = 75.8112\n",
      "****************************\n",
      "Epoch: 918\n",
      "train_loss = 87.7814\n",
      "test_loss = 75.7406\n",
      "****************************\n",
      "Epoch: 919\n",
      "train_loss = 88.1579\n",
      "test_loss = 74.8684\n",
      "****************************\n",
      "Epoch: 920\n",
      "train_loss = 87.8291\n",
      "test_loss = 75.4701\n",
      "****************************\n",
      "Epoch: 921\n",
      "train_loss = 89.7260\n",
      "test_loss = 74.5502\n",
      "****************************\n",
      "Epoch: 922\n",
      "train_loss = 88.0227\n",
      "test_loss = 75.0050\n",
      "****************************\n",
      "Epoch: 923\n",
      "train_loss = 87.8470\n",
      "test_loss = 75.4370\n",
      "****************************\n",
      "Epoch: 924\n",
      "train_loss = 87.8512\n",
      "test_loss = 76.5466\n",
      "****************************\n",
      "Epoch: 925\n",
      "train_loss = 87.8487\n",
      "test_loss = 76.6715\n",
      "****************************\n",
      "Epoch: 926\n",
      "train_loss = 89.4591\n",
      "test_loss = 75.1763\n",
      "****************************\n",
      "Epoch: 927\n",
      "train_loss = 87.8801\n",
      "test_loss = 75.7670\n",
      "****************************\n",
      "Epoch: 928\n",
      "train_loss = 87.8321\n",
      "test_loss = 75.9247\n",
      "****************************\n",
      "Epoch: 929\n",
      "train_loss = 87.9019\n",
      "test_loss = 75.3729\n",
      "****************************\n",
      "Epoch: 930\n",
      "train_loss = 87.7804\n",
      "test_loss = 76.0273\n",
      "****************************\n",
      "Epoch: 931\n",
      "train_loss = 88.0061\n",
      "test_loss = 77.0274\n",
      "****************************\n",
      "Epoch: 932\n",
      "train_loss = 88.6021\n",
      "test_loss = 74.6746\n",
      "****************************\n",
      "Epoch: 933\n",
      "train_loss = 88.0589\n",
      "test_loss = 74.9825\n",
      "****************************\n",
      "Epoch: 934\n",
      "train_loss = 87.8260\n",
      "test_loss = 76.4465\n",
      "****************************\n",
      "Epoch: 935\n",
      "train_loss = 88.4892\n",
      "test_loss = 77.8022\n",
      "****************************\n",
      "Epoch: 936\n",
      "train_loss = 88.1897\n",
      "test_loss = 77.6218\n",
      "****************************\n",
      "Epoch: 937\n",
      "train_loss = 87.8144\n",
      "test_loss = 75.8684\n",
      "****************************\n",
      "Epoch: 938\n",
      "train_loss = 87.8045\n",
      "test_loss = 76.2013\n",
      "****************************\n",
      "Epoch: 939\n",
      "train_loss = 92.9124\n",
      "test_loss = 85.5713\n",
      "****************************\n",
      "Epoch: 940\n",
      "train_loss = 88.1628\n",
      "test_loss = 74.8898\n",
      "****************************\n",
      "Epoch: 941\n",
      "train_loss = 88.5940\n",
      "test_loss = 75.3610\n",
      "****************************\n",
      "Epoch: 942\n",
      "train_loss = 87.8150\n",
      "test_loss = 75.9986\n",
      "****************************\n",
      "Epoch: 943\n",
      "train_loss = 87.8059\n",
      "test_loss = 75.9108\n",
      "****************************\n",
      "Epoch: 944\n",
      "train_loss = 88.0641\n",
      "test_loss = 77.0679\n",
      "****************************\n",
      "Epoch: 945\n",
      "train_loss = 87.9317\n",
      "test_loss = 76.7998\n",
      "****************************\n",
      "Epoch: 946\n",
      "train_loss = 88.4232\n",
      "test_loss = 78.1503\n",
      "****************************\n",
      "Epoch: 947\n",
      "train_loss = 87.7929\n",
      "test_loss = 75.7991\n",
      "****************************\n",
      "Epoch: 948\n",
      "train_loss = 87.8096\n",
      "test_loss = 75.8870\n",
      "****************************\n",
      "Epoch: 949\n",
      "train_loss = 87.8476\n",
      "test_loss = 75.8801\n",
      "****************************\n",
      "Epoch: 950\n",
      "train_loss = 87.8541\n",
      "test_loss = 76.4880\n",
      "****************************\n",
      "Epoch: 951\n",
      "train_loss = 88.1450\n",
      "test_loss = 74.8901\n",
      "****************************\n",
      "Epoch: 952\n",
      "train_loss = 87.8516\n",
      "test_loss = 76.5979\n",
      "****************************\n",
      "Epoch: 953\n",
      "train_loss = 88.5306\n",
      "test_loss = 74.6913\n",
      "****************************\n",
      "Epoch: 954\n",
      "train_loss = 88.0887\n",
      "test_loss = 75.1646\n",
      "****************************\n",
      "Epoch: 955\n",
      "train_loss = 88.2603\n",
      "test_loss = 77.3487\n",
      "****************************\n",
      "Epoch: 956\n",
      "train_loss = 88.1502\n",
      "test_loss = 77.2571\n",
      "****************************\n",
      "Epoch: 957\n",
      "train_loss = 87.9081\n",
      "test_loss = 76.5964\n",
      "****************************\n",
      "Epoch: 958\n",
      "train_loss = 88.1391\n",
      "test_loss = 74.9327\n",
      "****************************\n",
      "Epoch: 959\n",
      "train_loss = 88.8114\n",
      "test_loss = 74.6230\n",
      "****************************\n",
      "Epoch: 960\n",
      "train_loss = 87.9627\n",
      "test_loss = 76.7061\n",
      "****************************\n",
      "Epoch: 961\n",
      "train_loss = 87.9433\n",
      "test_loss = 75.5591\n",
      "****************************\n",
      "Epoch: 962\n",
      "train_loss = 88.0552\n",
      "test_loss = 77.2005\n",
      "****************************\n",
      "Epoch: 963\n",
      "train_loss = 87.8680\n",
      "test_loss = 75.5800\n",
      "****************************\n",
      "Epoch: 964\n",
      "train_loss = 87.7992\n",
      "test_loss = 75.8854\n",
      "****************************\n",
      "Epoch: 965\n",
      "train_loss = 88.0650\n",
      "test_loss = 74.9992\n",
      "****************************\n",
      "Epoch: 966\n",
      "train_loss = 87.8652\n",
      "test_loss = 76.6088\n",
      "****************************\n",
      "Epoch: 967\n",
      "train_loss = 88.3701\n",
      "test_loss = 78.1184\n",
      "****************************\n",
      "Epoch: 968\n",
      "train_loss = 87.8106\n",
      "test_loss = 76.3626\n",
      "****************************\n",
      "Epoch: 969\n",
      "train_loss = 89.6029\n",
      "test_loss = 74.4881\n",
      "****************************\n",
      "Epoch: 970\n",
      "train_loss = 88.0093\n",
      "test_loss = 76.8808\n",
      "****************************\n",
      "Epoch: 971\n",
      "train_loss = 88.8260\n",
      "test_loss = 79.1051\n",
      "****************************\n",
      "Epoch: 972\n",
      "train_loss = 89.2570\n",
      "test_loss = 79.9066\n",
      "****************************\n",
      "Epoch: 973\n",
      "train_loss = 87.8802\n",
      "test_loss = 75.2930\n",
      "****************************\n",
      "Epoch: 974\n",
      "train_loss = 87.8578\n",
      "test_loss = 76.1381\n",
      "****************************\n",
      "Epoch: 975\n",
      "train_loss = 87.8306\n",
      "test_loss = 75.5821\n",
      "****************************\n",
      "Epoch: 976\n",
      "train_loss = 88.0184\n",
      "test_loss = 74.9774\n",
      "****************************\n",
      "Epoch: 977\n",
      "train_loss = 87.8512\n",
      "test_loss = 75.4190\n",
      "****************************\n",
      "Epoch: 978\n",
      "train_loss = 88.0799\n",
      "test_loss = 74.9440\n",
      "****************************\n",
      "Epoch: 979\n",
      "train_loss = 87.9108\n",
      "test_loss = 75.0811\n",
      "****************************\n",
      "Epoch: 980\n",
      "train_loss = 88.3730\n",
      "test_loss = 77.6919\n",
      "****************************\n",
      "Epoch: 981\n",
      "train_loss = 88.5358\n",
      "test_loss = 78.0582\n",
      "****************************\n",
      "Epoch: 982\n",
      "train_loss = 88.7917\n",
      "test_loss = 74.5748\n",
      "****************************\n",
      "Epoch: 983\n",
      "train_loss = 88.4027\n",
      "test_loss = 74.7062\n",
      "****************************\n",
      "Epoch: 984\n",
      "train_loss = 87.8615\n",
      "test_loss = 76.3452\n",
      "****************************\n",
      "Epoch: 985\n",
      "train_loss = 88.2449\n",
      "test_loss = 77.8587\n",
      "****************************\n",
      "Epoch: 986\n",
      "train_loss = 89.9840\n",
      "test_loss = 81.1113\n",
      "****************************\n",
      "Epoch: 987\n",
      "train_loss = 88.8701\n",
      "test_loss = 75.2532\n",
      "****************************\n",
      "Epoch: 988\n",
      "train_loss = 88.3844\n",
      "test_loss = 75.1496\n",
      "****************************\n",
      "Epoch: 989\n",
      "train_loss = 88.4242\n",
      "test_loss = 74.8669\n",
      "****************************\n",
      "Epoch: 990\n",
      "train_loss = 88.0077\n",
      "test_loss = 75.0994\n",
      "****************************\n",
      "Epoch: 991\n",
      "train_loss = 87.9463\n",
      "test_loss = 75.2069\n",
      "****************************\n",
      "Epoch: 992\n",
      "train_loss = 88.1324\n",
      "test_loss = 74.8724\n",
      "****************************\n",
      "Epoch: 993\n",
      "train_loss = 88.1766\n",
      "test_loss = 74.8571\n",
      "****************************\n",
      "Epoch: 994\n",
      "train_loss = 87.7810\n",
      "test_loss = 75.7439\n",
      "****************************\n",
      "Epoch: 995\n",
      "train_loss = 87.9598\n",
      "test_loss = 76.8624\n",
      "****************************\n",
      "Epoch: 996\n",
      "train_loss = 87.7854\n",
      "test_loss = 75.7860\n",
      "****************************\n",
      "Epoch: 997\n",
      "train_loss = 87.7902\n",
      "test_loss = 75.9933\n",
      "****************************\n",
      "Epoch: 998\n",
      "train_loss = 87.8181\n",
      "test_loss = 75.3132\n",
      "****************************\n",
      "Epoch: 999\n",
      "train_loss = 88.3026\n",
      "test_loss = 74.6893\n",
      "****************************\n",
      "Epoch: 1000\n",
      "train_loss = 87.7473\n",
      "test_loss = 75.9894\n",
      "****************************\n",
      "Epoch: 1001\n",
      "train_loss = 88.5407\n",
      "test_loss = 74.5933\n",
      "****************************\n",
      "Epoch: 1002\n",
      "train_loss = 87.8425\n",
      "test_loss = 76.3959\n",
      "****************************\n",
      "Epoch: 1003\n",
      "train_loss = 88.0342\n",
      "test_loss = 75.0076\n",
      "****************************\n",
      "Epoch: 1004\n",
      "train_loss = 91.8577\n",
      "test_loss = 83.9893\n",
      "****************************\n",
      "Epoch: 1005\n",
      "train_loss = 87.7448\n",
      "test_loss = 75.7694\n",
      "****************************\n",
      "Epoch: 1006\n",
      "train_loss = 87.7434\n",
      "test_loss = 75.8215\n",
      "****************************\n",
      "Epoch: 1007\n",
      "train_loss = 87.7269\n",
      "test_loss = 75.8892\n",
      "****************************\n",
      "Epoch: 1008\n",
      "train_loss = 87.9656\n",
      "test_loss = 77.0705\n",
      "****************************\n",
      "Epoch: 1009\n",
      "train_loss = 87.9705\n",
      "test_loss = 77.0609\n",
      "****************************\n",
      "Epoch: 1010\n",
      "train_loss = 88.6156\n",
      "test_loss = 78.5755\n",
      "****************************\n",
      "Epoch: 1011\n",
      "train_loss = 96.9327\n",
      "test_loss = 77.7924\n",
      "****************************\n",
      "Epoch: 1012\n",
      "train_loss = 89.1541\n",
      "test_loss = 74.5056\n",
      "****************************\n",
      "Epoch: 1013\n",
      "train_loss = 88.1356\n",
      "test_loss = 77.2914\n",
      "****************************\n",
      "Epoch: 1014\n",
      "train_loss = 87.9324\n",
      "test_loss = 76.6799\n",
      "****************************\n",
      "Epoch: 1015\n",
      "train_loss = 87.7843\n",
      "test_loss = 75.7650\n",
      "****************************\n",
      "Epoch: 1016\n",
      "train_loss = 88.4109\n",
      "test_loss = 78.0002\n",
      "****************************\n",
      "Epoch: 1017\n",
      "train_loss = 87.8982\n",
      "test_loss = 75.2193\n",
      "****************************\n",
      "Epoch: 1018\n",
      "train_loss = 87.7842\n",
      "test_loss = 76.2206\n",
      "****************************\n",
      "Epoch: 1019\n",
      "train_loss = 88.4307\n",
      "test_loss = 74.6267\n",
      "****************************\n",
      "Epoch: 1020\n",
      "train_loss = 87.7978\n",
      "test_loss = 76.4673\n",
      "****************************\n",
      "Epoch: 1021\n",
      "train_loss = 87.8238\n",
      "test_loss = 76.4407\n",
      "****************************\n",
      "Epoch: 1022\n",
      "train_loss = 87.7999\n",
      "test_loss = 76.3310\n",
      "****************************\n",
      "Epoch: 1023\n",
      "train_loss = 87.7679\n",
      "test_loss = 75.5499\n",
      "****************************\n",
      "Epoch: 1024\n",
      "train_loss = 88.2338\n",
      "test_loss = 74.7824\n",
      "****************************\n",
      "Epoch: 1025\n",
      "train_loss = 88.0625\n",
      "test_loss = 74.9179\n",
      "****************************\n",
      "Epoch: 1026\n",
      "train_loss = 87.8886\n",
      "test_loss = 75.1855\n",
      "****************************\n",
      "Epoch: 1027\n",
      "train_loss = 87.8700\n",
      "test_loss = 75.2001\n",
      "****************************\n",
      "Epoch: 1028\n",
      "train_loss = 87.9067\n",
      "test_loss = 77.0429\n",
      "****************************\n",
      "Epoch: 1029\n",
      "train_loss = 87.7584\n",
      "test_loss = 76.1783\n",
      "****************************\n",
      "Epoch: 1030\n",
      "train_loss = 88.2675\n",
      "test_loss = 74.7587\n",
      "****************************\n",
      "Epoch: 1031\n",
      "train_loss = 87.9501\n",
      "test_loss = 76.7587\n",
      "****************************\n",
      "Epoch: 1032\n",
      "train_loss = 88.0071\n",
      "test_loss = 77.1196\n",
      "****************************\n",
      "Epoch: 1033\n",
      "train_loss = 87.7652\n",
      "test_loss = 76.0468\n",
      "****************************\n",
      "Epoch: 1034\n",
      "train_loss = 87.9402\n",
      "test_loss = 75.0607\n",
      "****************************\n",
      "Epoch: 1035\n",
      "train_loss = 87.7670\n",
      "test_loss = 75.8140\n",
      "****************************\n",
      "Epoch: 1036\n",
      "train_loss = 87.8120\n",
      "test_loss = 76.3468\n",
      "****************************\n",
      "Epoch: 1037\n",
      "train_loss = 87.8078\n",
      "test_loss = 75.3017\n",
      "****************************\n",
      "Epoch: 1038\n",
      "train_loss = 89.0204\n",
      "test_loss = 79.1322\n",
      "****************************\n",
      "Epoch: 1039\n",
      "train_loss = 87.8754\n",
      "test_loss = 75.3590\n",
      "****************************\n",
      "Epoch: 1040\n",
      "train_loss = 87.7962\n",
      "test_loss = 76.2863\n",
      "****************************\n",
      "Epoch: 1041\n",
      "train_loss = 87.9715\n",
      "test_loss = 75.0048\n",
      "****************************\n",
      "Epoch: 1042\n",
      "train_loss = 88.3580\n",
      "test_loss = 74.6970\n",
      "****************************\n",
      "Epoch: 1043\n",
      "train_loss = 89.6358\n",
      "test_loss = 80.3477\n",
      "****************************\n",
      "Epoch: 1044\n",
      "train_loss = 88.2880\n",
      "test_loss = 77.9095\n",
      "****************************\n",
      "Epoch: 1045\n",
      "train_loss = 88.4559\n",
      "test_loss = 74.6267\n",
      "****************************\n",
      "Epoch: 1046\n",
      "train_loss = 88.1689\n",
      "test_loss = 77.3174\n",
      "****************************\n",
      "Epoch: 1047\n",
      "train_loss = 88.2691\n",
      "test_loss = 77.7070\n",
      "****************************\n",
      "Epoch: 1048\n",
      "train_loss = 87.7534\n",
      "test_loss = 76.0125\n",
      "****************************\n",
      "Epoch: 1049\n",
      "train_loss = 87.8474\n",
      "test_loss = 76.4589\n",
      "****************************\n",
      "Epoch: 1050\n",
      "train_loss = 88.8397\n",
      "test_loss = 74.5047\n",
      "****************************\n",
      "Epoch: 1051\n",
      "train_loss = 88.4759\n",
      "test_loss = 74.5999\n",
      "****************************\n",
      "Epoch: 1052\n",
      "train_loss = 88.9837\n",
      "test_loss = 74.4904\n",
      "****************************\n",
      "Epoch: 1053\n",
      "train_loss = 87.7919\n",
      "test_loss = 75.4544\n",
      "****************************\n",
      "Epoch: 1054\n",
      "train_loss = 89.7222\n",
      "test_loss = 80.5155\n",
      "****************************\n",
      "Epoch: 1055\n",
      "train_loss = 88.1591\n",
      "test_loss = 77.0549\n",
      "****************************\n",
      "Epoch: 1056\n",
      "train_loss = 88.0951\n",
      "test_loss = 75.0644\n",
      "****************************\n",
      "Epoch: 1057\n",
      "train_loss = 88.1511\n",
      "test_loss = 74.8935\n",
      "****************************\n",
      "Epoch: 1058\n",
      "train_loss = 87.7745\n",
      "test_loss = 75.7386\n",
      "****************************\n",
      "Epoch: 1059\n",
      "train_loss = 87.8032\n",
      "test_loss = 75.4381\n",
      "****************************\n",
      "Epoch: 1060\n",
      "train_loss = 88.6949\n",
      "test_loss = 74.6018\n",
      "****************************\n",
      "Epoch: 1061\n",
      "train_loss = 88.6264\n",
      "test_loss = 74.6074\n",
      "****************************\n",
      "Epoch: 1062\n",
      "train_loss = 88.0527\n",
      "test_loss = 74.9739\n",
      "****************************\n",
      "Epoch: 1063\n",
      "train_loss = 87.9739\n",
      "test_loss = 75.0103\n",
      "****************************\n",
      "Epoch: 1064\n",
      "train_loss = 87.8949\n",
      "test_loss = 76.6390\n",
      "****************************\n",
      "Epoch: 1065\n",
      "train_loss = 88.9032\n",
      "test_loss = 79.1311\n",
      "****************************\n",
      "Epoch: 1066\n",
      "train_loss = 89.5292\n",
      "test_loss = 74.5655\n",
      "****************************\n",
      "Epoch: 1067\n",
      "train_loss = 87.9926\n",
      "test_loss = 77.2219\n",
      "****************************\n",
      "Epoch: 1068\n",
      "train_loss = 89.9261\n",
      "test_loss = 80.8122\n",
      "****************************\n",
      "Epoch: 1069\n",
      "train_loss = 87.9181\n",
      "test_loss = 75.1128\n",
      "****************************\n",
      "Epoch: 1070\n",
      "train_loss = 90.4063\n",
      "test_loss = 81.7220\n",
      "****************************\n",
      "Epoch: 1071\n",
      "train_loss = 88.1247\n",
      "test_loss = 74.9574\n",
      "****************************\n",
      "Epoch: 1072\n",
      "train_loss = 87.7978\n",
      "test_loss = 75.5354\n",
      "****************************\n",
      "Epoch: 1073\n",
      "train_loss = 88.0268\n",
      "test_loss = 77.1275\n",
      "****************************\n",
      "Epoch: 1074\n",
      "train_loss = 88.5474\n",
      "test_loss = 74.6955\n",
      "****************************\n",
      "Epoch: 1075\n",
      "train_loss = 87.8191\n",
      "test_loss = 76.3307\n",
      "****************************\n",
      "Epoch: 1076\n",
      "train_loss = 87.8055\n",
      "test_loss = 75.6352\n",
      "****************************\n",
      "Epoch: 1077\n",
      "train_loss = 88.1138\n",
      "test_loss = 74.9493\n",
      "****************************\n",
      "Epoch: 1078\n",
      "train_loss = 87.9168\n",
      "test_loss = 75.2242\n",
      "****************************\n",
      "Epoch: 1079\n",
      "train_loss = 88.2188\n",
      "test_loss = 74.8342\n",
      "****************************\n",
      "Epoch: 1080\n",
      "train_loss = 88.6459\n",
      "test_loss = 78.7436\n",
      "****************************\n",
      "Epoch: 1081\n",
      "train_loss = 88.3671\n",
      "test_loss = 74.7209\n",
      "****************************\n",
      "Epoch: 1082\n",
      "train_loss = 89.1216\n",
      "test_loss = 79.5048\n",
      "****************************\n",
      "Epoch: 1083\n",
      "train_loss = 89.2329\n",
      "test_loss = 79.6689\n",
      "****************************\n",
      "Epoch: 1084\n",
      "train_loss = 87.7859\n",
      "test_loss = 75.6479\n",
      "****************************\n",
      "Epoch: 1085\n",
      "train_loss = 88.0290\n",
      "test_loss = 77.1177\n",
      "****************************\n",
      "Epoch: 1086\n",
      "train_loss = 90.0895\n",
      "test_loss = 81.5010\n",
      "****************************\n",
      "Epoch: 1087\n",
      "train_loss = 88.1196\n",
      "test_loss = 74.8681\n",
      "****************************\n",
      "Epoch: 1088\n",
      "train_loss = 87.8376\n",
      "test_loss = 75.3344\n",
      "****************************\n",
      "Epoch: 1089\n",
      "train_loss = 87.8967\n",
      "test_loss = 75.1295\n",
      "****************************\n",
      "Epoch: 1090\n",
      "train_loss = 88.0732\n",
      "test_loss = 74.8539\n",
      "****************************\n",
      "Epoch: 1091\n",
      "train_loss = 88.9461\n",
      "test_loss = 74.4416\n",
      "****************************\n",
      "Epoch: 1092\n",
      "train_loss = 87.7488\n",
      "test_loss = 76.1531\n",
      "****************************\n",
      "Epoch: 1093\n",
      "train_loss = 88.3484\n",
      "test_loss = 77.7466\n",
      "****************************\n",
      "Epoch: 1094\n",
      "train_loss = 87.9698\n",
      "test_loss = 75.1862\n",
      "****************************\n",
      "Epoch: 1095\n",
      "train_loss = 87.9301\n",
      "test_loss = 76.5492\n",
      "****************************\n",
      "Epoch: 1096\n",
      "train_loss = 87.8032\n",
      "test_loss = 75.3040\n",
      "****************************\n",
      "Epoch: 1097\n",
      "train_loss = 87.8499\n",
      "test_loss = 75.3614\n",
      "****************************\n",
      "Epoch: 1098\n",
      "train_loss = 87.9228\n",
      "test_loss = 76.6524\n",
      "****************************\n",
      "Epoch: 1099\n",
      "train_loss = 88.0844\n",
      "test_loss = 74.9235\n",
      "****************************\n",
      "Epoch: 1100\n",
      "train_loss = 89.2588\n",
      "test_loss = 79.8743\n",
      "****************************\n",
      "Epoch: 1101\n",
      "train_loss = 87.9122\n",
      "test_loss = 75.0973\n",
      "****************************\n",
      "Epoch: 1102\n",
      "train_loss = 87.8761\n",
      "test_loss = 75.1679\n",
      "****************************\n",
      "Epoch: 1103\n",
      "train_loss = 87.7732\n",
      "test_loss = 75.5478\n",
      "****************************\n",
      "Epoch: 1104\n",
      "train_loss = 87.7825\n",
      "test_loss = 75.9310\n",
      "****************************\n",
      "Epoch: 1105\n",
      "train_loss = 88.0264\n",
      "test_loss = 77.1170\n",
      "****************************\n",
      "Epoch: 1106\n",
      "train_loss = 88.1398\n",
      "test_loss = 74.9526\n",
      "****************************\n",
      "Epoch: 1107\n",
      "train_loss = 88.0516\n",
      "test_loss = 74.9770\n",
      "****************************\n",
      "Epoch: 1108\n",
      "train_loss = 90.4336\n",
      "test_loss = 81.8902\n",
      "****************************\n",
      "Epoch: 1109\n",
      "train_loss = 88.3485\n",
      "test_loss = 74.7422\n",
      "****************************\n",
      "Epoch: 1110\n",
      "train_loss = 87.9295\n",
      "test_loss = 75.3197\n",
      "****************************\n",
      "Epoch: 1111\n",
      "train_loss = 87.7830\n",
      "test_loss = 76.3635\n",
      "****************************\n",
      "Epoch: 1112\n",
      "train_loss = 90.1111\n",
      "test_loss = 74.5484\n",
      "****************************\n",
      "Epoch: 1113\n",
      "train_loss = 87.7507\n",
      "test_loss = 75.5932\n",
      "****************************\n",
      "Epoch: 1114\n",
      "train_loss = 87.7256\n",
      "test_loss = 75.6322\n",
      "****************************\n",
      "Epoch: 1115\n",
      "train_loss = 87.7661\n",
      "test_loss = 76.2703\n",
      "****************************\n",
      "Epoch: 1116\n",
      "train_loss = 87.7676\n",
      "test_loss = 76.3493\n",
      "****************************\n",
      "Epoch: 1117\n",
      "train_loss = 87.7496\n",
      "test_loss = 75.9202\n",
      "****************************\n",
      "Epoch: 1118\n",
      "train_loss = 87.7787\n",
      "test_loss = 75.2692\n",
      "****************************\n",
      "Epoch: 1119\n",
      "train_loss = 88.0699\n",
      "test_loss = 74.8366\n",
      "****************************\n",
      "Epoch: 1120\n",
      "train_loss = 88.6027\n",
      "test_loss = 74.5352\n",
      "****************************\n",
      "Epoch: 1121\n",
      "train_loss = 88.1471\n",
      "test_loss = 74.7376\n",
      "****************************\n",
      "Epoch: 1122\n",
      "train_loss = 87.9168\n",
      "test_loss = 75.0585\n",
      "****************************\n",
      "Epoch: 1123\n",
      "train_loss = 88.0408\n",
      "test_loss = 74.8442\n",
      "****************************\n",
      "Epoch: 1124\n",
      "train_loss = 88.1581\n",
      "test_loss = 77.5982\n",
      "****************************\n",
      "Epoch: 1125\n",
      "train_loss = 87.8107\n",
      "test_loss = 75.2577\n",
      "****************************\n",
      "Epoch: 1126\n",
      "train_loss = 88.3223\n",
      "test_loss = 74.6441\n",
      "****************************\n",
      "Epoch: 1127\n",
      "train_loss = 91.7443\n",
      "test_loss = 83.5986\n",
      "****************************\n",
      "Epoch: 1128\n",
      "train_loss = 90.9705\n",
      "test_loss = 82.3597\n",
      "****************************\n",
      "Epoch: 1129\n",
      "train_loss = 88.2370\n",
      "test_loss = 77.4296\n",
      "****************************\n",
      "Epoch: 1130\n",
      "train_loss = 87.7750\n",
      "test_loss = 75.3548\n",
      "****************************\n",
      "Epoch: 1131\n",
      "train_loss = 87.7430\n",
      "test_loss = 75.8351\n",
      "****************************\n",
      "Epoch: 1132\n",
      "train_loss = 88.6578\n",
      "test_loss = 74.4695\n",
      "****************************\n",
      "Epoch: 1133\n",
      "train_loss = 87.8161\n",
      "test_loss = 76.3032\n",
      "****************************\n",
      "Epoch: 1134\n",
      "train_loss = 87.8996\n",
      "test_loss = 75.0379\n",
      "****************************\n",
      "Epoch: 1135\n",
      "train_loss = 87.9049\n",
      "test_loss = 76.8264\n",
      "****************************\n",
      "Epoch: 1136\n",
      "train_loss = 87.7831\n",
      "test_loss = 75.4163\n",
      "****************************\n",
      "Epoch: 1137\n",
      "train_loss = 88.1386\n",
      "test_loss = 77.4960\n",
      "****************************\n",
      "Epoch: 1138\n",
      "train_loss = 89.8827\n",
      "test_loss = 81.0978\n",
      "****************************\n",
      "Epoch: 1139\n",
      "train_loss = 87.7947\n",
      "test_loss = 76.4914\n",
      "****************************\n",
      "Epoch: 1140\n",
      "train_loss = 87.9433\n",
      "test_loss = 74.9523\n",
      "****************************\n",
      "Epoch: 1141\n",
      "train_loss = 87.7985\n",
      "test_loss = 75.3889\n",
      "****************************\n",
      "Epoch: 1142\n",
      "train_loss = 89.7318\n",
      "test_loss = 74.4724\n",
      "****************************\n",
      "Epoch: 1143\n",
      "train_loss = 87.9460\n",
      "test_loss = 77.0568\n",
      "****************************\n",
      "Epoch: 1144\n",
      "train_loss = 87.6870\n",
      "test_loss = 75.8740\n",
      "****************************\n",
      "Epoch: 1145\n",
      "train_loss = 88.5789\n",
      "test_loss = 74.5854\n",
      "****************************\n",
      "Epoch: 1146\n",
      "train_loss = 87.7592\n",
      "test_loss = 75.8946\n",
      "****************************\n",
      "Epoch: 1147\n",
      "train_loss = 87.8737\n",
      "test_loss = 75.0590\n",
      "****************************\n",
      "Epoch: 1148\n",
      "train_loss = 87.8397\n",
      "test_loss = 75.1001\n",
      "****************************\n",
      "Epoch: 1149\n",
      "train_loss = 89.0347\n",
      "test_loss = 79.5547\n",
      "****************************\n",
      "Epoch: 1150\n",
      "train_loss = 88.6065\n",
      "test_loss = 78.8626\n",
      "****************************\n",
      "Epoch: 1151\n",
      "train_loss = 87.6995\n",
      "test_loss = 75.9588\n",
      "****************************\n",
      "Epoch: 1152\n",
      "train_loss = 88.3913\n",
      "test_loss = 78.2631\n",
      "****************************\n",
      "Epoch: 1153\n",
      "train_loss = 88.6417\n",
      "test_loss = 78.7454\n",
      "****************************\n",
      "Epoch: 1154\n",
      "train_loss = 88.1590\n",
      "test_loss = 77.6471\n",
      "****************************\n",
      "Epoch: 1155\n",
      "train_loss = 87.7110\n",
      "test_loss = 75.4611\n",
      "****************************\n",
      "Epoch: 1156\n",
      "train_loss = 88.3746\n",
      "test_loss = 74.5538\n",
      "****************************\n",
      "Epoch: 1157\n",
      "train_loss = 87.6801\n",
      "test_loss = 75.6558\n",
      "****************************\n",
      "Epoch: 1158\n",
      "train_loss = 88.1765\n",
      "test_loss = 74.6750\n",
      "****************************\n",
      "Epoch: 1159\n",
      "train_loss = 87.6896\n",
      "test_loss = 75.8860\n",
      "****************************\n",
      "Epoch: 1160\n",
      "train_loss = 87.7663\n",
      "test_loss = 76.5087\n",
      "****************************\n",
      "Epoch: 1161\n",
      "train_loss = 87.9629\n",
      "test_loss = 74.8649\n",
      "****************************\n",
      "Epoch: 1162\n",
      "train_loss = 87.6995\n",
      "test_loss = 75.4435\n",
      "****************************\n",
      "Epoch: 1163\n",
      "train_loss = 87.7243\n",
      "test_loss = 75.3670\n",
      "****************************\n",
      "Epoch: 1164\n",
      "train_loss = 87.6912\n",
      "test_loss = 76.0855\n",
      "****************************\n",
      "Epoch: 1165\n",
      "train_loss = 87.6931\n",
      "test_loss = 75.8416\n",
      "****************************\n",
      "Epoch: 1166\n",
      "train_loss = 87.6601\n",
      "test_loss = 75.8840\n",
      "****************************\n",
      "Epoch: 1167\n",
      "train_loss = 87.7906\n",
      "test_loss = 75.0459\n",
      "****************************\n",
      "Epoch: 1168\n",
      "train_loss = 87.6616\n",
      "test_loss = 75.7286\n",
      "****************************\n",
      "Epoch: 1169\n",
      "train_loss = 89.2228\n",
      "test_loss = 74.3524\n",
      "****************************\n",
      "Epoch: 1170\n",
      "train_loss = 87.9669\n",
      "test_loss = 74.7074\n",
      "****************************\n",
      "Epoch: 1171\n",
      "train_loss = 88.9380\n",
      "test_loss = 79.0331\n",
      "****************************\n",
      "Epoch: 1172\n",
      "train_loss = 89.0090\n",
      "test_loss = 79.2508\n",
      "****************************\n",
      "Epoch: 1173\n",
      "train_loss = 87.7221\n",
      "test_loss = 75.2493\n",
      "****************************\n",
      "Epoch: 1174\n",
      "train_loss = 87.6825\n",
      "test_loss = 75.6627\n",
      "****************************\n",
      "Epoch: 1175\n",
      "train_loss = 88.4863\n",
      "test_loss = 77.9224\n",
      "****************************\n",
      "Epoch: 1176\n",
      "train_loss = 88.7676\n",
      "test_loss = 78.5909\n",
      "****************************\n",
      "Epoch: 1177\n",
      "train_loss = 88.4841\n",
      "test_loss = 74.4654\n",
      "****************************\n",
      "Epoch: 1178\n",
      "train_loss = 87.7100\n",
      "test_loss = 75.5427\n",
      "****************************\n",
      "Epoch: 1179\n",
      "train_loss = 87.8087\n",
      "test_loss = 75.3313\n",
      "****************************\n",
      "Epoch: 1180\n",
      "train_loss = 87.7074\n",
      "test_loss = 75.9621\n",
      "****************************\n",
      "Epoch: 1181\n",
      "train_loss = 87.9469\n",
      "test_loss = 77.0513\n",
      "****************************\n",
      "Epoch: 1182\n",
      "train_loss = 87.7537\n",
      "test_loss = 75.1506\n",
      "****************************\n",
      "Epoch: 1183\n",
      "train_loss = 88.1887\n",
      "test_loss = 74.5780\n",
      "****************************\n",
      "Epoch: 1184\n",
      "train_loss = 87.7784\n",
      "test_loss = 76.1545\n",
      "****************************\n",
      "Epoch: 1185\n",
      "train_loss = 89.0363\n",
      "test_loss = 74.3638\n",
      "****************************\n",
      "Epoch: 1186\n",
      "train_loss = 87.8489\n",
      "test_loss = 75.1786\n",
      "****************************\n",
      "Epoch: 1187\n",
      "train_loss = 88.4785\n",
      "test_loss = 78.1238\n",
      "****************************\n",
      "Epoch: 1188\n",
      "train_loss = 87.7445\n",
      "test_loss = 75.2013\n",
      "****************************\n",
      "Epoch: 1189\n",
      "train_loss = 88.8369\n",
      "test_loss = 74.3714\n",
      "****************************\n",
      "Epoch: 1190\n",
      "train_loss = 90.6245\n",
      "test_loss = 81.8513\n",
      "****************************\n",
      "Epoch: 1191\n",
      "train_loss = 87.8479\n",
      "test_loss = 76.2140\n",
      "****************************\n",
      "Epoch: 1192\n",
      "train_loss = 87.8465\n",
      "test_loss = 75.1420\n",
      "****************************\n",
      "Epoch: 1193\n",
      "train_loss = 87.8184\n",
      "test_loss = 75.2540\n",
      "****************************\n",
      "Epoch: 1194\n",
      "train_loss = 87.8977\n",
      "test_loss = 76.8545\n",
      "****************************\n",
      "Epoch: 1195\n",
      "train_loss = 87.7181\n",
      "test_loss = 76.0077\n",
      "****************************\n",
      "Epoch: 1196\n",
      "train_loss = 87.7468\n",
      "test_loss = 76.1029\n",
      "****************************\n",
      "Epoch: 1197\n",
      "train_loss = 89.8205\n",
      "test_loss = 80.4499\n",
      "****************************\n",
      "Epoch: 1198\n",
      "train_loss = 88.0024\n",
      "test_loss = 77.1695\n",
      "****************************\n",
      "Epoch: 1199\n",
      "train_loss = 88.5259\n",
      "test_loss = 74.4965\n",
      "****************************\n",
      "Epoch: 1200\n",
      "train_loss = 87.9031\n",
      "test_loss = 74.9565\n",
      "****************************\n",
      "Epoch: 1201\n",
      "train_loss = 88.2105\n",
      "test_loss = 77.7152\n",
      "****************************\n",
      "Epoch: 1202\n",
      "train_loss = 87.7982\n",
      "test_loss = 76.5357\n",
      "****************************\n",
      "Epoch: 1203\n",
      "train_loss = 89.2176\n",
      "test_loss = 79.7342\n",
      "****************************\n",
      "Epoch: 1204\n",
      "train_loss = 88.1591\n",
      "test_loss = 77.5425\n",
      "****************************\n",
      "Epoch: 1205\n",
      "train_loss = 87.7203\n",
      "test_loss = 75.6509\n",
      "****************************\n",
      "Epoch: 1206\n",
      "train_loss = 88.0987\n",
      "test_loss = 77.5233\n",
      "****************************\n",
      "Epoch: 1207\n",
      "train_loss = 88.5561\n",
      "test_loss = 74.4792\n",
      "****************************\n",
      "Epoch: 1208\n",
      "train_loss = 87.7716\n",
      "test_loss = 75.1622\n",
      "****************************\n",
      "Epoch: 1209\n",
      "train_loss = 88.1877\n",
      "test_loss = 74.7127\n",
      "****************************\n",
      "Epoch: 1210\n",
      "train_loss = 89.9065\n",
      "test_loss = 81.0107\n",
      "****************************\n",
      "Epoch: 1211\n",
      "train_loss = 88.0224\n",
      "test_loss = 77.3071\n",
      "****************************\n",
      "Epoch: 1212\n",
      "train_loss = 88.4951\n",
      "test_loss = 78.3388\n",
      "****************************\n",
      "Epoch: 1213\n",
      "train_loss = 87.8417\n",
      "test_loss = 75.0704\n",
      "****************************\n",
      "Epoch: 1214\n",
      "train_loss = 87.7560\n",
      "test_loss = 75.5695\n",
      "****************************\n",
      "Epoch: 1215\n",
      "train_loss = 87.9431\n",
      "test_loss = 76.7027\n",
      "****************************\n",
      "Epoch: 1216\n",
      "train_loss = 88.2998\n",
      "test_loss = 77.8016\n",
      "****************************\n",
      "Epoch: 1217\n",
      "train_loss = 87.7299\n",
      "test_loss = 75.6627\n",
      "****************************\n",
      "Epoch: 1218\n",
      "train_loss = 87.6948\n",
      "test_loss = 75.6540\n",
      "****************************\n",
      "Epoch: 1219\n",
      "train_loss = 87.7960\n",
      "test_loss = 76.5708\n",
      "****************************\n",
      "Epoch: 1220\n",
      "train_loss = 88.1152\n",
      "test_loss = 74.6754\n",
      "****************************\n",
      "Epoch: 1221\n",
      "train_loss = 87.6899\n",
      "test_loss = 75.8469\n",
      "****************************\n",
      "Epoch: 1222\n",
      "train_loss = 88.3138\n",
      "test_loss = 74.5681\n",
      "****************************\n",
      "Epoch: 1223\n",
      "train_loss = 88.2060\n",
      "test_loss = 77.8131\n",
      "****************************\n",
      "Epoch: 1224\n",
      "train_loss = 87.8233\n",
      "test_loss = 75.0328\n",
      "****************************\n",
      "Epoch: 1225\n",
      "train_loss = 87.6906\n",
      "test_loss = 75.7467\n",
      "****************************\n",
      "Epoch: 1226\n",
      "train_loss = 88.4254\n",
      "test_loss = 74.5152\n",
      "****************************\n",
      "Epoch: 1227\n",
      "train_loss = 87.8016\n",
      "test_loss = 76.6784\n",
      "****************************\n",
      "Epoch: 1228\n",
      "train_loss = 87.6773\n",
      "test_loss = 75.5796\n",
      "****************************\n",
      "Epoch: 1229\n",
      "train_loss = 87.9505\n",
      "test_loss = 74.8556\n",
      "****************************\n",
      "Epoch: 1230\n",
      "train_loss = 87.8312\n",
      "test_loss = 74.9890\n",
      "****************************\n",
      "Epoch: 1231\n",
      "train_loss = 88.5518\n",
      "test_loss = 78.2988\n",
      "****************************\n",
      "Epoch: 1232\n",
      "train_loss = 88.8625\n",
      "test_loss = 74.3841\n",
      "****************************\n",
      "Epoch: 1233\n",
      "train_loss = 87.9724\n",
      "test_loss = 77.0884\n",
      "****************************\n",
      "Epoch: 1234\n",
      "train_loss = 87.9433\n",
      "test_loss = 74.8094\n",
      "****************************\n",
      "Epoch: 1235\n",
      "train_loss = 87.8537\n",
      "test_loss = 76.7440\n",
      "****************************\n",
      "Epoch: 1236\n",
      "train_loss = 88.4364\n",
      "test_loss = 78.3205\n",
      "****************************\n",
      "Epoch: 1237\n",
      "train_loss = 87.6943\n",
      "test_loss = 75.5115\n",
      "****************************\n",
      "Epoch: 1238\n",
      "train_loss = 87.6998\n",
      "test_loss = 75.9702\n",
      "****************************\n",
      "Epoch: 1239\n",
      "train_loss = 88.6645\n",
      "test_loss = 78.8158\n",
      "****************************\n",
      "Epoch: 1240\n",
      "train_loss = 87.7729\n",
      "test_loss = 75.2453\n",
      "****************************\n",
      "Epoch: 1241\n",
      "train_loss = 87.8077\n",
      "test_loss = 75.2133\n",
      "****************************\n",
      "Epoch: 1242\n",
      "train_loss = 87.7700\n",
      "test_loss = 76.0615\n",
      "****************************\n",
      "Epoch: 1243\n",
      "train_loss = 88.4333\n",
      "test_loss = 78.2460\n",
      "****************************\n",
      "Epoch: 1244\n",
      "train_loss = 90.9179\n",
      "test_loss = 82.2923\n",
      "****************************\n",
      "Epoch: 1245\n",
      "train_loss = 87.7105\n",
      "test_loss = 75.6125\n",
      "****************************\n",
      "Epoch: 1246\n",
      "train_loss = 87.9118\n",
      "test_loss = 74.8687\n",
      "****************************\n",
      "Epoch: 1247\n",
      "train_loss = 87.8291\n",
      "test_loss = 75.0246\n",
      "****************************\n",
      "Epoch: 1248\n",
      "train_loss = 88.2525\n",
      "test_loss = 74.6437\n",
      "****************************\n",
      "Epoch: 1249\n",
      "train_loss = 88.1038\n",
      "test_loss = 76.9843\n",
      "****************************\n",
      "Epoch: 1250\n",
      "train_loss = 87.7470\n",
      "test_loss = 75.5135\n",
      "****************************\n",
      "Epoch: 1251\n",
      "train_loss = 88.1390\n",
      "test_loss = 77.5720\n",
      "****************************\n",
      "Epoch: 1252\n",
      "train_loss = 88.3380\n",
      "test_loss = 78.1270\n",
      "****************************\n",
      "Epoch: 1253\n",
      "train_loss = 90.5297\n",
      "test_loss = 81.6027\n",
      "****************************\n",
      "Epoch: 1254\n",
      "train_loss = 87.8088\n",
      "test_loss = 76.4445\n",
      "****************************\n",
      "Epoch: 1255\n",
      "train_loss = 87.9611\n",
      "test_loss = 77.1277\n",
      "****************************\n",
      "Epoch: 1256\n",
      "train_loss = 88.5745\n",
      "test_loss = 78.1144\n",
      "****************************\n",
      "Epoch: 1257\n",
      "train_loss = 88.4377\n",
      "test_loss = 78.0131\n",
      "****************************\n",
      "Epoch: 1258\n",
      "train_loss = 88.0722\n",
      "test_loss = 77.1769\n",
      "****************************\n",
      "Epoch: 1259\n",
      "train_loss = 88.9025\n",
      "test_loss = 79.1253\n",
      "****************************\n",
      "Epoch: 1260\n",
      "train_loss = 87.7404\n",
      "test_loss = 75.6657\n",
      "****************************\n",
      "Epoch: 1261\n",
      "train_loss = 88.4145\n",
      "test_loss = 78.1654\n",
      "****************************\n",
      "Epoch: 1262\n",
      "train_loss = 87.7493\n",
      "test_loss = 75.3203\n",
      "****************************\n",
      "Epoch: 1263\n",
      "train_loss = 87.7603\n",
      "test_loss = 75.6152\n",
      "****************************\n",
      "Epoch: 1264\n",
      "train_loss = 87.7316\n",
      "test_loss = 75.3499\n",
      "****************************\n",
      "Epoch: 1265\n",
      "train_loss = 88.0266\n",
      "test_loss = 74.7163\n",
      "****************************\n",
      "Epoch: 1266\n",
      "train_loss = 87.7101\n",
      "test_loss = 75.4464\n",
      "****************************\n",
      "Epoch: 1267\n",
      "train_loss = 87.7073\n",
      "test_loss = 75.9772\n",
      "****************************\n",
      "Epoch: 1268\n",
      "train_loss = 87.8688\n",
      "test_loss = 74.9955\n",
      "****************************\n",
      "Epoch: 1269\n",
      "train_loss = 87.8082\n",
      "test_loss = 76.8280\n",
      "****************************\n",
      "Epoch: 1270\n",
      "train_loss = 87.7708\n",
      "test_loss = 76.5962\n",
      "****************************\n",
      "Epoch: 1271\n",
      "train_loss = 87.9121\n",
      "test_loss = 74.8951\n",
      "****************************\n",
      "Epoch: 1272\n",
      "train_loss = 87.7750\n",
      "test_loss = 76.4878\n",
      "****************************\n",
      "Epoch: 1273\n",
      "train_loss = 87.6653\n",
      "test_loss = 75.7884\n",
      "****************************\n",
      "Epoch: 1274\n",
      "train_loss = 87.7376\n",
      "test_loss = 76.4442\n",
      "****************************\n",
      "Epoch: 1275\n",
      "train_loss = 88.2632\n",
      "test_loss = 74.5029\n",
      "****************************\n",
      "Epoch: 1276\n",
      "train_loss = 87.7513\n",
      "test_loss = 76.1344\n",
      "****************************\n",
      "Epoch: 1277\n",
      "train_loss = 87.9166\n",
      "test_loss = 76.9872\n",
      "****************************\n",
      "Epoch: 1278\n",
      "train_loss = 87.7288\n",
      "test_loss = 76.0190\n",
      "****************************\n",
      "Epoch: 1279\n",
      "train_loss = 87.9005\n",
      "test_loss = 76.5970\n",
      "****************************\n",
      "Epoch: 1280\n",
      "train_loss = 87.8873\n",
      "test_loss = 75.0772\n",
      "****************************\n",
      "Epoch: 1281\n",
      "train_loss = 87.7349\n",
      "test_loss = 75.5810\n",
      "****************************\n",
      "Epoch: 1282\n",
      "train_loss = 87.7200\n",
      "test_loss = 75.9841\n",
      "****************************\n",
      "Epoch: 1283\n",
      "train_loss = 88.5622\n",
      "test_loss = 78.6805\n",
      "****************************\n",
      "Epoch: 1284\n",
      "train_loss = 87.7173\n",
      "test_loss = 75.5039\n",
      "****************************\n",
      "Epoch: 1285\n",
      "train_loss = 87.7914\n",
      "test_loss = 75.0989\n",
      "****************************\n",
      "Epoch: 1286\n",
      "train_loss = 87.9741\n",
      "test_loss = 74.8671\n",
      "****************************\n",
      "Epoch: 1287\n",
      "train_loss = 87.8105\n",
      "test_loss = 75.0481\n",
      "****************************\n",
      "Epoch: 1288\n",
      "train_loss = 87.8796\n",
      "test_loss = 76.7962\n",
      "****************************\n",
      "Epoch: 1289\n",
      "train_loss = 87.9589\n",
      "test_loss = 74.9949\n",
      "****************************\n",
      "Epoch: 1290\n",
      "train_loss = 87.9577\n",
      "test_loss = 74.8235\n",
      "****************************\n",
      "Epoch: 1291\n",
      "train_loss = 88.3919\n",
      "test_loss = 78.4156\n",
      "****************************\n",
      "Epoch: 1292\n",
      "train_loss = 87.6963\n",
      "test_loss = 75.3166\n",
      "****************************\n",
      "Epoch: 1293\n",
      "train_loss = 88.7447\n",
      "test_loss = 79.1354\n",
      "****************************\n",
      "Epoch: 1294\n",
      "train_loss = 88.8540\n",
      "test_loss = 79.2730\n",
      "****************************\n",
      "Epoch: 1295\n",
      "train_loss = 88.1075\n",
      "test_loss = 77.5620\n",
      "****************************\n",
      "Epoch: 1296\n",
      "train_loss = 87.7432\n",
      "test_loss = 75.1341\n",
      "****************************\n",
      "Epoch: 1297\n",
      "train_loss = 87.6701\n",
      "test_loss = 75.9137\n",
      "****************************\n",
      "Epoch: 1298\n",
      "train_loss = 88.2355\n",
      "test_loss = 77.8507\n",
      "****************************\n",
      "Epoch: 1299\n",
      "train_loss = 88.3709\n",
      "test_loss = 78.1579\n",
      "****************************\n",
      "Epoch: 1300\n",
      "train_loss = 87.6969\n",
      "test_loss = 76.2538\n",
      "****************************\n",
      "Epoch: 1301\n",
      "train_loss = 87.6994\n",
      "test_loss = 76.4273\n",
      "****************************\n",
      "Epoch: 1302\n",
      "train_loss = 87.6382\n",
      "test_loss = 75.4699\n",
      "****************************\n",
      "Epoch: 1303\n",
      "train_loss = 87.6466\n",
      "test_loss = 76.0741\n",
      "****************************\n",
      "Epoch: 1304\n",
      "train_loss = 87.9823\n",
      "test_loss = 77.3814\n",
      "****************************\n",
      "Epoch: 1305\n",
      "train_loss = 88.0063\n",
      "test_loss = 74.7145\n",
      "****************************\n",
      "Epoch: 1306\n",
      "train_loss = 87.7165\n",
      "test_loss = 75.3827\n",
      "****************************\n",
      "Epoch: 1307\n",
      "train_loss = 87.7153\n",
      "test_loss = 75.1893\n",
      "****************************\n",
      "Epoch: 1308\n",
      "train_loss = 87.8329\n",
      "test_loss = 74.8888\n",
      "****************************\n",
      "Epoch: 1309\n",
      "train_loss = 87.6498\n",
      "test_loss = 75.8271\n",
      "****************************\n",
      "Epoch: 1310\n",
      "train_loss = 88.8654\n",
      "test_loss = 79.2568\n",
      "****************************\n",
      "Epoch: 1311\n",
      "train_loss = 88.6800\n",
      "test_loss = 78.9002\n",
      "****************************\n",
      "Epoch: 1312\n",
      "train_loss = 87.9565\n",
      "test_loss = 74.7613\n",
      "****************************\n",
      "Epoch: 1313\n",
      "train_loss = 88.3275\n",
      "test_loss = 74.4433\n",
      "****************************\n",
      "Epoch: 1314\n",
      "train_loss = 87.8126\n",
      "test_loss = 76.4589\n",
      "****************************\n",
      "Epoch: 1315\n",
      "train_loss = 88.4123\n",
      "test_loss = 74.4198\n",
      "****************************\n",
      "Epoch: 1316\n",
      "train_loss = 87.6522\n",
      "test_loss = 75.9651\n",
      "****************************\n",
      "Epoch: 1317\n",
      "train_loss = 87.6109\n",
      "test_loss = 75.6649\n",
      "****************************\n",
      "Epoch: 1318\n",
      "train_loss = 88.2983\n",
      "test_loss = 74.4852\n",
      "****************************\n",
      "Epoch: 1319\n",
      "train_loss = 87.6699\n",
      "test_loss = 75.4694\n",
      "****************************\n",
      "Epoch: 1320\n",
      "train_loss = 88.4325\n",
      "test_loss = 78.1067\n",
      "****************************\n",
      "Epoch: 1321\n",
      "train_loss = 87.9908\n",
      "test_loss = 75.2104\n",
      "****************************\n",
      "Epoch: 1322\n",
      "train_loss = 87.7927\n",
      "test_loss = 76.5827\n",
      "****************************\n",
      "Epoch: 1323\n",
      "train_loss = 87.8442\n",
      "test_loss = 76.8550\n",
      "****************************\n",
      "Epoch: 1324\n",
      "train_loss = 87.6760\n",
      "test_loss = 75.5364\n",
      "****************************\n",
      "Epoch: 1325\n",
      "train_loss = 88.9665\n",
      "test_loss = 74.3604\n",
      "****************************\n",
      "Epoch: 1326\n",
      "train_loss = 87.7510\n",
      "test_loss = 75.9651\n",
      "****************************\n",
      "Epoch: 1327\n",
      "train_loss = 87.7711\n",
      "test_loss = 75.0846\n",
      "****************************\n",
      "Epoch: 1328\n",
      "train_loss = 87.6821\n",
      "test_loss = 75.8014\n",
      "****************************\n",
      "Epoch: 1329\n",
      "train_loss = 88.0442\n",
      "test_loss = 77.4091\n",
      "****************************\n",
      "Epoch: 1330\n",
      "train_loss = 87.6841\n",
      "test_loss = 76.1573\n",
      "****************************\n",
      "Epoch: 1331\n",
      "train_loss = 87.8533\n",
      "test_loss = 74.9166\n",
      "****************************\n",
      "Epoch: 1332\n",
      "train_loss = 88.5717\n",
      "test_loss = 78.7083\n",
      "****************************\n",
      "Epoch: 1333\n",
      "train_loss = 90.2086\n",
      "test_loss = 75.0621\n",
      "****************************\n",
      "Epoch: 1334\n",
      "train_loss = 88.7677\n",
      "test_loss = 78.9067\n",
      "****************************\n",
      "Epoch: 1335\n",
      "train_loss = 87.6941\n",
      "test_loss = 75.5022\n",
      "****************************\n",
      "Epoch: 1336\n",
      "train_loss = 88.2517\n",
      "test_loss = 74.5917\n",
      "****************************\n",
      "Epoch: 1337\n",
      "train_loss = 87.7337\n",
      "test_loss = 75.1814\n",
      "****************************\n",
      "Epoch: 1338\n",
      "train_loss = 88.0514\n",
      "test_loss = 77.5025\n",
      "****************************\n",
      "Epoch: 1339\n",
      "train_loss = 87.8045\n",
      "test_loss = 74.9631\n",
      "****************************\n",
      "Epoch: 1340\n",
      "train_loss = 87.9459\n",
      "test_loss = 74.7038\n",
      "****************************\n",
      "Epoch: 1341\n",
      "train_loss = 87.9587\n",
      "test_loss = 74.6740\n",
      "****************************\n",
      "Epoch: 1342\n",
      "train_loss = 87.6939\n",
      "test_loss = 75.1337\n",
      "****************************\n",
      "Epoch: 1343\n",
      "train_loss = 88.1023\n",
      "test_loss = 74.5522\n",
      "****************************\n",
      "Epoch: 1344\n",
      "train_loss = 88.0750\n",
      "test_loss = 77.1991\n",
      "****************************\n",
      "Epoch: 1345\n",
      "train_loss = 87.7453\n",
      "test_loss = 75.1403\n",
      "****************************\n",
      "Epoch: 1346\n",
      "train_loss = 87.6533\n",
      "test_loss = 75.4437\n",
      "****************************\n",
      "Epoch: 1347\n",
      "train_loss = 87.9446\n",
      "test_loss = 76.6557\n",
      "****************************\n",
      "Epoch: 1348\n",
      "train_loss = 87.9357\n",
      "test_loss = 74.7932\n",
      "****************************\n",
      "Epoch: 1349\n",
      "train_loss = 87.7860\n",
      "test_loss = 76.4261\n",
      "****************************\n",
      "Epoch: 1350\n",
      "train_loss = 87.6724\n",
      "test_loss = 75.4647\n",
      "****************************\n",
      "Epoch: 1351\n",
      "train_loss = 89.4258\n",
      "test_loss = 79.6397\n",
      "****************************\n",
      "Epoch: 1352\n",
      "train_loss = 87.7075\n",
      "test_loss = 75.7806\n",
      "****************************\n",
      "Epoch: 1353\n",
      "train_loss = 87.8254\n",
      "test_loss = 76.7192\n",
      "****************************\n",
      "Epoch: 1354\n",
      "train_loss = 87.8722\n",
      "test_loss = 76.9185\n",
      "****************************\n",
      "Epoch: 1355\n",
      "train_loss = 87.9580\n",
      "test_loss = 75.6867\n",
      "****************************\n",
      "Epoch: 1356\n",
      "train_loss = 89.5825\n",
      "test_loss = 74.4396\n",
      "****************************\n",
      "Epoch: 1357\n",
      "train_loss = 87.6651\n",
      "test_loss = 75.7325\n",
      "****************************\n",
      "Epoch: 1358\n",
      "train_loss = 89.3583\n",
      "test_loss = 74.3942\n",
      "****************************\n",
      "Epoch: 1359\n",
      "train_loss = 87.8248\n",
      "test_loss = 76.7529\n",
      "****************************\n",
      "Epoch: 1360\n",
      "train_loss = 87.7039\n",
      "test_loss = 75.2953\n",
      "****************************\n",
      "Epoch: 1361\n",
      "train_loss = 87.9865\n",
      "test_loss = 75.0257\n",
      "****************************\n",
      "Epoch: 1362\n",
      "train_loss = 89.7435\n",
      "test_loss = 74.4533\n",
      "****************************\n",
      "Epoch: 1363\n",
      "train_loss = 87.9807\n",
      "test_loss = 77.2513\n",
      "****************************\n",
      "Epoch: 1364\n",
      "train_loss = 89.1033\n",
      "test_loss = 74.3537\n",
      "****************************\n",
      "Epoch: 1365\n",
      "train_loss = 90.8608\n",
      "test_loss = 82.1577\n",
      "****************************\n",
      "Epoch: 1366\n",
      "train_loss = 87.9658\n",
      "test_loss = 77.2237\n",
      "****************************\n",
      "Epoch: 1367\n",
      "train_loss = 88.4083\n",
      "test_loss = 78.2782\n",
      "****************************\n",
      "Epoch: 1368\n",
      "train_loss = 87.9435\n",
      "test_loss = 74.7757\n",
      "****************************\n",
      "Epoch: 1369\n",
      "train_loss = 87.9825\n",
      "test_loss = 74.7406\n",
      "****************************\n",
      "Epoch: 1370\n",
      "train_loss = 88.2960\n",
      "test_loss = 77.9099\n",
      "****************************\n",
      "Epoch: 1371\n",
      "train_loss = 91.8434\n",
      "test_loss = 83.7135\n",
      "****************************\n",
      "Epoch: 1372\n",
      "train_loss = 88.1006\n",
      "test_loss = 77.3154\n",
      "****************************\n",
      "Epoch: 1373\n",
      "train_loss = 87.6997\n",
      "test_loss = 75.9279\n",
      "****************************\n",
      "Epoch: 1374\n",
      "train_loss = 87.9644\n",
      "test_loss = 77.1121\n",
      "****************************\n",
      "Epoch: 1375\n",
      "train_loss = 87.9393\n",
      "test_loss = 74.8172\n",
      "****************************\n",
      "Epoch: 1376\n",
      "train_loss = 87.6745\n",
      "test_loss = 75.3541\n",
      "****************************\n",
      "Epoch: 1377\n",
      "train_loss = 87.9992\n",
      "test_loss = 74.7670\n",
      "****************************\n",
      "Epoch: 1378\n",
      "train_loss = 87.6720\n",
      "test_loss = 75.9496\n",
      "****************************\n",
      "Epoch: 1379\n",
      "train_loss = 87.6476\n",
      "test_loss = 75.8615\n",
      "****************************\n",
      "Epoch: 1380\n",
      "train_loss = 88.1215\n",
      "test_loss = 74.6278\n",
      "****************************\n",
      "Epoch: 1381\n",
      "train_loss = 87.8473\n",
      "test_loss = 76.5264\n",
      "****************************\n",
      "Epoch: 1382\n",
      "train_loss = 87.8210\n",
      "test_loss = 75.1185\n",
      "****************************\n",
      "Epoch: 1383\n",
      "train_loss = 87.7176\n",
      "test_loss = 75.4389\n",
      "****************************\n",
      "Epoch: 1384\n",
      "train_loss = 87.6855\n",
      "test_loss = 75.4719\n",
      "****************************\n",
      "Epoch: 1385\n",
      "train_loss = 87.7212\n",
      "test_loss = 76.4274\n",
      "****************************\n",
      "Epoch: 1386\n",
      "train_loss = 87.8965\n",
      "test_loss = 76.9137\n",
      "****************************\n",
      "Epoch: 1387\n",
      "train_loss = 87.7153\n",
      "test_loss = 75.1437\n",
      "****************************\n",
      "Epoch: 1388\n",
      "train_loss = 87.6601\n",
      "test_loss = 76.0254\n",
      "****************************\n",
      "Epoch: 1389\n",
      "train_loss = 87.9288\n",
      "test_loss = 74.8121\n",
      "****************************\n",
      "Epoch: 1390\n",
      "train_loss = 88.8039\n",
      "test_loss = 74.3524\n",
      "****************************\n",
      "Epoch: 1391\n",
      "train_loss = 87.8377\n",
      "test_loss = 76.8348\n",
      "****************************\n",
      "Epoch: 1392\n",
      "train_loss = 87.8001\n",
      "test_loss = 75.1410\n",
      "****************************\n",
      "Epoch: 1393\n",
      "train_loss = 87.9734\n",
      "test_loss = 74.7234\n",
      "****************************\n",
      "Epoch: 1394\n",
      "train_loss = 87.6920\n",
      "test_loss = 75.3057\n",
      "****************************\n",
      "Epoch: 1395\n",
      "train_loss = 87.6862\n",
      "test_loss = 75.9621\n",
      "****************************\n",
      "Epoch: 1396\n",
      "train_loss = 87.6426\n",
      "test_loss = 75.4522\n",
      "****************************\n",
      "Epoch: 1397\n",
      "train_loss = 87.7057\n",
      "test_loss = 76.3862\n",
      "****************************\n",
      "Epoch: 1398\n",
      "train_loss = 87.7830\n",
      "test_loss = 76.6569\n",
      "****************************\n",
      "Epoch: 1399\n",
      "train_loss = 87.8472\n",
      "test_loss = 76.9498\n",
      "****************************\n",
      "Epoch: 1400\n",
      "train_loss = 87.7312\n",
      "test_loss = 75.0228\n",
      "****************************\n",
      "Epoch: 1401\n",
      "train_loss = 88.0110\n",
      "test_loss = 77.5863\n",
      "****************************\n",
      "Epoch: 1402\n",
      "train_loss = 88.0547\n",
      "test_loss = 77.5033\n",
      "****************************\n",
      "Epoch: 1403\n",
      "train_loss = 87.6703\n",
      "test_loss = 75.2145\n",
      "****************************\n",
      "Epoch: 1404\n",
      "train_loss = 87.6457\n",
      "test_loss = 76.1115\n",
      "****************************\n",
      "Epoch: 1405\n",
      "train_loss = 88.0580\n",
      "test_loss = 74.6631\n",
      "****************************\n",
      "Epoch: 1406\n",
      "train_loss = 87.7487\n",
      "test_loss = 75.0789\n",
      "****************************\n",
      "Epoch: 1407\n",
      "train_loss = 87.8747\n",
      "test_loss = 74.8817\n",
      "****************************\n",
      "Epoch: 1408\n",
      "train_loss = 88.1396\n",
      "test_loss = 74.6525\n",
      "****************************\n",
      "Epoch: 1409\n",
      "train_loss = 88.1578\n",
      "test_loss = 77.5819\n",
      "****************************\n",
      "Epoch: 1410\n",
      "train_loss = 87.6907\n",
      "test_loss = 75.5124\n",
      "****************************\n",
      "Epoch: 1411\n",
      "train_loss = 87.6926\n",
      "test_loss = 75.9734\n",
      "****************************\n",
      "Epoch: 1412\n",
      "train_loss = 88.1737\n",
      "test_loss = 77.6462\n",
      "****************************\n",
      "Epoch: 1413\n",
      "train_loss = 87.9977\n",
      "test_loss = 77.2652\n",
      "****************************\n",
      "Epoch: 1414\n",
      "train_loss = 87.9703\n",
      "test_loss = 74.7133\n",
      "****************************\n",
      "Epoch: 1415\n",
      "train_loss = 87.6831\n",
      "test_loss = 75.5678\n",
      "****************************\n",
      "Epoch: 1416\n",
      "train_loss = 87.8694\n",
      "test_loss = 76.9445\n",
      "****************************\n",
      "Epoch: 1417\n",
      "train_loss = 87.6629\n",
      "test_loss = 76.0344\n",
      "****************************\n",
      "Epoch: 1418\n",
      "train_loss = 87.6590\n",
      "test_loss = 75.7336\n",
      "****************************\n",
      "Epoch: 1419\n",
      "train_loss = 87.9891\n",
      "test_loss = 77.1542\n",
      "****************************\n",
      "Epoch: 1420\n",
      "train_loss = 89.7637\n",
      "test_loss = 80.2707\n",
      "****************************\n",
      "Epoch: 1421\n",
      "train_loss = 87.8540\n",
      "test_loss = 76.6058\n",
      "****************************\n",
      "Epoch: 1422\n",
      "train_loss = 88.0928\n",
      "test_loss = 77.5280\n",
      "****************************\n",
      "Epoch: 1423\n",
      "train_loss = 87.6966\n",
      "test_loss = 75.1980\n",
      "****************************\n",
      "Epoch: 1424\n",
      "train_loss = 88.1918\n",
      "test_loss = 77.8171\n",
      "****************************\n",
      "Epoch: 1425\n",
      "train_loss = 87.8794\n",
      "test_loss = 77.0794\n",
      "****************************\n",
      "Epoch: 1426\n",
      "train_loss = 87.8071\n",
      "test_loss = 76.7251\n",
      "****************************\n",
      "Epoch: 1427\n",
      "train_loss = 87.7138\n",
      "test_loss = 75.1006\n",
      "****************************\n",
      "Epoch: 1428\n",
      "train_loss = 87.6546\n",
      "test_loss = 75.3951\n",
      "****************************\n",
      "Epoch: 1429\n",
      "train_loss = 88.7841\n",
      "test_loss = 78.8227\n",
      "****************************\n",
      "Epoch: 1430\n",
      "train_loss = 87.8796\n",
      "test_loss = 74.8935\n",
      "****************************\n",
      "Epoch: 1431\n",
      "train_loss = 87.6603\n",
      "test_loss = 75.7532\n",
      "****************************\n",
      "Epoch: 1432\n",
      "train_loss = 87.6419\n",
      "test_loss = 75.5899\n",
      "****************************\n",
      "Epoch: 1433\n",
      "train_loss = 87.9350\n",
      "test_loss = 74.7540\n",
      "****************************\n",
      "Epoch: 1434\n",
      "train_loss = 87.6389\n",
      "test_loss = 75.8670\n",
      "****************************\n",
      "Epoch: 1435\n",
      "train_loss = 87.7594\n",
      "test_loss = 75.3364\n",
      "****************************\n",
      "Epoch: 1436\n",
      "train_loss = 89.5931\n",
      "test_loss = 80.3716\n",
      "****************************\n",
      "Epoch: 1437\n",
      "train_loss = 90.2179\n",
      "test_loss = 74.5107\n",
      "****************************\n",
      "Epoch: 1438\n",
      "train_loss = 88.2273\n",
      "test_loss = 74.6093\n",
      "****************************\n",
      "Epoch: 1439\n",
      "train_loss = 88.0833\n",
      "test_loss = 74.6325\n",
      "****************************\n",
      "Epoch: 1440\n",
      "train_loss = 87.6909\n",
      "test_loss = 75.8840\n",
      "****************************\n",
      "Epoch: 1441\n",
      "train_loss = 87.7231\n",
      "test_loss = 75.1329\n",
      "****************************\n",
      "Epoch: 1442\n",
      "train_loss = 88.2468\n",
      "test_loss = 77.8185\n",
      "****************************\n",
      "Epoch: 1443\n",
      "train_loss = 87.8780\n",
      "test_loss = 74.8236\n",
      "****************************\n",
      "Epoch: 1444\n",
      "train_loss = 88.1670\n",
      "test_loss = 74.7768\n",
      "****************************\n",
      "Epoch: 1445\n",
      "train_loss = 88.2743\n",
      "test_loss = 77.9020\n",
      "****************************\n",
      "Epoch: 1446\n",
      "train_loss = 87.6455\n",
      "test_loss = 75.9682\n",
      "****************************\n",
      "Epoch: 1447\n",
      "train_loss = 87.6878\n",
      "test_loss = 75.2352\n",
      "****************************\n",
      "Epoch: 1448\n",
      "train_loss = 88.1671\n",
      "test_loss = 77.7407\n",
      "****************************\n",
      "Epoch: 1449\n",
      "train_loss = 87.7462\n",
      "test_loss = 76.5089\n",
      "****************************\n",
      "Epoch: 1450\n",
      "train_loss = 87.8047\n",
      "test_loss = 76.7460\n",
      "****************************\n",
      "Epoch: 1451\n",
      "train_loss = 88.9550\n",
      "test_loss = 79.2727\n",
      "****************************\n",
      "Epoch: 1452\n",
      "train_loss = 88.3178\n",
      "test_loss = 74.5456\n",
      "****************************\n",
      "Epoch: 1453\n",
      "train_loss = 87.7109\n",
      "test_loss = 76.3325\n",
      "****************************\n",
      "Epoch: 1454\n",
      "train_loss = 88.3276\n",
      "test_loss = 74.4562\n",
      "****************************\n",
      "Epoch: 1455\n",
      "train_loss = 87.6630\n",
      "test_loss = 75.7482\n",
      "****************************\n",
      "Epoch: 1456\n",
      "train_loss = 88.1476\n",
      "test_loss = 77.5981\n",
      "****************************\n",
      "Epoch: 1457\n",
      "train_loss = 88.6161\n",
      "test_loss = 78.4638\n",
      "****************************\n",
      "Epoch: 1458\n",
      "train_loss = 88.0181\n",
      "test_loss = 74.6767\n",
      "****************************\n",
      "Epoch: 1459\n",
      "train_loss = 88.4667\n",
      "test_loss = 74.3900\n",
      "****************************\n",
      "Epoch: 1460\n",
      "train_loss = 87.7159\n",
      "test_loss = 75.1666\n",
      "****************************\n",
      "Epoch: 1461\n",
      "train_loss = 88.0524\n",
      "test_loss = 74.6118\n",
      "****************************\n",
      "Epoch: 1462\n",
      "train_loss = 87.6202\n",
      "test_loss = 75.5631\n",
      "****************************\n",
      "Epoch: 1463\n",
      "train_loss = 87.7615\n",
      "test_loss = 75.0100\n",
      "****************************\n",
      "Epoch: 1464\n",
      "train_loss = 87.6384\n",
      "test_loss = 75.4976\n",
      "****************************\n",
      "Epoch: 1465\n",
      "train_loss = 87.7882\n",
      "test_loss = 74.9570\n",
      "****************************\n",
      "Epoch: 1466\n",
      "train_loss = 88.8035\n",
      "test_loss = 75.2591\n",
      "****************************\n",
      "Epoch: 1467\n",
      "train_loss = 87.8255\n",
      "test_loss = 74.9721\n",
      "****************************\n",
      "Epoch: 1468\n",
      "train_loss = 89.5700\n",
      "test_loss = 80.4365\n",
      "****************************\n",
      "Epoch: 1469\n",
      "train_loss = 87.8406\n",
      "test_loss = 74.8669\n",
      "****************************\n",
      "Epoch: 1470\n",
      "train_loss = 88.3659\n",
      "test_loss = 77.3298\n",
      "****************************\n",
      "Epoch: 1471\n",
      "train_loss = 87.8121\n",
      "test_loss = 76.5774\n",
      "****************************\n",
      "Epoch: 1472\n",
      "train_loss = 88.7464\n",
      "test_loss = 74.3896\n",
      "****************************\n",
      "Epoch: 1473\n",
      "train_loss = 88.1892\n",
      "test_loss = 74.5675\n",
      "****************************\n",
      "Epoch: 1474\n",
      "train_loss = 87.8010\n",
      "test_loss = 76.4988\n",
      "****************************\n",
      "Epoch: 1475\n",
      "train_loss = 87.6790\n",
      "test_loss = 75.9424\n",
      "****************************\n",
      "Epoch: 1476\n",
      "train_loss = 87.8693\n",
      "test_loss = 76.9783\n",
      "****************************\n",
      "Epoch: 1477\n",
      "train_loss = 88.2148\n",
      "test_loss = 74.5455\n",
      "****************************\n",
      "Epoch: 1478\n",
      "train_loss = 87.6418\n",
      "test_loss = 75.7039\n",
      "****************************\n",
      "Epoch: 1479\n",
      "train_loss = 88.2257\n",
      "test_loss = 74.5358\n",
      "****************************\n",
      "Epoch: 1480\n",
      "train_loss = 89.9571\n",
      "test_loss = 81.3012\n",
      "****************************\n",
      "Epoch: 1481\n",
      "train_loss = 87.9325\n",
      "test_loss = 77.2034\n",
      "****************************\n",
      "Epoch: 1482\n",
      "train_loss = 87.6791\n",
      "test_loss = 76.3815\n",
      "****************************\n",
      "Epoch: 1483\n",
      "train_loss = 87.7317\n",
      "test_loss = 75.0503\n",
      "****************************\n",
      "Epoch: 1484\n",
      "train_loss = 87.6986\n",
      "test_loss = 76.0297\n",
      "****************************\n",
      "Epoch: 1485\n",
      "train_loss = 87.9031\n",
      "test_loss = 74.7371\n",
      "****************************\n",
      "Epoch: 1486\n",
      "train_loss = 88.2739\n",
      "test_loss = 77.8283\n",
      "****************************\n",
      "Epoch: 1487\n",
      "train_loss = 87.6552\n",
      "test_loss = 75.5830\n",
      "****************************\n",
      "Epoch: 1488\n",
      "train_loss = 87.7967\n",
      "test_loss = 75.4061\n",
      "****************************\n",
      "Epoch: 1489\n",
      "train_loss = 87.7690\n",
      "test_loss = 75.0442\n",
      "****************************\n",
      "Epoch: 1490\n",
      "train_loss = 90.7300\n",
      "test_loss = 82.2688\n",
      "****************************\n",
      "Epoch: 1491\n",
      "train_loss = 87.6608\n",
      "test_loss = 75.1665\n",
      "****************************\n",
      "Epoch: 1492\n",
      "train_loss = 87.6303\n",
      "test_loss = 75.9346\n",
      "****************************\n",
      "Epoch: 1493\n",
      "train_loss = 87.6489\n",
      "test_loss = 75.3853\n",
      "****************************\n",
      "Epoch: 1494\n",
      "train_loss = 87.8169\n",
      "test_loss = 74.8258\n",
      "****************************\n",
      "Epoch: 1495\n",
      "train_loss = 87.8634\n",
      "test_loss = 76.7799\n",
      "****************************\n",
      "Epoch: 1496\n",
      "train_loss = 88.3078\n",
      "test_loss = 77.8781\n",
      "****************************\n",
      "Epoch: 1497\n",
      "train_loss = 88.1449\n",
      "test_loss = 77.5267\n",
      "****************************\n",
      "Epoch: 1498\n",
      "train_loss = 87.7337\n",
      "test_loss = 76.4008\n",
      "****************************\n",
      "Epoch: 1499\n",
      "train_loss = 89.6896\n",
      "test_loss = 80.0353\n",
      "****************************\n",
      "Epoch: 1500\n",
      "train_loss = 88.0061\n",
      "test_loss = 74.7682\n",
      "****************************\n",
      "Epoch: 1501\n",
      "train_loss = 87.8959\n",
      "test_loss = 74.7885\n",
      "****************************\n",
      "Epoch: 1502\n",
      "train_loss = 87.9321\n",
      "test_loss = 74.7124\n",
      "****************************\n",
      "Epoch: 1503\n",
      "train_loss = 88.5125\n",
      "test_loss = 78.4483\n",
      "****************************\n",
      "Epoch: 1504\n",
      "train_loss = 87.6514\n",
      "test_loss = 75.2872\n",
      "****************************\n",
      "Epoch: 1505\n",
      "train_loss = 88.0541\n",
      "test_loss = 76.8688\n",
      "****************************\n",
      "Epoch: 1506\n",
      "train_loss = 87.7482\n",
      "test_loss = 75.9232\n",
      "****************************\n",
      "Epoch: 1507\n",
      "train_loss = 88.0382\n",
      "test_loss = 74.6953\n",
      "****************************\n",
      "Epoch: 1508\n",
      "train_loss = 87.7347\n",
      "test_loss = 75.8163\n",
      "****************************\n",
      "Epoch: 1509\n",
      "train_loss = 87.7614\n",
      "test_loss = 75.1071\n",
      "****************************\n",
      "Epoch: 1510\n",
      "train_loss = 90.8391\n",
      "test_loss = 82.2514\n",
      "****************************\n",
      "Epoch: 1511\n",
      "train_loss = 87.8737\n",
      "test_loss = 74.8832\n",
      "****************************\n",
      "Epoch: 1512\n",
      "train_loss = 87.6597\n",
      "test_loss = 75.7578\n",
      "****************************\n",
      "Epoch: 1513\n",
      "train_loss = 87.7564\n",
      "test_loss = 75.0344\n",
      "****************************\n",
      "Epoch: 1514\n",
      "train_loss = 88.3016\n",
      "test_loss = 74.4582\n",
      "****************************\n",
      "Epoch: 1515\n",
      "train_loss = 87.8287\n",
      "test_loss = 76.7535\n",
      "****************************\n",
      "Epoch: 1516\n",
      "train_loss = 88.9123\n",
      "test_loss = 79.2910\n",
      "****************************\n",
      "Epoch: 1517\n",
      "train_loss = 88.1493\n",
      "test_loss = 77.8134\n",
      "****************************\n",
      "Epoch: 1518\n",
      "train_loss = 87.7538\n",
      "test_loss = 76.6263\n",
      "****************************\n",
      "Epoch: 1519\n",
      "train_loss = 87.9320\n",
      "test_loss = 77.2150\n",
      "****************************\n",
      "Epoch: 1520\n",
      "train_loss = 88.3588\n",
      "test_loss = 78.2164\n",
      "****************************\n",
      "Epoch: 1521\n",
      "train_loss = 87.6753\n",
      "test_loss = 76.3518\n",
      "****************************\n",
      "Epoch: 1522\n",
      "train_loss = 87.6363\n",
      "test_loss = 76.0450\n",
      "****************************\n",
      "Epoch: 1523\n",
      "train_loss = 87.6680\n",
      "test_loss = 75.1722\n",
      "****************************\n",
      "Epoch: 1524\n",
      "train_loss = 88.1816\n",
      "test_loss = 77.8729\n",
      "****************************\n",
      "Epoch: 1525\n",
      "train_loss = 88.1267\n",
      "test_loss = 74.7254\n",
      "****************************\n",
      "Epoch: 1526\n",
      "train_loss = 87.6699\n",
      "test_loss = 75.6272\n",
      "****************************\n",
      "Epoch: 1527\n",
      "train_loss = 88.0042\n",
      "test_loss = 77.3477\n",
      "****************************\n",
      "Epoch: 1528\n",
      "train_loss = 87.7372\n",
      "test_loss = 75.0896\n",
      "****************************\n",
      "Epoch: 1529\n",
      "train_loss = 88.7556\n",
      "test_loss = 74.3463\n",
      "****************************\n",
      "Epoch: 1530\n",
      "train_loss = 88.4281\n",
      "test_loss = 78.2537\n",
      "****************************\n",
      "Epoch: 1531\n",
      "train_loss = 90.5106\n",
      "test_loss = 81.8325\n",
      "****************************\n",
      "Epoch: 1532\n",
      "train_loss = 87.9019\n",
      "test_loss = 74.7462\n",
      "****************************\n",
      "Epoch: 1533\n",
      "train_loss = 88.2527\n",
      "test_loss = 74.4785\n",
      "****************************\n",
      "Epoch: 1534\n",
      "train_loss = 88.2385\n",
      "test_loss = 77.6569\n",
      "****************************\n",
      "Epoch: 1535\n",
      "train_loss = 87.6892\n",
      "test_loss = 75.7874\n",
      "****************************\n",
      "Epoch: 1536\n",
      "train_loss = 87.7334\n",
      "test_loss = 75.0507\n",
      "****************************\n",
      "Epoch: 1537\n",
      "train_loss = 88.1967\n",
      "test_loss = 74.5551\n",
      "****************************\n",
      "Epoch: 1538\n",
      "train_loss = 87.6641\n",
      "test_loss = 75.8542\n",
      "****************************\n",
      "Epoch: 1539\n",
      "train_loss = 87.6484\n",
      "test_loss = 75.5738\n",
      "****************************\n",
      "Epoch: 1540\n",
      "train_loss = 87.6916\n",
      "test_loss = 75.3353\n",
      "****************************\n",
      "Epoch: 1541\n",
      "train_loss = 87.6576\n",
      "test_loss = 75.4730\n",
      "****************************\n",
      "Epoch: 1542\n",
      "train_loss = 87.6543\n",
      "test_loss = 75.4879\n",
      "****************************\n",
      "Epoch: 1543\n",
      "train_loss = 88.0567\n",
      "test_loss = 77.3378\n",
      "****************************\n",
      "Epoch: 1544\n",
      "train_loss = 88.2706\n",
      "test_loss = 77.7751\n",
      "****************************\n",
      "Epoch: 1545\n",
      "train_loss = 87.7379\n",
      "test_loss = 74.9644\n",
      "****************************\n",
      "Epoch: 1546\n",
      "train_loss = 87.6913\n",
      "test_loss = 75.0369\n",
      "****************************\n",
      "Epoch: 1547\n",
      "train_loss = 87.7320\n",
      "test_loss = 74.9346\n",
      "****************************\n",
      "Epoch: 1548\n",
      "train_loss = 87.9210\n",
      "test_loss = 74.6284\n",
      "****************************\n",
      "Epoch: 1549\n",
      "train_loss = 88.3466\n",
      "test_loss = 74.3302\n",
      "****************************\n",
      "Epoch: 1550\n",
      "train_loss = 87.9850\n",
      "test_loss = 74.5339\n",
      "****************************\n",
      "Epoch: 1551\n",
      "train_loss = 87.5892\n",
      "test_loss = 75.5916\n",
      "****************************\n",
      "Epoch: 1552\n",
      "train_loss = 87.7343\n",
      "test_loss = 74.9018\n",
      "****************************\n",
      "Epoch: 1553\n",
      "train_loss = 88.5417\n",
      "test_loss = 78.5362\n",
      "****************************\n",
      "Epoch: 1554\n",
      "train_loss = 87.6198\n",
      "test_loss = 75.8078\n",
      "****************************\n",
      "Epoch: 1555\n",
      "train_loss = 87.6386\n",
      "test_loss = 75.2428\n",
      "****************************\n",
      "Epoch: 1556\n",
      "train_loss = 89.5091\n",
      "test_loss = 80.2218\n",
      "****************************\n",
      "Epoch: 1557\n",
      "train_loss = 87.8978\n",
      "test_loss = 74.6802\n",
      "****************************\n",
      "Epoch: 1558\n",
      "train_loss = 88.0829\n",
      "test_loss = 74.5501\n",
      "****************************\n",
      "Epoch: 1559\n",
      "train_loss = 87.8264\n",
      "test_loss = 76.4956\n",
      "****************************\n",
      "Epoch: 1560\n",
      "train_loss = 87.6763\n",
      "test_loss = 76.0712\n",
      "****************************\n",
      "Epoch: 1561\n",
      "train_loss = 88.1511\n",
      "test_loss = 77.5553\n",
      "****************************\n",
      "Epoch: 1562\n",
      "train_loss = 89.9968\n",
      "test_loss = 80.7281\n",
      "****************************\n",
      "Epoch: 1563\n",
      "train_loss = 87.6562\n",
      "test_loss = 75.3138\n",
      "****************************\n",
      "Epoch: 1564\n",
      "train_loss = 87.6307\n",
      "test_loss = 75.4865\n",
      "****************************\n",
      "Epoch: 1565\n",
      "train_loss = 87.6422\n",
      "test_loss = 75.5259\n",
      "****************************\n",
      "Epoch: 1566\n",
      "train_loss = 88.4855\n",
      "test_loss = 74.3384\n",
      "****************************\n",
      "Epoch: 1567\n",
      "train_loss = 87.7479\n",
      "test_loss = 74.9533\n",
      "****************************\n",
      "Epoch: 1568\n",
      "train_loss = 87.7257\n",
      "test_loss = 76.5094\n",
      "****************************\n",
      "Epoch: 1569\n",
      "train_loss = 87.7500\n",
      "test_loss = 76.5327\n",
      "****************************\n",
      "Epoch: 1570\n",
      "train_loss = 87.8441\n",
      "test_loss = 76.9344\n",
      "****************************\n",
      "Epoch: 1571\n",
      "train_loss = 88.4282\n",
      "test_loss = 78.1709\n",
      "****************************\n",
      "Epoch: 1572\n",
      "train_loss = 88.7221\n",
      "test_loss = 78.9594\n",
      "****************************\n",
      "Epoch: 1573\n",
      "train_loss = 87.7280\n",
      "test_loss = 76.0547\n",
      "****************************\n",
      "Epoch: 1574\n",
      "train_loss = 88.1733\n",
      "test_loss = 77.4406\n",
      "****************************\n",
      "Epoch: 1575\n",
      "train_loss = 87.8221\n",
      "test_loss = 76.7191\n",
      "****************************\n",
      "Epoch: 1576\n",
      "train_loss = 87.7903\n",
      "test_loss = 76.5601\n",
      "****************************\n",
      "Epoch: 1577\n",
      "train_loss = 87.6683\n",
      "test_loss = 75.3504\n",
      "****************************\n",
      "Epoch: 1578\n",
      "train_loss = 87.6661\n",
      "test_loss = 75.7584\n",
      "****************************\n",
      "Epoch: 1579\n",
      "train_loss = 87.7193\n",
      "test_loss = 76.2571\n",
      "****************************\n",
      "Epoch: 1580\n",
      "train_loss = 87.9143\n",
      "test_loss = 76.7887\n",
      "****************************\n",
      "Epoch: 1581\n",
      "train_loss = 88.9113\n",
      "test_loss = 74.2717\n",
      "****************************\n",
      "Epoch: 1582\n",
      "train_loss = 88.7974\n",
      "test_loss = 74.2841\n",
      "****************************\n",
      "Epoch: 1583\n",
      "train_loss = 87.7053\n",
      "test_loss = 76.0017\n",
      "****************************\n",
      "Epoch: 1584\n",
      "train_loss = 87.6259\n",
      "test_loss = 75.9934\n",
      "****************************\n",
      "Epoch: 1585\n",
      "train_loss = 88.3150\n",
      "test_loss = 74.4013\n",
      "****************************\n",
      "Epoch: 1586\n",
      "train_loss = 89.1133\n",
      "test_loss = 74.2587\n",
      "****************************\n",
      "Epoch: 1587\n",
      "train_loss = 87.9961\n",
      "test_loss = 74.6236\n",
      "****************************\n",
      "Epoch: 1588\n",
      "train_loss = 87.8417\n",
      "test_loss = 74.8150\n",
      "****************************\n",
      "Epoch: 1589\n",
      "train_loss = 87.7866\n",
      "test_loss = 76.7122\n",
      "****************************\n",
      "Epoch: 1590\n",
      "train_loss = 87.7363\n",
      "test_loss = 75.0018\n",
      "****************************\n",
      "Epoch: 1591\n",
      "train_loss = 87.7194\n",
      "test_loss = 76.0952\n",
      "****************************\n",
      "Epoch: 1592\n",
      "train_loss = 87.6904\n",
      "test_loss = 75.1933\n",
      "****************************\n",
      "Epoch: 1593\n",
      "train_loss = 87.8993\n",
      "test_loss = 74.6824\n",
      "****************************\n",
      "Epoch: 1594\n",
      "train_loss = 88.0886\n",
      "test_loss = 77.0916\n",
      "****************************\n",
      "Epoch: 1595\n",
      "train_loss = 88.3426\n",
      "test_loss = 78.2700\n",
      "****************************\n",
      "Epoch: 1596\n",
      "train_loss = 88.1846\n",
      "test_loss = 74.5895\n",
      "****************************\n",
      "Epoch: 1597\n",
      "train_loss = 87.9527\n",
      "test_loss = 76.9204\n",
      "****************************\n",
      "Epoch: 1598\n",
      "train_loss = 87.9468\n",
      "test_loss = 77.1187\n",
      "****************************\n",
      "Epoch: 1599\n",
      "train_loss = 88.0360\n",
      "test_loss = 74.6153\n",
      "****************************\n",
      "Epoch: 1600\n",
      "train_loss = 87.8258\n",
      "test_loss = 74.8265\n",
      "****************************\n",
      "Epoch: 1601\n",
      "train_loss = 87.6104\n",
      "test_loss = 75.4631\n",
      "****************************\n",
      "Epoch: 1602\n",
      "train_loss = 87.6255\n",
      "test_loss = 75.2875\n",
      "****************************\n",
      "Epoch: 1603\n",
      "train_loss = 87.6166\n",
      "test_loss = 75.3751\n",
      "****************************\n",
      "Epoch: 1604\n",
      "train_loss = 87.6899\n",
      "test_loss = 76.2761\n",
      "****************************\n",
      "Epoch: 1605\n",
      "train_loss = 87.8437\n",
      "test_loss = 74.7660\n",
      "****************************\n",
      "Epoch: 1606\n",
      "train_loss = 87.6849\n",
      "test_loss = 75.2032\n",
      "****************************\n",
      "Epoch: 1607\n",
      "train_loss = 87.6277\n",
      "test_loss = 75.7991\n",
      "****************************\n",
      "Epoch: 1608\n",
      "train_loss = 87.8924\n",
      "test_loss = 76.9666\n",
      "****************************\n",
      "Epoch: 1609\n",
      "train_loss = 87.7451\n",
      "test_loss = 76.2419\n",
      "****************************\n",
      "Epoch: 1610\n",
      "train_loss = 88.0813\n",
      "test_loss = 75.1865\n",
      "****************************\n",
      "Epoch: 1611\n",
      "train_loss = 88.6044\n",
      "test_loss = 74.4212\n",
      "****************************\n",
      "Epoch: 1612\n",
      "train_loss = 87.8362\n",
      "test_loss = 76.8024\n",
      "****************************\n",
      "Epoch: 1613\n",
      "train_loss = 87.6960\n",
      "test_loss = 76.1343\n",
      "****************************\n",
      "Epoch: 1614\n",
      "train_loss = 87.6298\n",
      "test_loss = 75.6813\n",
      "****************************\n",
      "Epoch: 1615\n",
      "train_loss = 88.7725\n",
      "test_loss = 79.0655\n",
      "****************************\n",
      "Epoch: 1616\n",
      "train_loss = 88.3607\n",
      "test_loss = 74.3599\n",
      "****************************\n",
      "Epoch: 1617\n",
      "train_loss = 87.6110\n",
      "test_loss = 75.6505\n",
      "****************************\n",
      "Epoch: 1618\n",
      "train_loss = 90.6712\n",
      "test_loss = 82.1498\n",
      "****************************\n",
      "Epoch: 1619\n",
      "train_loss = 87.6584\n",
      "test_loss = 75.3767\n",
      "****************************\n",
      "Epoch: 1620\n",
      "train_loss = 87.6215\n",
      "test_loss = 75.4889\n",
      "****************************\n",
      "Epoch: 1621\n",
      "train_loss = 87.6538\n",
      "test_loss = 75.1627\n",
      "****************************\n",
      "Epoch: 1622\n",
      "train_loss = 87.6242\n",
      "test_loss = 75.8015\n",
      "****************************\n",
      "Epoch: 1623\n",
      "train_loss = 87.6238\n",
      "test_loss = 75.8486\n",
      "****************************\n",
      "Epoch: 1624\n",
      "train_loss = 87.6559\n",
      "test_loss = 76.2897\n",
      "****************************\n",
      "Epoch: 1625\n",
      "train_loss = 87.5896\n",
      "test_loss = 75.6836\n",
      "****************************\n",
      "Epoch: 1626\n",
      "train_loss = 87.6556\n",
      "test_loss = 76.3362\n",
      "****************************\n",
      "Epoch: 1627\n",
      "train_loss = 87.9292\n",
      "test_loss = 74.7013\n",
      "****************************\n",
      "Epoch: 1628\n",
      "train_loss = 87.7685\n",
      "test_loss = 76.4902\n",
      "****************************\n",
      "Epoch: 1629\n",
      "train_loss = 89.1125\n",
      "test_loss = 79.7834\n",
      "****************************\n",
      "Epoch: 1630\n",
      "train_loss = 87.7522\n",
      "test_loss = 74.8898\n",
      "****************************\n",
      "Epoch: 1631\n",
      "train_loss = 88.3589\n",
      "test_loss = 74.3802\n",
      "****************************\n",
      "Epoch: 1632\n",
      "train_loss = 87.6410\n",
      "test_loss = 75.2531\n",
      "****************************\n",
      "Epoch: 1633\n",
      "train_loss = 88.0509\n",
      "test_loss = 74.5471\n",
      "****************************\n",
      "Epoch: 1634\n",
      "train_loss = 87.6770\n",
      "test_loss = 75.0978\n",
      "****************************\n",
      "Epoch: 1635\n",
      "train_loss = 87.6800\n",
      "test_loss = 76.0574\n",
      "****************************\n",
      "Epoch: 1636\n",
      "train_loss = 87.6813\n",
      "test_loss = 76.0946\n",
      "****************************\n",
      "Epoch: 1637\n",
      "train_loss = 87.9263\n",
      "test_loss = 76.9586\n",
      "****************************\n",
      "Epoch: 1638\n",
      "train_loss = 88.2215\n",
      "test_loss = 75.1293\n",
      "****************************\n",
      "Epoch: 1639\n",
      "train_loss = 88.7051\n",
      "test_loss = 74.3677\n",
      "****************************\n",
      "Epoch: 1640\n",
      "train_loss = 87.6451\n",
      "test_loss = 75.5257\n",
      "****************************\n",
      "Epoch: 1641\n",
      "train_loss = 87.7092\n",
      "test_loss = 75.0569\n",
      "****************************\n",
      "Epoch: 1642\n",
      "train_loss = 87.6668\n",
      "test_loss = 75.6449\n",
      "****************************\n",
      "Epoch: 1643\n",
      "train_loss = 88.3328\n",
      "test_loss = 74.7404\n",
      "****************************\n",
      "Epoch: 1644\n",
      "train_loss = 88.8429\n",
      "test_loss = 78.9285\n",
      "****************************\n",
      "Epoch: 1645\n",
      "train_loss = 88.3643\n",
      "test_loss = 78.1363\n",
      "****************************\n",
      "Epoch: 1646\n",
      "train_loss = 88.5279\n",
      "test_loss = 78.6305\n",
      "****************************\n",
      "Epoch: 1647\n",
      "train_loss = 87.6839\n",
      "test_loss = 76.2460\n",
      "****************************\n",
      "Epoch: 1648\n",
      "train_loss = 87.6902\n",
      "test_loss = 76.2848\n",
      "****************************\n",
      "Epoch: 1649\n",
      "train_loss = 88.1600\n",
      "test_loss = 77.8399\n",
      "****************************\n",
      "Epoch: 1650\n",
      "train_loss = 87.8229\n",
      "test_loss = 74.8759\n",
      "****************************\n",
      "Epoch: 1651\n",
      "train_loss = 87.6374\n",
      "test_loss = 75.8847\n",
      "****************************\n",
      "Epoch: 1652\n",
      "train_loss = 88.2130\n",
      "test_loss = 74.4909\n",
      "****************************\n",
      "Epoch: 1653\n",
      "train_loss = 87.9579\n",
      "test_loss = 77.3136\n",
      "****************************\n",
      "Epoch: 1654\n",
      "train_loss = 87.9706\n",
      "test_loss = 74.6167\n",
      "****************************\n",
      "Epoch: 1655\n",
      "train_loss = 87.8517\n",
      "test_loss = 74.7778\n",
      "****************************\n",
      "Epoch: 1656\n",
      "train_loss = 88.5078\n",
      "test_loss = 74.3609\n",
      "****************************\n",
      "Epoch: 1657\n",
      "train_loss = 87.8973\n",
      "test_loss = 74.7404\n",
      "****************************\n",
      "Epoch: 1658\n",
      "train_loss = 88.2415\n",
      "test_loss = 78.0022\n",
      "****************************\n",
      "Epoch: 1659\n",
      "train_loss = 88.0658\n",
      "test_loss = 77.5983\n",
      "****************************\n",
      "Epoch: 1660\n",
      "train_loss = 88.6937\n",
      "test_loss = 74.2856\n",
      "****************************\n",
      "Epoch: 1661\n",
      "train_loss = 87.7084\n",
      "test_loss = 75.0175\n",
      "****************************\n",
      "Epoch: 1662\n",
      "train_loss = 87.6603\n",
      "test_loss = 75.2209\n",
      "****************************\n",
      "Epoch: 1663\n",
      "train_loss = 87.8063\n",
      "test_loss = 76.9444\n",
      "****************************\n",
      "Epoch: 1664\n",
      "train_loss = 87.6676\n",
      "test_loss = 76.4397\n",
      "****************************\n",
      "Epoch: 1665\n",
      "train_loss = 87.6212\n",
      "test_loss = 75.4762\n",
      "****************************\n",
      "Epoch: 1666\n",
      "train_loss = 88.3524\n",
      "test_loss = 74.3865\n",
      "****************************\n",
      "Epoch: 1667\n",
      "train_loss = 90.2715\n",
      "test_loss = 81.6403\n",
      "****************************\n",
      "Epoch: 1668\n",
      "train_loss = 87.7206\n",
      "test_loss = 76.4911\n",
      "****************************\n",
      "Epoch: 1669\n",
      "train_loss = 87.7247\n",
      "test_loss = 74.9995\n",
      "****************************\n",
      "Epoch: 1670\n",
      "train_loss = 89.3822\n",
      "test_loss = 80.2250\n",
      "****************************\n",
      "Epoch: 1671\n",
      "train_loss = 87.7981\n",
      "test_loss = 74.8801\n",
      "****************************\n",
      "Epoch: 1672\n",
      "train_loss = 87.6619\n",
      "test_loss = 76.2441\n",
      "****************************\n",
      "Epoch: 1673\n",
      "train_loss = 87.6395\n",
      "test_loss = 76.0563\n",
      "****************************\n",
      "Epoch: 1674\n",
      "train_loss = 90.2489\n",
      "test_loss = 81.5075\n",
      "****************************\n",
      "Epoch: 1675\n",
      "train_loss = 87.6151\n",
      "test_loss = 75.3959\n",
      "****************************\n",
      "Epoch: 1676\n",
      "train_loss = 87.5949\n",
      "test_loss = 75.6313\n",
      "****************************\n",
      "Epoch: 1677\n",
      "train_loss = 87.7570\n",
      "test_loss = 76.7103\n",
      "****************************\n",
      "Epoch: 1678\n",
      "train_loss = 87.6969\n",
      "test_loss = 76.0417\n",
      "****************************\n",
      "Epoch: 1679\n",
      "train_loss = 87.7084\n",
      "test_loss = 76.2574\n",
      "****************************\n",
      "Epoch: 1680\n",
      "train_loss = 87.8213\n",
      "test_loss = 76.7955\n",
      "****************************\n",
      "Epoch: 1681\n",
      "train_loss = 87.6599\n",
      "test_loss = 75.0877\n",
      "****************************\n",
      "Epoch: 1682\n",
      "train_loss = 87.8699\n",
      "test_loss = 74.6899\n",
      "****************************\n",
      "Epoch: 1683\n",
      "train_loss = 87.6302\n",
      "test_loss = 76.1260\n",
      "****************************\n",
      "Epoch: 1684\n",
      "train_loss = 88.7524\n",
      "test_loss = 74.2486\n",
      "****************************\n",
      "Epoch: 1685\n",
      "train_loss = 87.7289\n",
      "test_loss = 76.5886\n",
      "****************************\n",
      "Epoch: 1686\n",
      "train_loss = 87.8935\n",
      "test_loss = 76.9931\n",
      "****************************\n",
      "Epoch: 1687\n",
      "train_loss = 87.5943\n",
      "test_loss = 75.2409\n",
      "****************************\n",
      "Epoch: 1688\n",
      "train_loss = 87.7127\n",
      "test_loss = 74.9256\n",
      "****************************\n",
      "Epoch: 1689\n",
      "train_loss = 88.4625\n",
      "test_loss = 78.1125\n",
      "****************************\n",
      "Epoch: 1690\n",
      "train_loss = 88.1773\n",
      "test_loss = 77.6750\n",
      "****************************\n",
      "Epoch: 1691\n",
      "train_loss = 88.3914\n",
      "test_loss = 78.1232\n",
      "****************************\n",
      "Epoch: 1692\n",
      "train_loss = 87.7890\n",
      "test_loss = 76.5818\n",
      "****************************\n",
      "Epoch: 1693\n",
      "train_loss = 87.9753\n",
      "test_loss = 74.7063\n",
      "****************************\n",
      "Epoch: 1694\n",
      "train_loss = 87.6615\n",
      "test_loss = 76.2394\n",
      "****************************\n",
      "Epoch: 1695\n",
      "train_loss = 87.5997\n",
      "test_loss = 75.6303\n",
      "****************************\n",
      "Epoch: 1696\n",
      "train_loss = 87.7367\n",
      "test_loss = 76.4986\n",
      "****************************\n",
      "Epoch: 1697\n",
      "train_loss = 87.6644\n",
      "test_loss = 75.9625\n",
      "****************************\n",
      "Epoch: 1698\n",
      "train_loss = 87.9656\n",
      "test_loss = 74.5938\n",
      "****************************\n",
      "Epoch: 1699\n",
      "train_loss = 88.2949\n",
      "test_loss = 77.7837\n",
      "****************************\n",
      "Epoch: 1700\n",
      "train_loss = 87.6903\n",
      "test_loss = 75.1949\n",
      "****************************\n",
      "Epoch: 1701\n",
      "train_loss = 88.0772\n",
      "test_loss = 77.5637\n",
      "****************************\n",
      "Epoch: 1702\n",
      "train_loss = 87.6133\n",
      "test_loss = 75.4317\n",
      "****************************\n",
      "Epoch: 1703\n",
      "train_loss = 87.8202\n",
      "test_loss = 76.8659\n",
      "****************************\n",
      "Epoch: 1704\n",
      "train_loss = 87.9834\n",
      "test_loss = 74.5637\n",
      "****************************\n",
      "Epoch: 1705\n",
      "train_loss = 93.0349\n",
      "test_loss = 85.4705\n",
      "****************************\n",
      "Epoch: 1706\n",
      "train_loss = 87.6509\n",
      "test_loss = 75.2627\n",
      "****************************\n",
      "Epoch: 1707\n",
      "train_loss = 88.0254\n",
      "test_loss = 74.5902\n",
      "****************************\n",
      "Epoch: 1708\n",
      "train_loss = 88.5347\n",
      "test_loss = 74.3189\n",
      "****************************\n",
      "Epoch: 1709\n",
      "train_loss = 88.1893\n",
      "test_loss = 74.4647\n",
      "****************************\n",
      "Epoch: 1710\n",
      "train_loss = 87.7984\n",
      "test_loss = 74.7937\n",
      "****************************\n",
      "Epoch: 1711\n",
      "train_loss = 88.1191\n",
      "test_loss = 77.3843\n",
      "****************************\n",
      "Epoch: 1712\n",
      "train_loss = 87.6461\n",
      "test_loss = 75.1388\n",
      "****************************\n",
      "Epoch: 1713\n",
      "train_loss = 88.2290\n",
      "test_loss = 74.4092\n",
      "****************************\n",
      "Epoch: 1714\n",
      "train_loss = 87.7347\n",
      "test_loss = 74.8733\n",
      "****************************\n",
      "Epoch: 1715\n",
      "train_loss = 87.6118\n",
      "test_loss = 75.7708\n",
      "****************************\n",
      "Epoch: 1716\n",
      "train_loss = 87.8883\n",
      "test_loss = 74.6579\n",
      "****************************\n",
      "Epoch: 1717\n",
      "train_loss = 88.8905\n",
      "test_loss = 74.3014\n",
      "****************************\n",
      "Epoch: 1718\n",
      "train_loss = 87.7907\n",
      "test_loss = 76.6993\n",
      "****************************\n",
      "Epoch: 1719\n",
      "train_loss = 87.6129\n",
      "test_loss = 75.7609\n",
      "****************************\n",
      "Epoch: 1720\n",
      "train_loss = 87.7564\n",
      "test_loss = 74.8413\n",
      "****************************\n",
      "Epoch: 1721\n",
      "train_loss = 87.7392\n",
      "test_loss = 74.8486\n",
      "****************************\n",
      "Epoch: 1722\n",
      "train_loss = 87.7071\n",
      "test_loss = 74.9147\n",
      "****************************\n",
      "Epoch: 1723\n",
      "train_loss = 87.6210\n",
      "test_loss = 75.9416\n",
      "****************************\n",
      "Epoch: 1724\n",
      "train_loss = 87.6544\n",
      "test_loss = 75.1008\n",
      "****************************\n",
      "Epoch: 1725\n",
      "train_loss = 87.8484\n",
      "test_loss = 76.8703\n",
      "****************************\n",
      "Epoch: 1726\n",
      "train_loss = 88.6967\n",
      "test_loss = 78.7722\n",
      "****************************\n",
      "Epoch: 1727\n",
      "train_loss = 87.6616\n",
      "test_loss = 76.2141\n",
      "****************************\n",
      "Epoch: 1728\n",
      "train_loss = 87.6095\n",
      "test_loss = 75.9115\n",
      "****************************\n",
      "Epoch: 1729\n",
      "train_loss = 87.7040\n",
      "test_loss = 74.9790\n",
      "****************************\n",
      "Epoch: 1730\n",
      "train_loss = 87.6491\n",
      "test_loss = 76.0099\n",
      "****************************\n",
      "Epoch: 1731\n",
      "train_loss = 87.6605\n",
      "test_loss = 76.1048\n",
      "****************************\n",
      "Epoch: 1732\n",
      "train_loss = 87.6027\n",
      "test_loss = 75.6860\n",
      "****************************\n",
      "Epoch: 1733\n",
      "train_loss = 87.5922\n",
      "test_loss = 75.7848\n",
      "****************************\n",
      "Epoch: 1734\n",
      "train_loss = 90.8107\n",
      "test_loss = 82.3429\n",
      "****************************\n",
      "Epoch: 1735\n",
      "train_loss = 87.6052\n",
      "test_loss = 75.9547\n",
      "****************************\n",
      "Epoch: 1736\n",
      "train_loss = 87.8777\n",
      "test_loss = 77.0719\n",
      "****************************\n",
      "Epoch: 1737\n",
      "train_loss = 87.9860\n",
      "test_loss = 74.4966\n",
      "****************************\n",
      "Epoch: 1738\n",
      "train_loss = 87.6068\n",
      "test_loss = 75.3546\n",
      "****************************\n",
      "Epoch: 1739\n",
      "train_loss = 87.8115\n",
      "test_loss = 76.9432\n",
      "****************************\n",
      "Epoch: 1740\n",
      "train_loss = 90.2125\n",
      "test_loss = 81.5448\n",
      "****************************\n",
      "Epoch: 1741\n",
      "train_loss = 87.8557\n",
      "test_loss = 76.9214\n",
      "****************************\n",
      "Epoch: 1742\n",
      "train_loss = 88.6296\n",
      "test_loss = 78.8082\n",
      "****************************\n",
      "Epoch: 1743\n",
      "train_loss = 87.6361\n",
      "test_loss = 75.0696\n",
      "****************************\n",
      "Epoch: 1744\n",
      "train_loss = 93.9307\n",
      "test_loss = 86.9962\n",
      "****************************\n",
      "Epoch: 1745\n",
      "train_loss = 87.5935\n",
      "test_loss = 75.9788\n",
      "****************************\n",
      "Epoch: 1746\n",
      "train_loss = 87.7417\n",
      "test_loss = 74.8412\n",
      "****************************\n",
      "Epoch: 1747\n",
      "train_loss = 88.5473\n",
      "test_loss = 78.6190\n",
      "****************************\n",
      "Epoch: 1748\n",
      "train_loss = 88.2332\n",
      "test_loss = 74.3856\n",
      "****************************\n",
      "Epoch: 1749\n",
      "train_loss = 87.6944\n",
      "test_loss = 75.0631\n",
      "****************************\n",
      "Epoch: 1750\n",
      "train_loss = 87.6914\n",
      "test_loss = 75.1192\n",
      "****************************\n",
      "Epoch: 1751\n",
      "train_loss = 87.8689\n",
      "test_loss = 74.6915\n",
      "****************************\n",
      "Epoch: 1752\n",
      "train_loss = 87.6061\n",
      "test_loss = 75.5378\n",
      "****************************\n",
      "Epoch: 1753\n",
      "train_loss = 87.5935\n",
      "test_loss = 75.5166\n",
      "****************************\n",
      "Epoch: 1754\n",
      "train_loss = 87.8943\n",
      "test_loss = 76.9152\n",
      "****************************\n",
      "Epoch: 1755\n",
      "train_loss = 88.3943\n",
      "test_loss = 74.3401\n",
      "****************************\n",
      "Epoch: 1756\n",
      "train_loss = 88.0142\n",
      "test_loss = 77.3029\n",
      "****************************\n",
      "Epoch: 1757\n",
      "train_loss = 87.5588\n",
      "test_loss = 75.6043\n",
      "****************************\n",
      "Epoch: 1758\n",
      "train_loss = 88.7275\n",
      "test_loss = 78.7432\n",
      "****************************\n",
      "Epoch: 1759\n",
      "train_loss = 87.8690\n",
      "test_loss = 74.6665\n",
      "****************************\n",
      "Epoch: 1760\n",
      "train_loss = 87.7412\n",
      "test_loss = 76.4576\n",
      "****************************\n",
      "Epoch: 1761\n",
      "train_loss = 87.6409\n",
      "test_loss = 75.3071\n",
      "****************************\n",
      "Epoch: 1762\n",
      "train_loss = 87.5884\n",
      "test_loss = 75.7352\n",
      "****************************\n",
      "Epoch: 1763\n",
      "train_loss = 88.0171\n",
      "test_loss = 74.5361\n",
      "****************************\n",
      "Epoch: 1764\n",
      "train_loss = 87.6556\n",
      "test_loss = 76.0094\n",
      "****************************\n",
      "Epoch: 1765\n",
      "train_loss = 90.2159\n",
      "test_loss = 81.5776\n",
      "****************************\n",
      "Epoch: 1766\n",
      "train_loss = 87.6020\n",
      "test_loss = 75.3542\n",
      "****************************\n",
      "Epoch: 1767\n",
      "train_loss = 87.5976\n",
      "test_loss = 75.7577\n",
      "****************************\n",
      "Epoch: 1768\n",
      "train_loss = 87.9563\n",
      "test_loss = 77.1904\n",
      "****************************\n",
      "Epoch: 1769\n",
      "train_loss = 87.9183\n",
      "test_loss = 77.0186\n",
      "****************************\n",
      "Epoch: 1770\n",
      "train_loss = 87.6253\n",
      "test_loss = 75.3397\n",
      "****************************\n",
      "Epoch: 1771\n",
      "train_loss = 89.1955\n",
      "test_loss = 79.5775\n",
      "****************************\n",
      "Epoch: 1772\n",
      "train_loss = 87.8529\n",
      "test_loss = 74.7056\n",
      "****************************\n",
      "Epoch: 1773\n",
      "train_loss = 87.6091\n",
      "test_loss = 75.2464\n",
      "****************************\n",
      "Epoch: 1774\n",
      "train_loss = 87.6275\n",
      "test_loss = 75.0986\n",
      "****************************\n",
      "Epoch: 1775\n",
      "train_loss = 87.6608\n",
      "test_loss = 75.0112\n",
      "****************************\n",
      "Epoch: 1776\n",
      "train_loss = 88.1457\n",
      "test_loss = 77.8713\n",
      "****************************\n",
      "Epoch: 1777\n",
      "train_loss = 88.1211\n",
      "test_loss = 74.4819\n",
      "****************************\n",
      "Epoch: 1778\n",
      "train_loss = 88.7484\n",
      "test_loss = 74.2580\n",
      "****************************\n",
      "Epoch: 1779\n",
      "train_loss = 87.6151\n",
      "test_loss = 75.0926\n",
      "****************************\n",
      "Epoch: 1780\n",
      "train_loss = 87.7152\n",
      "test_loss = 76.5405\n",
      "****************************\n",
      "Epoch: 1781\n",
      "train_loss = 88.1222\n",
      "test_loss = 77.8235\n",
      "****************************\n",
      "Epoch: 1782\n",
      "train_loss = 87.7773\n",
      "test_loss = 74.7273\n",
      "****************************\n",
      "Epoch: 1783\n",
      "train_loss = 87.7724\n",
      "test_loss = 74.8437\n",
      "****************************\n",
      "Epoch: 1784\n",
      "train_loss = 87.5922\n",
      "test_loss = 75.5151\n",
      "****************************\n",
      "Epoch: 1785\n",
      "train_loss = 90.9927\n",
      "test_loss = 82.6285\n",
      "****************************\n",
      "Epoch: 1786\n",
      "train_loss = 87.5637\n",
      "test_loss = 75.4664\n",
      "****************************\n",
      "Epoch: 1787\n",
      "train_loss = 88.4904\n",
      "test_loss = 74.3224\n",
      "****************************\n",
      "Epoch: 1788\n",
      "train_loss = 87.7753\n",
      "test_loss = 76.7785\n",
      "****************************\n",
      "Epoch: 1789\n",
      "train_loss = 87.5518\n",
      "test_loss = 75.5531\n",
      "****************************\n",
      "Epoch: 1790\n",
      "train_loss = 88.0268\n",
      "test_loss = 74.4688\n",
      "****************************\n",
      "Epoch: 1791\n",
      "train_loss = 87.6014\n",
      "test_loss = 75.9019\n",
      "****************************\n",
      "Epoch: 1792\n",
      "train_loss = 87.6400\n",
      "test_loss = 75.0432\n",
      "****************************\n",
      "Epoch: 1793\n",
      "train_loss = 92.1884\n",
      "test_loss = 84.3103\n",
      "****************************\n",
      "Epoch: 1794\n",
      "train_loss = 87.6331\n",
      "test_loss = 76.2255\n",
      "****************************\n",
      "Epoch: 1795\n",
      "train_loss = 88.5989\n",
      "test_loss = 74.2700\n",
      "****************************\n",
      "Epoch: 1796\n",
      "train_loss = 88.0998\n",
      "test_loss = 74.4083\n",
      "****************************\n",
      "Epoch: 1797\n",
      "train_loss = 87.8456\n",
      "test_loss = 76.7409\n",
      "****************************\n",
      "Epoch: 1798\n",
      "train_loss = 88.1066\n",
      "test_loss = 74.4170\n",
      "****************************\n",
      "Epoch: 1799\n",
      "train_loss = 87.8319\n",
      "test_loss = 74.6784\n",
      "****************************\n",
      "Epoch: 1800\n",
      "train_loss = 87.6808\n",
      "test_loss = 76.4171\n",
      "****************************\n",
      "Epoch: 1801\n",
      "train_loss = 87.5713\n",
      "test_loss = 75.4334\n",
      "****************************\n",
      "Epoch: 1802\n",
      "train_loss = 87.7472\n",
      "test_loss = 76.7254\n",
      "****************************\n",
      "Epoch: 1803\n",
      "train_loss = 87.5402\n",
      "test_loss = 75.4979\n",
      "****************************\n",
      "Epoch: 1804\n",
      "train_loss = 88.1534\n",
      "test_loss = 74.3557\n",
      "****************************\n",
      "Epoch: 1805\n",
      "train_loss = 89.2609\n",
      "test_loss = 79.5911\n",
      "****************************\n",
      "Epoch: 1806\n",
      "train_loss = 87.6677\n",
      "test_loss = 74.9642\n",
      "****************************\n",
      "Epoch: 1807\n",
      "train_loss = 87.8456\n",
      "test_loss = 74.6538\n",
      "****************************\n",
      "Epoch: 1808\n",
      "train_loss = 87.8889\n",
      "test_loss = 76.2501\n",
      "****************************\n",
      "Epoch: 1809\n",
      "train_loss = 88.1179\n",
      "test_loss = 77.4902\n",
      "****************************\n",
      "Epoch: 1810\n",
      "train_loss = 87.6295\n",
      "test_loss = 75.4348\n",
      "****************************\n",
      "Epoch: 1811\n",
      "train_loss = 88.3687\n",
      "test_loss = 74.3438\n",
      "****************************\n",
      "Epoch: 1812\n",
      "train_loss = 87.6866\n",
      "test_loss = 75.0145\n",
      "****************************\n",
      "Epoch: 1813\n",
      "train_loss = 87.6861\n",
      "test_loss = 75.9767\n",
      "****************************\n",
      "Epoch: 1814\n",
      "train_loss = 90.2348\n",
      "test_loss = 81.5300\n",
      "****************************\n",
      "Epoch: 1815\n",
      "train_loss = 87.8183\n",
      "test_loss = 76.7779\n",
      "****************************\n",
      "Epoch: 1816\n",
      "train_loss = 88.1100\n",
      "test_loss = 74.4554\n",
      "****************************\n",
      "Epoch: 1817\n",
      "train_loss = 87.7477\n",
      "test_loss = 74.8377\n",
      "****************************\n",
      "Epoch: 1818\n",
      "train_loss = 87.6628\n",
      "test_loss = 76.0517\n",
      "****************************\n",
      "Epoch: 1819\n",
      "train_loss = 89.7226\n",
      "test_loss = 80.4361\n",
      "****************************\n",
      "Epoch: 1820\n",
      "train_loss = 88.4362\n",
      "test_loss = 74.3234\n",
      "****************************\n",
      "Epoch: 1821\n",
      "train_loss = 87.6499\n",
      "test_loss = 75.0939\n",
      "****************************\n",
      "Epoch: 1822\n",
      "train_loss = 87.6536\n",
      "test_loss = 75.0282\n",
      "****************************\n",
      "Epoch: 1823\n",
      "train_loss = 87.7275\n",
      "test_loss = 76.4989\n",
      "****************************\n",
      "Epoch: 1824\n",
      "train_loss = 88.7299\n",
      "test_loss = 78.8061\n",
      "****************************\n",
      "Epoch: 1825\n",
      "train_loss = 87.5870\n",
      "test_loss = 75.3166\n",
      "****************************\n",
      "Epoch: 1826\n",
      "train_loss = 87.6070\n",
      "test_loss = 75.7763\n",
      "****************************\n",
      "Epoch: 1827\n",
      "train_loss = 87.6210\n",
      "test_loss = 75.4520\n",
      "****************************\n",
      "Epoch: 1828\n",
      "train_loss = 88.3206\n",
      "test_loss = 74.3760\n",
      "****************************\n",
      "Epoch: 1829\n",
      "train_loss = 87.6081\n",
      "test_loss = 75.3090\n",
      "****************************\n",
      "Epoch: 1830\n",
      "train_loss = 87.9668\n",
      "test_loss = 74.6040\n",
      "****************************\n",
      "Epoch: 1831\n",
      "train_loss = 87.9769\n",
      "test_loss = 77.0754\n",
      "****************************\n",
      "Epoch: 1832\n",
      "train_loss = 87.9183\n",
      "test_loss = 74.6396\n",
      "****************************\n",
      "Epoch: 1833\n",
      "train_loss = 89.1220\n",
      "test_loss = 74.2593\n",
      "****************************\n",
      "Epoch: 1834\n",
      "train_loss = 87.6328\n",
      "test_loss = 76.0160\n",
      "****************************\n",
      "Epoch: 1835\n",
      "train_loss = 87.6501\n",
      "test_loss = 76.3414\n",
      "****************************\n",
      "Epoch: 1836\n",
      "train_loss = 89.7613\n",
      "test_loss = 80.5781\n",
      "****************************\n",
      "Epoch: 1837\n",
      "train_loss = 87.6155\n",
      "test_loss = 75.6210\n",
      "****************************\n",
      "Epoch: 1838\n",
      "train_loss = 87.7886\n",
      "test_loss = 74.8398\n",
      "****************************\n",
      "Epoch: 1839\n",
      "train_loss = 87.6805\n",
      "test_loss = 76.3622\n",
      "****************************\n",
      "Epoch: 1840\n",
      "train_loss = 87.8551\n",
      "test_loss = 76.4455\n",
      "****************************\n",
      "Epoch: 1841\n",
      "train_loss = 87.8600\n",
      "test_loss = 76.7247\n",
      "****************************\n",
      "Epoch: 1842\n",
      "train_loss = 87.6714\n",
      "test_loss = 75.1087\n",
      "****************************\n",
      "Epoch: 1843\n",
      "train_loss = 87.6851\n",
      "test_loss = 76.1281\n",
      "****************************\n",
      "Epoch: 1844\n",
      "train_loss = 87.6834\n",
      "test_loss = 74.9459\n",
      "****************************\n",
      "Epoch: 1845\n",
      "train_loss = 87.6110\n",
      "test_loss = 75.9621\n",
      "****************************\n",
      "Epoch: 1846\n",
      "train_loss = 88.1151\n",
      "test_loss = 74.4611\n",
      "****************************\n",
      "Epoch: 1847\n",
      "train_loss = 87.6390\n",
      "test_loss = 76.1315\n",
      "****************************\n",
      "Epoch: 1848\n",
      "train_loss = 87.6038\n",
      "test_loss = 75.6892\n",
      "****************************\n",
      "Epoch: 1849\n",
      "train_loss = 87.5719\n",
      "test_loss = 75.5877\n",
      "****************************\n",
      "Epoch: 1850\n",
      "train_loss = 87.5514\n",
      "test_loss = 75.8110\n",
      "****************************\n",
      "Epoch: 1851\n",
      "train_loss = 88.7969\n",
      "test_loss = 79.0854\n",
      "****************************\n",
      "Epoch: 1852\n",
      "train_loss = 87.6347\n",
      "test_loss = 76.3054\n",
      "****************************\n",
      "Epoch: 1853\n",
      "train_loss = 88.3632\n",
      "test_loss = 74.3063\n",
      "****************************\n",
      "Epoch: 1854\n",
      "train_loss = 87.7886\n",
      "test_loss = 74.7258\n",
      "****************************\n",
      "Epoch: 1855\n",
      "train_loss = 88.1673\n",
      "test_loss = 74.4021\n",
      "****************************\n",
      "Epoch: 1856\n",
      "train_loss = 88.0399\n",
      "test_loss = 77.4754\n",
      "****************************\n",
      "Epoch: 1857\n",
      "train_loss = 87.7299\n",
      "test_loss = 76.4140\n",
      "****************************\n",
      "Epoch: 1858\n",
      "train_loss = 87.9079\n",
      "test_loss = 74.5929\n",
      "****************************\n",
      "Epoch: 1859\n",
      "train_loss = 88.1191\n",
      "test_loss = 77.5749\n",
      "****************************\n",
      "Epoch: 1860\n",
      "train_loss = 88.0856\n",
      "test_loss = 74.5012\n",
      "****************************\n",
      "Epoch: 1861\n",
      "train_loss = 87.6935\n",
      "test_loss = 76.2166\n",
      "****************************\n",
      "Epoch: 1862\n",
      "train_loss = 87.5846\n",
      "test_loss = 75.3420\n",
      "****************************\n",
      "Epoch: 1863\n",
      "train_loss = 87.6575\n",
      "test_loss = 76.2192\n",
      "****************************\n",
      "Epoch: 1864\n",
      "train_loss = 88.0819\n",
      "test_loss = 74.4831\n",
      "****************************\n",
      "Epoch: 1865\n",
      "train_loss = 87.6021\n",
      "test_loss = 75.5346\n",
      "****************************\n",
      "Epoch: 1866\n",
      "train_loss = 87.7752\n",
      "test_loss = 74.9525\n",
      "****************************\n",
      "Epoch: 1867\n",
      "train_loss = 87.6050\n",
      "test_loss = 75.5722\n",
      "****************************\n",
      "Epoch: 1868\n",
      "train_loss = 87.6728\n",
      "test_loss = 75.0231\n",
      "****************************\n",
      "Epoch: 1869\n",
      "train_loss = 88.3237\n",
      "test_loss = 74.3540\n",
      "****************************\n",
      "Epoch: 1870\n",
      "train_loss = 87.9775\n",
      "test_loss = 77.1031\n",
      "****************************\n",
      "Epoch: 1871\n",
      "train_loss = 87.7468\n",
      "test_loss = 74.8372\n",
      "****************************\n",
      "Epoch: 1872\n",
      "train_loss = 87.6423\n",
      "test_loss = 75.6250\n",
      "****************************\n",
      "Epoch: 1873\n",
      "train_loss = 88.2192\n",
      "test_loss = 77.7790\n",
      "****************************\n",
      "Epoch: 1874\n",
      "train_loss = 87.5702\n",
      "test_loss = 75.9082\n",
      "****************************\n",
      "Epoch: 1875\n",
      "train_loss = 87.5976\n",
      "test_loss = 76.2237\n",
      "****************************\n",
      "Epoch: 1876\n",
      "train_loss = 91.1933\n",
      "test_loss = 83.1222\n",
      "****************************\n",
      "Epoch: 1877\n",
      "train_loss = 87.5420\n",
      "test_loss = 75.7238\n",
      "****************************\n",
      "Epoch: 1878\n",
      "train_loss = 87.6682\n",
      "test_loss = 74.8432\n",
      "****************************\n",
      "Epoch: 1879\n",
      "train_loss = 87.6090\n",
      "test_loss = 75.0221\n",
      "****************************\n",
      "Epoch: 1880\n",
      "train_loss = 87.6638\n",
      "test_loss = 76.4618\n",
      "****************************\n",
      "Epoch: 1881\n",
      "train_loss = 91.3886\n",
      "test_loss = 75.2935\n",
      "****************************\n",
      "Epoch: 1882\n",
      "train_loss = 87.8253\n",
      "test_loss = 74.8991\n",
      "****************************\n",
      "Epoch: 1883\n",
      "train_loss = 87.7339\n",
      "test_loss = 74.9975\n",
      "****************************\n",
      "Epoch: 1884\n",
      "train_loss = 87.6131\n",
      "test_loss = 75.8046\n",
      "****************************\n",
      "Epoch: 1885\n",
      "train_loss = 88.3220\n",
      "test_loss = 78.1269\n",
      "****************************\n",
      "Epoch: 1886\n",
      "train_loss = 87.7991\n",
      "test_loss = 76.9057\n",
      "****************************\n",
      "Epoch: 1887\n",
      "train_loss = 87.8856\n",
      "test_loss = 74.6326\n",
      "****************************\n",
      "Epoch: 1888\n",
      "train_loss = 87.7053\n",
      "test_loss = 75.1741\n",
      "****************************\n",
      "Epoch: 1889\n",
      "train_loss = 87.6964\n",
      "test_loss = 75.0781\n",
      "****************************\n",
      "Epoch: 1890\n",
      "train_loss = 87.7723\n",
      "test_loss = 74.8696\n",
      "****************************\n",
      "Epoch: 1891\n",
      "train_loss = 87.6612\n",
      "test_loss = 75.0484\n",
      "****************************\n",
      "Epoch: 1892\n",
      "train_loss = 87.9053\n",
      "test_loss = 76.7535\n",
      "****************************\n",
      "Epoch: 1893\n",
      "train_loss = 87.6394\n",
      "test_loss = 75.1968\n",
      "****************************\n",
      "Epoch: 1894\n",
      "train_loss = 87.5893\n",
      "test_loss = 75.5459\n",
      "****************************\n",
      "Epoch: 1895\n",
      "train_loss = 88.2400\n",
      "test_loss = 78.0844\n",
      "****************************\n",
      "Epoch: 1896\n",
      "train_loss = 87.9410\n",
      "test_loss = 76.0994\n",
      "****************************\n",
      "Epoch: 1897\n",
      "train_loss = 88.1193\n",
      "test_loss = 77.4645\n",
      "****************************\n",
      "Epoch: 1898\n",
      "train_loss = 88.2385\n",
      "test_loss = 74.4576\n",
      "****************************\n",
      "Epoch: 1899\n",
      "train_loss = 87.6938\n",
      "test_loss = 76.3084\n",
      "****************************\n",
      "Epoch: 1900\n",
      "train_loss = 87.7305\n",
      "test_loss = 74.8908\n",
      "****************************\n",
      "Epoch: 1901\n",
      "train_loss = 87.9872\n",
      "test_loss = 77.3707\n",
      "****************************\n",
      "Epoch: 1902\n",
      "train_loss = 89.1262\n",
      "test_loss = 79.4718\n",
      "****************************\n",
      "Epoch: 1903\n",
      "train_loss = 88.4095\n",
      "test_loss = 74.3549\n",
      "****************************\n",
      "Epoch: 1904\n",
      "train_loss = 87.6121\n",
      "test_loss = 75.5710\n",
      "****************************\n",
      "Epoch: 1905\n",
      "train_loss = 87.5600\n",
      "test_loss = 75.4373\n",
      "****************************\n",
      "Epoch: 1906\n",
      "train_loss = 87.6621\n",
      "test_loss = 74.9150\n",
      "****************************\n",
      "Epoch: 1907\n",
      "train_loss = 88.1677\n",
      "test_loss = 74.3772\n",
      "****************************\n",
      "Epoch: 1908\n",
      "train_loss = 87.6464\n",
      "test_loss = 76.1908\n",
      "****************************\n",
      "Epoch: 1909\n",
      "train_loss = 87.6605\n",
      "test_loss = 74.9585\n",
      "****************************\n",
      "Epoch: 1910\n",
      "train_loss = 88.4927\n",
      "test_loss = 78.2668\n",
      "****************************\n",
      "Epoch: 1911\n",
      "train_loss = 88.2952\n",
      "test_loss = 74.3504\n",
      "****************************\n",
      "Epoch: 1912\n",
      "train_loss = 88.4629\n",
      "test_loss = 74.2865\n",
      "****************************\n",
      "Epoch: 1913\n",
      "train_loss = 87.7373\n",
      "test_loss = 74.7861\n",
      "****************************\n",
      "Epoch: 1914\n",
      "train_loss = 87.6974\n",
      "test_loss = 74.8460\n",
      "****************************\n",
      "Epoch: 1915\n",
      "train_loss = 87.9382\n",
      "test_loss = 74.5559\n",
      "****************************\n",
      "Epoch: 1916\n",
      "train_loss = 87.5856\n",
      "test_loss = 75.6426\n",
      "****************************\n",
      "Epoch: 1917\n",
      "train_loss = 87.6027\n",
      "test_loss = 76.2156\n",
      "****************************\n",
      "Epoch: 1918\n",
      "train_loss = 87.7472\n",
      "test_loss = 74.8057\n",
      "****************************\n",
      "Epoch: 1919\n",
      "train_loss = 87.8782\n",
      "test_loss = 76.8804\n",
      "****************************\n",
      "Epoch: 1920\n",
      "train_loss = 89.9366\n",
      "test_loss = 80.8184\n",
      "****************************\n",
      "Epoch: 1921\n",
      "train_loss = 87.5530\n",
      "test_loss = 75.8037\n",
      "****************************\n",
      "Epoch: 1922\n",
      "train_loss = 87.7314\n",
      "test_loss = 74.7518\n",
      "****************************\n",
      "Epoch: 1923\n",
      "train_loss = 87.5649\n",
      "test_loss = 75.8431\n",
      "****************************\n",
      "Epoch: 1924\n",
      "train_loss = 88.5323\n",
      "test_loss = 78.6827\n",
      "****************************\n",
      "Epoch: 1925\n",
      "train_loss = 87.7210\n",
      "test_loss = 76.6742\n",
      "****************************\n",
      "Epoch: 1926\n",
      "train_loss = 87.9523\n",
      "test_loss = 77.2783\n",
      "****************************\n",
      "Epoch: 1927\n",
      "train_loss = 88.1560\n",
      "test_loss = 74.4285\n",
      "****************************\n",
      "Epoch: 1928\n",
      "train_loss = 87.6583\n",
      "test_loss = 75.7698\n",
      "****************************\n",
      "Epoch: 1929\n",
      "train_loss = 87.6550\n",
      "test_loss = 76.0621\n",
      "****************************\n",
      "Epoch: 1930\n",
      "train_loss = 87.7761\n",
      "test_loss = 76.7679\n",
      "****************************\n",
      "Epoch: 1931\n",
      "train_loss = 87.7141\n",
      "test_loss = 74.9491\n",
      "****************************\n",
      "Epoch: 1932\n",
      "train_loss = 87.5963\n",
      "test_loss = 75.2345\n",
      "****************************\n",
      "Epoch: 1933\n",
      "train_loss = 87.5721\n",
      "test_loss = 75.6447\n",
      "****************************\n",
      "Epoch: 1934\n",
      "train_loss = 87.7167\n",
      "test_loss = 74.8204\n",
      "****************************\n",
      "Epoch: 1935\n",
      "train_loss = 89.1566\n",
      "test_loss = 79.7459\n",
      "****************************\n",
      "Epoch: 1936\n",
      "train_loss = 87.5770\n",
      "test_loss = 75.6190\n",
      "****************************\n",
      "Epoch: 1937\n",
      "train_loss = 87.6930\n",
      "test_loss = 74.9076\n",
      "****************************\n",
      "Epoch: 1938\n",
      "train_loss = 89.2711\n",
      "test_loss = 79.7119\n",
      "****************************\n",
      "Epoch: 1939\n",
      "train_loss = 88.0297\n",
      "test_loss = 74.4801\n",
      "****************************\n",
      "Epoch: 1940\n",
      "train_loss = 87.9449\n",
      "test_loss = 74.5665\n",
      "****************************\n",
      "Epoch: 1941\n",
      "train_loss = 88.1960\n",
      "test_loss = 77.8031\n",
      "****************************\n",
      "Epoch: 1942\n",
      "train_loss = 88.5612\n",
      "test_loss = 74.3018\n",
      "****************************\n",
      "Epoch: 1943\n",
      "train_loss = 89.6539\n",
      "test_loss = 80.1951\n",
      "****************************\n",
      "Epoch: 1944\n",
      "train_loss = 88.6951\n",
      "test_loss = 78.6370\n",
      "****************************\n",
      "Epoch: 1945\n",
      "train_loss = 87.5607\n",
      "test_loss = 75.7645\n",
      "****************************\n",
      "Epoch: 1946\n",
      "train_loss = 87.5959\n",
      "test_loss = 75.2386\n",
      "****************************\n",
      "Epoch: 1947\n",
      "train_loss = 89.1042\n",
      "test_loss = 79.6640\n",
      "****************************\n",
      "Epoch: 1948\n",
      "train_loss = 87.8197\n",
      "test_loss = 74.6349\n",
      "****************************\n",
      "Epoch: 1949\n",
      "train_loss = 87.6672\n",
      "test_loss = 76.3965\n",
      "****************************\n",
      "Epoch: 1950\n",
      "train_loss = 87.5967\n",
      "test_loss = 75.2100\n",
      "****************************\n",
      "Epoch: 1951\n",
      "train_loss = 87.6117\n",
      "test_loss = 75.7276\n",
      "****************************\n",
      "Epoch: 1952\n",
      "train_loss = 88.2888\n",
      "test_loss = 78.0807\n",
      "****************************\n",
      "Epoch: 1953\n",
      "train_loss = 87.6632\n",
      "test_loss = 75.0186\n",
      "****************************\n",
      "Epoch: 1954\n",
      "train_loss = 87.6085\n",
      "test_loss = 75.3563\n",
      "****************************\n",
      "Epoch: 1955\n",
      "train_loss = 88.4937\n",
      "test_loss = 78.4917\n",
      "****************************\n",
      "Epoch: 1956\n",
      "train_loss = 89.5206\n",
      "test_loss = 80.3327\n",
      "****************************\n",
      "Epoch: 1957\n",
      "train_loss = 87.6242\n",
      "test_loss = 75.7721\n",
      "****************************\n",
      "Epoch: 1958\n",
      "train_loss = 88.9811\n",
      "test_loss = 79.3940\n",
      "****************************\n",
      "Epoch: 1959\n",
      "train_loss = 87.5923\n",
      "test_loss = 75.4698\n",
      "****************************\n",
      "Epoch: 1960\n",
      "train_loss = 87.5914\n",
      "test_loss = 75.6783\n",
      "****************************\n",
      "Epoch: 1961\n",
      "train_loss = 87.8369\n",
      "test_loss = 76.4713\n",
      "****************************\n",
      "Epoch: 1962\n",
      "train_loss = 88.9981\n",
      "test_loss = 78.9356\n",
      "****************************\n",
      "Epoch: 1963\n",
      "train_loss = 87.7381\n",
      "test_loss = 75.8999\n",
      "****************************\n",
      "Epoch: 1964\n",
      "train_loss = 88.0494\n",
      "test_loss = 74.6520\n",
      "****************************\n",
      "Epoch: 1965\n",
      "train_loss = 87.8013\n",
      "test_loss = 76.7047\n",
      "****************************\n",
      "Epoch: 1966\n",
      "train_loss = 87.5892\n",
      "test_loss = 75.6066\n",
      "****************************\n",
      "Epoch: 1967\n",
      "train_loss = 87.6061\n",
      "test_loss = 75.3129\n",
      "****************************\n",
      "Epoch: 1968\n",
      "train_loss = 87.6091\n",
      "test_loss = 75.4503\n",
      "****************************\n",
      "Epoch: 1969\n",
      "train_loss = 87.6002\n",
      "test_loss = 75.4630\n",
      "****************************\n",
      "Epoch: 1970\n",
      "train_loss = 87.8037\n",
      "test_loss = 74.8104\n",
      "****************************\n",
      "Epoch: 1971\n",
      "train_loss = 87.8009\n",
      "test_loss = 74.7567\n",
      "****************************\n",
      "Epoch: 1972\n",
      "train_loss = 88.0656\n",
      "test_loss = 74.4953\n",
      "****************************\n",
      "Epoch: 1973\n",
      "train_loss = 88.1789\n",
      "test_loss = 74.4291\n",
      "****************************\n",
      "Epoch: 1974\n",
      "train_loss = 87.5902\n",
      "test_loss = 76.0303\n",
      "****************************\n",
      "Epoch: 1975\n",
      "train_loss = 87.6322\n",
      "test_loss = 75.8244\n",
      "****************************\n",
      "Epoch: 1976\n",
      "train_loss = 90.9552\n",
      "test_loss = 82.3968\n",
      "****************************\n",
      "Epoch: 1977\n",
      "train_loss = 87.7762\n",
      "test_loss = 76.5584\n",
      "****************************\n",
      "Epoch: 1978\n",
      "train_loss = 87.6206\n",
      "test_loss = 75.8396\n",
      "****************************\n",
      "Epoch: 1979\n",
      "train_loss = 88.0876\n",
      "test_loss = 77.7196\n",
      "****************************\n",
      "Epoch: 1980\n",
      "train_loss = 87.6644\n",
      "test_loss = 75.3996\n",
      "****************************\n",
      "Epoch: 1981\n",
      "train_loss = 87.6012\n",
      "test_loss = 75.2550\n",
      "****************************\n",
      "Epoch: 1982\n",
      "train_loss = 87.6517\n",
      "test_loss = 75.0809\n",
      "****************************\n",
      "Epoch: 1983\n",
      "train_loss = 87.8119\n",
      "test_loss = 76.8285\n",
      "****************************\n",
      "Epoch: 1984\n",
      "train_loss = 87.7127\n",
      "test_loss = 74.8441\n",
      "****************************\n",
      "Epoch: 1985\n",
      "train_loss = 88.1864\n",
      "test_loss = 74.3587\n",
      "****************************\n",
      "Epoch: 1986\n",
      "train_loss = 88.1527\n",
      "test_loss = 74.3739\n",
      "****************************\n",
      "Epoch: 1987\n",
      "train_loss = 88.4156\n",
      "test_loss = 78.1616\n",
      "****************************\n",
      "Epoch: 1988\n",
      "train_loss = 87.7235\n",
      "test_loss = 76.6541\n",
      "****************************\n",
      "Epoch: 1989\n",
      "train_loss = 88.5199\n",
      "test_loss = 78.4885\n",
      "****************************\n",
      "Epoch: 1990\n",
      "train_loss = 88.0609\n",
      "test_loss = 77.5785\n",
      "****************************\n",
      "Epoch: 1991\n",
      "train_loss = 87.7979\n",
      "test_loss = 76.8099\n",
      "****************************\n",
      "Epoch: 1992\n",
      "train_loss = 88.0930\n",
      "test_loss = 77.6013\n",
      "****************************\n",
      "Epoch: 1993\n",
      "train_loss = 87.5784\n",
      "test_loss = 75.8481\n",
      "****************************\n",
      "Epoch: 1994\n",
      "train_loss = 87.5798\n",
      "test_loss = 75.8378\n",
      "****************************\n",
      "Epoch: 1995\n",
      "train_loss = 88.6704\n",
      "test_loss = 78.4586\n",
      "****************************\n",
      "Epoch: 1996\n",
      "train_loss = 87.5648\n",
      "test_loss = 75.3588\n",
      "****************************\n",
      "Epoch: 1997\n",
      "train_loss = 88.5516\n",
      "test_loss = 78.7182\n",
      "****************************\n",
      "Epoch: 1998\n",
      "train_loss = 87.5978\n",
      "test_loss = 75.2058\n",
      "****************************\n",
      "Epoch: 1999\n",
      "train_loss = 87.7391\n",
      "test_loss = 74.7529\n",
      "****************************\n",
      "Epoch: 2000\n",
      "train_loss = 87.5656\n",
      "test_loss = 75.3170\n",
      "****************************\n",
      "Epoch: 2001\n",
      "train_loss = 88.0691\n",
      "test_loss = 77.4751\n",
      "****************************\n",
      "Epoch: 2002\n",
      "train_loss = 88.3096\n",
      "test_loss = 74.3384\n",
      "****************************\n",
      "Epoch: 2003\n",
      "train_loss = 89.3812\n",
      "test_loss = 79.8245\n",
      "****************************\n",
      "Epoch: 2004\n",
      "train_loss = 87.6749\n",
      "test_loss = 75.0436\n",
      "****************************\n",
      "Epoch: 2005\n",
      "train_loss = 90.0060\n",
      "test_loss = 80.9099\n",
      "****************************\n",
      "Epoch: 2006\n",
      "train_loss = 87.6210\n",
      "test_loss = 75.2580\n",
      "****************************\n",
      "Epoch: 2007\n",
      "train_loss = 87.9895\n",
      "test_loss = 76.9938\n",
      "****************************\n",
      "Epoch: 2008\n",
      "train_loss = 87.8046\n",
      "test_loss = 74.7548\n",
      "****************************\n",
      "Epoch: 2009\n",
      "train_loss = 87.6532\n",
      "test_loss = 76.1412\n",
      "****************************\n",
      "Epoch: 2010\n",
      "train_loss = 88.5617\n",
      "test_loss = 78.5594\n",
      "****************************\n",
      "Epoch: 2011\n",
      "train_loss = 87.5689\n",
      "test_loss = 75.9962\n",
      "****************************\n",
      "Epoch: 2012\n",
      "train_loss = 88.2019\n",
      "test_loss = 77.6070\n",
      "****************************\n",
      "Epoch: 2013\n",
      "train_loss = 88.1803\n",
      "test_loss = 77.5724\n",
      "****************************\n",
      "Epoch: 2014\n",
      "train_loss = 88.1669\n",
      "test_loss = 74.3767\n",
      "****************************\n",
      "Epoch: 2015\n",
      "train_loss = 87.5963\n",
      "test_loss = 75.8206\n",
      "****************************\n",
      "Epoch: 2016\n",
      "train_loss = 87.6164\n",
      "test_loss = 75.1085\n",
      "****************************\n",
      "Epoch: 2017\n",
      "train_loss = 88.0777\n",
      "test_loss = 74.7121\n",
      "****************************\n",
      "Epoch: 2018\n",
      "train_loss = 87.9065\n",
      "test_loss = 76.8703\n",
      "****************************\n",
      "Epoch: 2019\n",
      "train_loss = 87.7634\n",
      "test_loss = 76.4459\n",
      "****************************\n",
      "Epoch: 2020\n",
      "train_loss = 87.7285\n",
      "test_loss = 74.8048\n",
      "****************************\n",
      "Epoch: 2021\n",
      "train_loss = 87.6470\n",
      "test_loss = 75.8663\n",
      "****************************\n",
      "Epoch: 2022\n",
      "train_loss = 89.0079\n",
      "test_loss = 79.4363\n",
      "****************************\n",
      "Epoch: 2023\n",
      "train_loss = 87.7021\n",
      "test_loss = 76.4267\n",
      "****************************\n",
      "Epoch: 2024\n",
      "train_loss = 88.1510\n",
      "test_loss = 77.7473\n",
      "****************************\n",
      "Epoch: 2025\n",
      "train_loss = 87.5600\n",
      "test_loss = 75.5704\n",
      "****************************\n",
      "Epoch: 2026\n",
      "train_loss = 90.3092\n",
      "test_loss = 81.2281\n",
      "****************************\n",
      "Epoch: 2027\n",
      "train_loss = 87.6942\n",
      "test_loss = 74.8754\n",
      "****************************\n",
      "Epoch: 2028\n",
      "train_loss = 87.6704\n",
      "test_loss = 76.2013\n",
      "****************************\n",
      "Epoch: 2029\n",
      "train_loss = 87.6374\n",
      "test_loss = 76.0166\n",
      "****************************\n",
      "Epoch: 2030\n",
      "train_loss = 87.9551\n",
      "test_loss = 74.6432\n",
      "****************************\n",
      "Epoch: 2031\n",
      "train_loss = 87.6379\n",
      "test_loss = 75.2773\n",
      "****************************\n",
      "Epoch: 2032\n",
      "train_loss = 87.6400\n",
      "test_loss = 75.2963\n",
      "****************************\n",
      "Epoch: 2033\n",
      "train_loss = 87.5948\n",
      "test_loss = 75.5736\n",
      "****************************\n",
      "Epoch: 2034\n",
      "train_loss = 89.7318\n",
      "test_loss = 80.5875\n",
      "****************************\n",
      "Epoch: 2035\n",
      "train_loss = 88.0332\n",
      "test_loss = 74.4680\n",
      "****************************\n",
      "Epoch: 2036\n",
      "train_loss = 88.1385\n",
      "test_loss = 77.4300\n",
      "****************************\n",
      "Epoch: 2037\n",
      "train_loss = 87.6358\n",
      "test_loss = 75.8307\n",
      "****************************\n",
      "Epoch: 2038\n",
      "train_loss = 87.8314\n",
      "test_loss = 74.7491\n",
      "****************************\n",
      "Epoch: 2039\n",
      "train_loss = 87.9353\n",
      "test_loss = 77.0727\n",
      "****************************\n",
      "Epoch: 2040\n",
      "train_loss = 87.8705\n",
      "test_loss = 74.6542\n",
      "****************************\n",
      "Epoch: 2041\n",
      "train_loss = 87.6984\n",
      "test_loss = 76.2277\n",
      "****************************\n",
      "Epoch: 2042\n",
      "train_loss = 88.0551\n",
      "test_loss = 77.4082\n",
      "****************************\n",
      "Epoch: 2043\n",
      "train_loss = 87.8788\n",
      "test_loss = 76.6996\n",
      "****************************\n",
      "Epoch: 2044\n",
      "train_loss = 87.7705\n",
      "test_loss = 75.0068\n",
      "****************************\n",
      "Epoch: 2045\n",
      "train_loss = 88.4624\n",
      "test_loss = 78.1842\n",
      "****************************\n",
      "Epoch: 2046\n",
      "train_loss = 88.1568\n",
      "test_loss = 74.4929\n",
      "****************************\n",
      "Epoch: 2047\n",
      "train_loss = 87.6726\n",
      "test_loss = 75.9260\n",
      "****************************\n",
      "Epoch: 2048\n",
      "train_loss = 88.4810\n",
      "test_loss = 74.3092\n",
      "****************************\n",
      "Epoch: 2049\n",
      "train_loss = 88.9715\n",
      "test_loss = 79.1941\n",
      "****************************\n",
      "Epoch: 2050\n",
      "train_loss = 87.6700\n",
      "test_loss = 75.1142\n",
      "****************************\n",
      "Epoch: 2051\n",
      "train_loss = 87.6886\n",
      "test_loss = 76.0964\n",
      "****************************\n",
      "Epoch: 2052\n",
      "train_loss = 87.8314\n",
      "test_loss = 74.7619\n",
      "****************************\n",
      "Epoch: 2053\n",
      "train_loss = 87.6301\n",
      "test_loss = 75.5568\n",
      "****************************\n",
      "Epoch: 2054\n",
      "train_loss = 87.6730\n",
      "test_loss = 76.1782\n",
      "****************************\n",
      "Epoch: 2055\n",
      "train_loss = 88.1301\n",
      "test_loss = 77.6453\n",
      "****************************\n",
      "Epoch: 2056\n",
      "train_loss = 87.9909\n",
      "test_loss = 74.6001\n",
      "****************************\n",
      "Epoch: 2057\n",
      "train_loss = 88.5734\n",
      "test_loss = 74.3281\n",
      "****************************\n",
      "Epoch: 2058\n",
      "train_loss = 87.6922\n",
      "test_loss = 76.3541\n",
      "****************************\n",
      "Epoch: 2059\n",
      "train_loss = 87.6005\n",
      "test_loss = 75.8511\n",
      "****************************\n",
      "Epoch: 2060\n",
      "train_loss = 87.5995\n",
      "test_loss = 75.7735\n",
      "****************************\n",
      "Epoch: 2061\n",
      "train_loss = 87.7297\n",
      "test_loss = 76.5882\n",
      "****************************\n",
      "Epoch: 2062\n",
      "train_loss = 87.6116\n",
      "test_loss = 76.1159\n",
      "****************************\n",
      "Epoch: 2063\n",
      "train_loss = 88.8433\n",
      "test_loss = 79.0120\n",
      "****************************\n",
      "Epoch: 2064\n",
      "train_loss = 88.0835\n",
      "test_loss = 74.4625\n",
      "****************************\n",
      "Epoch: 2065\n",
      "train_loss = 88.3071\n",
      "test_loss = 74.3253\n",
      "****************************\n",
      "Epoch: 2066\n",
      "train_loss = 87.8618\n",
      "test_loss = 77.0272\n",
      "****************************\n",
      "Epoch: 2067\n",
      "train_loss = 87.8594\n",
      "test_loss = 76.9993\n",
      "****************************\n",
      "Epoch: 2068\n",
      "train_loss = 88.0383\n",
      "test_loss = 74.4886\n",
      "****************************\n",
      "Epoch: 2069\n",
      "train_loss = 87.7233\n",
      "test_loss = 76.3519\n",
      "****************************\n",
      "Epoch: 2070\n",
      "train_loss = 87.5869\n",
      "test_loss = 75.2412\n",
      "****************************\n",
      "Epoch: 2071\n",
      "train_loss = 87.5669\n",
      "test_loss = 75.3302\n",
      "****************************\n",
      "Epoch: 2072\n",
      "train_loss = 88.0202\n",
      "test_loss = 77.4803\n",
      "****************************\n",
      "Epoch: 2073\n",
      "train_loss = 87.7397\n",
      "test_loss = 76.5257\n",
      "****************************\n",
      "Epoch: 2074\n",
      "train_loss = 87.6036\n",
      "test_loss = 75.9578\n",
      "****************************\n",
      "Epoch: 2075\n",
      "train_loss = 87.6169\n",
      "test_loss = 74.9970\n",
      "****************************\n",
      "Epoch: 2076\n",
      "train_loss = 88.1156\n",
      "test_loss = 77.6104\n",
      "****************************\n",
      "Epoch: 2077\n",
      "train_loss = 87.9186\n",
      "test_loss = 74.5353\n",
      "****************************\n",
      "Epoch: 2078\n",
      "train_loss = 88.2945\n",
      "test_loss = 77.9053\n",
      "****************************\n",
      "Epoch: 2079\n",
      "train_loss = 87.5819\n",
      "test_loss = 75.7111\n",
      "****************************\n",
      "Epoch: 2080\n",
      "train_loss = 87.7559\n",
      "test_loss = 76.6391\n",
      "****************************\n",
      "Epoch: 2081\n",
      "train_loss = 88.0486\n",
      "test_loss = 77.5276\n",
      "****************************\n",
      "Epoch: 2082\n",
      "train_loss = 87.6886\n",
      "test_loss = 75.0254\n",
      "****************************\n",
      "Epoch: 2083\n",
      "train_loss = 87.7402\n",
      "test_loss = 76.6782\n",
      "****************************\n",
      "Epoch: 2084\n",
      "train_loss = 87.6504\n",
      "test_loss = 75.0119\n",
      "****************************\n",
      "Epoch: 2085\n",
      "train_loss = 88.3633\n",
      "test_loss = 74.3499\n",
      "****************************\n",
      "Epoch: 2086\n",
      "train_loss = 88.0249\n",
      "test_loss = 74.5087\n",
      "****************************\n",
      "Epoch: 2087\n",
      "train_loss = 87.7185\n",
      "test_loss = 76.5941\n",
      "****************************\n",
      "Epoch: 2088\n",
      "train_loss = 88.1946\n",
      "test_loss = 74.3767\n",
      "****************************\n",
      "Epoch: 2089\n",
      "train_loss = 87.6209\n",
      "test_loss = 75.1101\n",
      "****************************\n",
      "Epoch: 2090\n",
      "train_loss = 87.9851\n",
      "test_loss = 74.4670\n",
      "****************************\n",
      "Epoch: 2091\n",
      "train_loss = 89.1277\n",
      "test_loss = 79.5166\n",
      "****************************\n",
      "Epoch: 2092\n",
      "train_loss = 87.6803\n",
      "test_loss = 74.9866\n",
      "****************************\n",
      "Epoch: 2093\n",
      "train_loss = 88.2631\n",
      "test_loss = 74.3348\n",
      "****************************\n",
      "Epoch: 2094\n",
      "train_loss = 87.7185\n",
      "test_loss = 74.8753\n",
      "****************************\n",
      "Epoch: 2095\n",
      "train_loss = 87.6366\n",
      "test_loss = 76.0537\n",
      "****************************\n",
      "Epoch: 2096\n",
      "train_loss = 87.6043\n",
      "test_loss = 75.2146\n",
      "****************************\n",
      "Epoch: 2097\n",
      "train_loss = 87.6845\n",
      "test_loss = 74.9590\n",
      "****************************\n",
      "Epoch: 2098\n",
      "train_loss = 87.7340\n",
      "test_loss = 76.5472\n",
      "****************************\n",
      "Epoch: 2099\n",
      "train_loss = 88.1100\n",
      "test_loss = 74.4292\n",
      "****************************\n",
      "Epoch: 2100\n",
      "train_loss = 87.7016\n",
      "test_loss = 74.8514\n",
      "****************************\n",
      "Epoch: 2101\n",
      "train_loss = 87.6812\n",
      "test_loss = 76.3175\n",
      "****************************\n",
      "Epoch: 2102\n",
      "train_loss = 87.6231\n",
      "test_loss = 75.1549\n",
      "****************************\n",
      "Epoch: 2103\n",
      "train_loss = 88.3947\n",
      "test_loss = 74.3481\n",
      "****************************\n",
      "Epoch: 2104\n",
      "train_loss = 88.7688\n",
      "test_loss = 79.0560\n",
      "****************************\n",
      "Epoch: 2105\n",
      "train_loss = 87.6241\n",
      "test_loss = 75.9811\n",
      "****************************\n",
      "Epoch: 2106\n",
      "train_loss = 88.1926\n",
      "test_loss = 77.8485\n",
      "****************************\n",
      "Epoch: 2107\n",
      "train_loss = 88.2402\n",
      "test_loss = 74.4349\n",
      "****************************\n",
      "Epoch: 2108\n",
      "train_loss = 87.6204\n",
      "test_loss = 75.0822\n",
      "****************************\n",
      "Epoch: 2109\n",
      "train_loss = 87.8114\n",
      "test_loss = 76.8591\n",
      "****************************\n",
      "Epoch: 2110\n",
      "train_loss = 87.6672\n",
      "test_loss = 74.9135\n",
      "****************************\n",
      "Epoch: 2111\n",
      "train_loss = 87.5456\n",
      "test_loss = 75.3348\n",
      "****************************\n",
      "Epoch: 2112\n",
      "train_loss = 87.5454\n",
      "test_loss = 75.3521\n",
      "****************************\n",
      "Epoch: 2113\n",
      "train_loss = 87.7189\n",
      "test_loss = 74.8102\n",
      "****************************\n",
      "Epoch: 2114\n",
      "train_loss = 87.7066\n",
      "test_loss = 74.8031\n",
      "****************************\n",
      "Epoch: 2115\n",
      "train_loss = 87.5550\n",
      "test_loss = 75.5861\n",
      "****************************\n",
      "Epoch: 2116\n",
      "train_loss = 87.5839\n",
      "test_loss = 75.4223\n",
      "****************************\n",
      "Epoch: 2117\n",
      "train_loss = 88.1243\n",
      "test_loss = 74.7642\n",
      "****************************\n",
      "Epoch: 2118\n",
      "train_loss = 88.2835\n",
      "test_loss = 77.5286\n",
      "****************************\n",
      "Epoch: 2119\n",
      "train_loss = 87.6325\n",
      "test_loss = 75.5792\n",
      "****************************\n",
      "Epoch: 2120\n",
      "train_loss = 87.5934\n",
      "test_loss = 75.7354\n",
      "****************************\n",
      "Epoch: 2121\n",
      "train_loss = 87.6984\n",
      "test_loss = 76.3987\n",
      "****************************\n",
      "Epoch: 2122\n",
      "train_loss = 87.7286\n",
      "test_loss = 76.2924\n",
      "****************************\n",
      "Epoch: 2123\n",
      "train_loss = 88.4750\n",
      "test_loss = 74.2616\n",
      "****************************\n",
      "Epoch: 2124\n",
      "train_loss = 88.1038\n",
      "test_loss = 74.4400\n",
      "****************************\n",
      "Epoch: 2125\n",
      "train_loss = 87.6051\n",
      "test_loss = 75.4747\n",
      "****************************\n",
      "Epoch: 2126\n",
      "train_loss = 88.0598\n",
      "test_loss = 74.4598\n",
      "****************************\n",
      "Epoch: 2127\n",
      "train_loss = 87.6239\n",
      "test_loss = 76.2412\n",
      "****************************\n",
      "Epoch: 2128\n",
      "train_loss = 87.6795\n",
      "test_loss = 74.9738\n",
      "****************************\n",
      "Epoch: 2129\n",
      "train_loss = 87.8590\n",
      "test_loss = 74.6156\n",
      "****************************\n",
      "Epoch: 2130\n",
      "train_loss = 87.5663\n",
      "test_loss = 75.1604\n",
      "****************************\n",
      "Epoch: 2131\n",
      "train_loss = 87.5936\n",
      "test_loss = 75.0705\n",
      "****************************\n",
      "Epoch: 2132\n",
      "train_loss = 88.1114\n",
      "test_loss = 74.4052\n",
      "****************************\n",
      "Epoch: 2133\n",
      "train_loss = 88.6237\n",
      "test_loss = 74.2195\n",
      "****************************\n",
      "Epoch: 2134\n",
      "train_loss = 88.7528\n",
      "test_loss = 78.9975\n",
      "****************************\n",
      "Epoch: 2135\n",
      "train_loss = 87.5931\n",
      "test_loss = 75.5330\n",
      "****************************\n",
      "Epoch: 2136\n",
      "train_loss = 87.5806\n",
      "test_loss = 75.6109\n",
      "****************************\n",
      "Epoch: 2137\n",
      "train_loss = 90.1905\n",
      "test_loss = 81.5058\n",
      "****************************\n",
      "Epoch: 2138\n",
      "train_loss = 87.7457\n",
      "test_loss = 76.6523\n",
      "****************************\n",
      "Epoch: 2139\n",
      "train_loss = 88.1573\n",
      "test_loss = 77.7951\n",
      "****************************\n",
      "Epoch: 2140\n",
      "train_loss = 87.9160\n",
      "test_loss = 74.6105\n",
      "****************************\n",
      "Epoch: 2141\n",
      "train_loss = 87.6418\n",
      "test_loss = 75.3543\n",
      "****************************\n",
      "Epoch: 2142\n",
      "train_loss = 87.6305\n",
      "test_loss = 75.1115\n",
      "****************************\n",
      "Epoch: 2143\n",
      "train_loss = 87.5534\n",
      "test_loss = 75.4957\n",
      "****************************\n",
      "Epoch: 2144\n",
      "train_loss = 88.1215\n",
      "test_loss = 74.4305\n",
      "****************************\n",
      "Epoch: 2145\n",
      "train_loss = 87.7900\n",
      "test_loss = 74.7302\n",
      "****************************\n",
      "Epoch: 2146\n",
      "train_loss = 87.9378\n",
      "test_loss = 74.5344\n",
      "****************************\n",
      "Epoch: 2147\n",
      "train_loss = 89.6291\n",
      "test_loss = 80.6191\n",
      "****************************\n",
      "Epoch: 2148\n",
      "train_loss = 87.6088\n",
      "test_loss = 75.1685\n",
      "****************************\n",
      "Epoch: 2149\n",
      "train_loss = 89.2414\n",
      "test_loss = 79.6756\n",
      "****************************\n",
      "Epoch: 2150\n",
      "train_loss = 88.8384\n",
      "test_loss = 74.2244\n",
      "****************************\n",
      "Epoch: 2151\n",
      "train_loss = 87.5893\n",
      "test_loss = 75.2377\n",
      "****************************\n",
      "Epoch: 2152\n",
      "train_loss = 87.6266\n",
      "test_loss = 76.1953\n",
      "****************************\n",
      "Epoch: 2153\n",
      "train_loss = 87.7162\n",
      "test_loss = 76.5726\n",
      "****************************\n",
      "Epoch: 2154\n",
      "train_loss = 87.6770\n",
      "test_loss = 75.0300\n",
      "****************************\n",
      "Epoch: 2155\n",
      "train_loss = 88.5206\n",
      "test_loss = 78.3455\n",
      "****************************\n",
      "Epoch: 2156\n",
      "train_loss = 88.0789\n",
      "test_loss = 77.3055\n",
      "****************************\n",
      "Epoch: 2157\n",
      "train_loss = 87.7593\n",
      "test_loss = 76.4337\n",
      "****************************\n",
      "Epoch: 2158\n",
      "train_loss = 87.6208\n",
      "test_loss = 76.1021\n",
      "****************************\n",
      "Epoch: 2159\n",
      "train_loss = 87.7209\n",
      "test_loss = 74.8971\n",
      "****************************\n",
      "Epoch: 2160\n",
      "train_loss = 89.2079\n",
      "test_loss = 74.2390\n",
      "****************************\n",
      "Epoch: 2161\n",
      "train_loss = 87.5913\n",
      "test_loss = 75.2167\n",
      "****************************\n",
      "Epoch: 2162\n",
      "train_loss = 87.8607\n",
      "test_loss = 77.2910\n",
      "****************************\n",
      "Epoch: 2163\n",
      "train_loss = 87.6417\n",
      "test_loss = 75.2156\n",
      "****************************\n",
      "Epoch: 2164\n",
      "train_loss = 87.6332\n",
      "test_loss = 75.7911\n",
      "****************************\n",
      "Epoch: 2165\n",
      "train_loss = 87.5916\n",
      "test_loss = 75.7665\n",
      "****************************\n",
      "Epoch: 2166\n",
      "train_loss = 87.5883\n",
      "test_loss = 75.6253\n",
      "****************************\n",
      "Epoch: 2167\n",
      "train_loss = 87.5990\n",
      "test_loss = 75.2408\n",
      "****************************\n",
      "Epoch: 2168\n",
      "train_loss = 87.7327\n",
      "test_loss = 76.6702\n",
      "****************************\n",
      "Epoch: 2169\n",
      "train_loss = 87.6099\n",
      "test_loss = 76.0917\n",
      "****************************\n",
      "Epoch: 2170\n",
      "train_loss = 88.2428\n",
      "test_loss = 78.0541\n",
      "****************************\n",
      "Epoch: 2171\n",
      "train_loss = 87.7186\n",
      "test_loss = 76.3856\n",
      "****************************\n",
      "Epoch: 2172\n",
      "train_loss = 87.5796\n",
      "test_loss = 75.2371\n",
      "****************************\n",
      "Epoch: 2173\n",
      "train_loss = 88.3820\n",
      "test_loss = 78.3597\n",
      "****************************\n",
      "Epoch: 2174\n",
      "train_loss = 87.6862\n",
      "test_loss = 74.8608\n",
      "****************************\n",
      "Epoch: 2175\n",
      "train_loss = 87.7236\n",
      "test_loss = 74.7767\n",
      "****************************\n",
      "Epoch: 2176\n",
      "train_loss = 87.5808\n",
      "test_loss = 75.2252\n",
      "****************************\n",
      "Epoch: 2177\n",
      "train_loss = 89.0641\n",
      "test_loss = 79.4255\n",
      "****************************\n",
      "Epoch: 2178\n",
      "train_loss = 87.6501\n",
      "test_loss = 75.0537\n",
      "****************************\n",
      "Epoch: 2179\n",
      "train_loss = 87.6309\n",
      "test_loss = 75.9739\n",
      "****************************\n",
      "Epoch: 2180\n",
      "train_loss = 87.5609\n",
      "test_loss = 75.7060\n",
      "****************************\n",
      "Epoch: 2181\n",
      "train_loss = 87.8296\n",
      "test_loss = 76.9462\n",
      "****************************\n",
      "Epoch: 2182\n",
      "train_loss = 87.6453\n",
      "test_loss = 76.2918\n",
      "****************************\n",
      "Epoch: 2183\n",
      "train_loss = 87.8346\n",
      "test_loss = 76.1334\n",
      "****************************\n",
      "Epoch: 2184\n",
      "train_loss = 87.6252\n",
      "test_loss = 75.4042\n",
      "****************************\n",
      "Epoch: 2185\n",
      "train_loss = 87.6292\n",
      "test_loss = 75.1956\n",
      "****************************\n",
      "Epoch: 2186\n",
      "train_loss = 87.6531\n",
      "test_loss = 75.0789\n",
      "****************************\n",
      "Epoch: 2187\n",
      "train_loss = 87.6158\n",
      "test_loss = 75.1913\n",
      "****************************\n",
      "Epoch: 2188\n",
      "train_loss = 87.8744\n",
      "test_loss = 76.8844\n",
      "****************************\n",
      "Epoch: 2189\n",
      "train_loss = 87.9278\n",
      "test_loss = 77.2412\n",
      "****************************\n",
      "Epoch: 2190\n",
      "train_loss = 87.7485\n",
      "test_loss = 76.7371\n",
      "****************************\n",
      "Epoch: 2191\n",
      "train_loss = 87.7859\n",
      "test_loss = 76.5933\n",
      "****************************\n",
      "Epoch: 2192\n",
      "train_loss = 87.6531\n",
      "test_loss = 74.9457\n",
      "****************************\n",
      "Epoch: 2193\n",
      "train_loss = 87.6720\n",
      "test_loss = 74.9392\n",
      "****************************\n",
      "Epoch: 2194\n",
      "train_loss = 87.5914\n",
      "test_loss = 75.3524\n",
      "****************************\n",
      "Epoch: 2195\n",
      "train_loss = 88.0013\n",
      "test_loss = 77.4591\n",
      "****************************\n",
      "Epoch: 2196\n",
      "train_loss = 87.6719\n",
      "test_loss = 74.8688\n",
      "****************************\n",
      "Epoch: 2197\n",
      "train_loss = 87.5973\n",
      "test_loss = 75.8341\n",
      "****************************\n",
      "Epoch: 2198\n",
      "train_loss = 87.5894\n",
      "test_loss = 75.1362\n",
      "****************************\n",
      "Epoch: 2199\n",
      "train_loss = 88.3020\n",
      "test_loss = 74.2834\n",
      "****************************\n",
      "Epoch: 2200\n",
      "train_loss = 87.8444\n",
      "test_loss = 76.7711\n",
      "****************************\n",
      "Epoch: 2201\n",
      "train_loss = 88.0612\n",
      "test_loss = 77.1742\n",
      "****************************\n",
      "Epoch: 2202\n",
      "train_loss = 88.2114\n",
      "test_loss = 74.3554\n",
      "****************************\n",
      "Epoch: 2203\n",
      "train_loss = 87.5846\n",
      "test_loss = 75.3996\n",
      "****************************\n",
      "Epoch: 2204\n",
      "train_loss = 87.6648\n",
      "test_loss = 76.1666\n",
      "****************************\n",
      "Epoch: 2205\n",
      "train_loss = 87.9288\n",
      "test_loss = 74.5598\n",
      "****************************\n",
      "Epoch: 2206\n",
      "train_loss = 87.8213\n",
      "test_loss = 74.6143\n",
      "****************************\n",
      "Epoch: 2207\n",
      "train_loss = 87.5991\n",
      "test_loss = 75.2922\n",
      "****************************\n",
      "Epoch: 2208\n",
      "train_loss = 88.2973\n",
      "test_loss = 74.3222\n",
      "****************************\n",
      "Epoch: 2209\n",
      "train_loss = 88.8236\n",
      "test_loss = 78.9060\n",
      "****************************\n",
      "Epoch: 2210\n",
      "train_loss = 87.5877\n",
      "test_loss = 75.1768\n",
      "****************************\n",
      "Epoch: 2211\n",
      "train_loss = 88.2099\n",
      "test_loss = 74.3683\n",
      "****************************\n",
      "Epoch: 2212\n",
      "train_loss = 87.5865\n",
      "test_loss = 75.7723\n",
      "****************************\n",
      "Epoch: 2213\n",
      "train_loss = 88.3441\n",
      "test_loss = 74.2431\n",
      "****************************\n",
      "Epoch: 2214\n",
      "train_loss = 87.7362\n",
      "test_loss = 74.6614\n",
      "****************************\n",
      "Epoch: 2215\n",
      "train_loss = 87.7149\n",
      "test_loss = 74.6751\n",
      "****************************\n",
      "Epoch: 2216\n",
      "train_loss = 87.5852\n",
      "test_loss = 75.7958\n",
      "****************************\n",
      "Epoch: 2217\n",
      "train_loss = 88.0412\n",
      "test_loss = 74.3801\n",
      "****************************\n",
      "Epoch: 2218\n",
      "train_loss = 87.9252\n",
      "test_loss = 76.9048\n",
      "****************************\n",
      "Epoch: 2219\n",
      "train_loss = 87.7464\n",
      "test_loss = 76.5200\n",
      "****************************\n",
      "Epoch: 2220\n",
      "train_loss = 87.7401\n",
      "test_loss = 76.6023\n",
      "****************************\n",
      "Epoch: 2221\n",
      "train_loss = 87.9361\n",
      "test_loss = 77.2124\n",
      "****************************\n",
      "Epoch: 2222\n",
      "train_loss = 88.3115\n",
      "test_loss = 74.2764\n",
      "****************************\n",
      "Epoch: 2223\n",
      "train_loss = 87.7340\n",
      "test_loss = 76.5178\n",
      "****************************\n",
      "Epoch: 2224\n",
      "train_loss = 87.5524\n",
      "test_loss = 75.4483\n",
      "****************************\n",
      "Epoch: 2225\n",
      "train_loss = 87.8985\n",
      "test_loss = 74.5267\n",
      "****************************\n",
      "Epoch: 2226\n",
      "train_loss = 87.6121\n",
      "test_loss = 76.0730\n",
      "****************************\n",
      "Epoch: 2227\n",
      "train_loss = 87.5396\n",
      "test_loss = 75.2978\n",
      "****************************\n",
      "Epoch: 2228\n",
      "train_loss = 87.9720\n",
      "test_loss = 74.4371\n",
      "****************************\n",
      "Epoch: 2229\n",
      "train_loss = 88.3181\n",
      "test_loss = 77.9349\n",
      "****************************\n",
      "Epoch: 2230\n",
      "train_loss = 87.5584\n",
      "test_loss = 75.7612\n",
      "****************************\n",
      "Epoch: 2231\n",
      "train_loss = 87.8248\n",
      "test_loss = 77.1349\n",
      "****************************\n",
      "Epoch: 2232\n",
      "train_loss = 87.8302\n",
      "test_loss = 77.1501\n",
      "****************************\n",
      "Epoch: 2233\n",
      "train_loss = 87.5856\n",
      "test_loss = 75.2860\n",
      "****************************\n",
      "Epoch: 2234\n",
      "train_loss = 87.6643\n",
      "test_loss = 76.1949\n",
      "****************************\n",
      "Epoch: 2235\n",
      "train_loss = 87.5584\n",
      "test_loss = 75.4321\n",
      "****************************\n",
      "Epoch: 2236\n",
      "train_loss = 88.1312\n",
      "test_loss = 74.3947\n",
      "****************************\n",
      "Epoch: 2237\n",
      "train_loss = 87.7405\n",
      "test_loss = 76.5660\n",
      "****************************\n",
      "Epoch: 2238\n",
      "train_loss = 87.5790\n",
      "test_loss = 75.8547\n",
      "****************************\n",
      "Epoch: 2239\n",
      "train_loss = 87.9216\n",
      "test_loss = 74.6108\n",
      "****************************\n",
      "Epoch: 2240\n",
      "train_loss = 87.5346\n",
      "test_loss = 75.5875\n",
      "****************************\n",
      "Epoch: 2241\n",
      "train_loss = 87.6460\n",
      "test_loss = 74.9902\n",
      "****************************\n",
      "Epoch: 2242\n",
      "train_loss = 87.7235\n",
      "test_loss = 76.6489\n",
      "****************************\n",
      "Epoch: 2243\n",
      "train_loss = 87.5314\n",
      "test_loss = 75.2530\n",
      "****************************\n",
      "Epoch: 2244\n",
      "train_loss = 87.5259\n",
      "test_loss = 75.8642\n",
      "****************************\n",
      "Epoch: 2245\n",
      "train_loss = 89.1783\n",
      "test_loss = 79.8764\n",
      "****************************\n",
      "Epoch: 2246\n",
      "train_loss = 87.5728\n",
      "test_loss = 75.7598\n",
      "****************************\n",
      "Epoch: 2247\n",
      "train_loss = 88.0293\n",
      "test_loss = 77.3535\n",
      "****************************\n",
      "Epoch: 2248\n",
      "train_loss = 88.6863\n",
      "test_loss = 78.7146\n",
      "****************************\n",
      "Epoch: 2249\n",
      "train_loss = 87.5586\n",
      "test_loss = 75.8165\n",
      "****************************\n",
      "Epoch: 2250\n",
      "train_loss = 88.7111\n",
      "test_loss = 78.9231\n",
      "****************************\n",
      "Epoch: 2251\n",
      "train_loss = 87.6940\n",
      "test_loss = 74.8547\n",
      "****************************\n",
      "Epoch: 2252\n",
      "train_loss = 87.6039\n",
      "test_loss = 75.6142\n",
      "****************************\n",
      "Epoch: 2253\n",
      "train_loss = 87.5950\n",
      "test_loss = 75.6613\n",
      "****************************\n",
      "Epoch: 2254\n",
      "train_loss = 87.5821\n",
      "test_loss = 75.6685\n",
      "****************************\n",
      "Epoch: 2255\n",
      "train_loss = 87.5962\n",
      "test_loss = 76.0491\n",
      "****************************\n",
      "Epoch: 2256\n",
      "train_loss = 87.8082\n",
      "test_loss = 76.6243\n",
      "****************************\n",
      "Epoch: 2257\n",
      "train_loss = 87.6226\n",
      "test_loss = 76.0549\n",
      "****************************\n",
      "Epoch: 2258\n",
      "train_loss = 87.8361\n",
      "test_loss = 74.6690\n",
      "****************************\n",
      "Epoch: 2259\n",
      "train_loss = 87.5975\n",
      "test_loss = 75.4564\n",
      "****************************\n",
      "Epoch: 2260\n",
      "train_loss = 87.6467\n",
      "test_loss = 75.8392\n",
      "****************************\n",
      "Epoch: 2261\n",
      "train_loss = 87.9148\n",
      "test_loss = 74.6361\n",
      "****************************\n",
      "Epoch: 2262\n",
      "train_loss = 87.5835\n",
      "test_loss = 75.4248\n",
      "****************************\n",
      "Epoch: 2263\n",
      "train_loss = 87.6349\n",
      "test_loss = 76.2213\n",
      "****************************\n",
      "Epoch: 2264\n",
      "train_loss = 87.5484\n",
      "test_loss = 75.4827\n",
      "****************************\n",
      "Epoch: 2265\n",
      "train_loss = 87.9575\n",
      "test_loss = 77.1657\n",
      "****************************\n",
      "Epoch: 2266\n",
      "train_loss = 88.0614\n",
      "test_loss = 74.4665\n",
      "****************************\n",
      "Epoch: 2267\n",
      "train_loss = 87.7913\n",
      "test_loss = 74.6681\n",
      "****************************\n",
      "Epoch: 2268\n",
      "train_loss = 87.5552\n",
      "test_loss = 75.4127\n",
      "****************************\n",
      "Epoch: 2269\n",
      "train_loss = 87.6064\n",
      "test_loss = 76.1364\n",
      "****************************\n",
      "Epoch: 2270\n",
      "train_loss = 87.5909\n",
      "test_loss = 76.1254\n",
      "****************************\n",
      "Epoch: 2271\n",
      "train_loss = 88.2534\n",
      "test_loss = 77.8639\n",
      "****************************\n",
      "Epoch: 2272\n",
      "train_loss = 88.3843\n",
      "test_loss = 78.2961\n",
      "****************************\n",
      "Epoch: 2273\n",
      "train_loss = 87.6532\n",
      "test_loss = 75.4427\n",
      "****************************\n",
      "Epoch: 2274\n",
      "train_loss = 87.6653\n",
      "test_loss = 74.9333\n",
      "****************************\n",
      "Epoch: 2275\n",
      "train_loss = 87.6444\n",
      "test_loss = 76.3985\n",
      "****************************\n",
      "Epoch: 2276\n",
      "train_loss = 87.5680\n",
      "test_loss = 75.6479\n",
      "****************************\n",
      "Epoch: 2277\n",
      "train_loss = 87.6669\n",
      "test_loss = 74.9172\n",
      "****************************\n",
      "Epoch: 2278\n",
      "train_loss = 87.7997\n",
      "test_loss = 76.8254\n",
      "****************************\n",
      "Epoch: 2279\n",
      "train_loss = 87.5741\n",
      "test_loss = 76.0506\n",
      "****************************\n",
      "Epoch: 2280\n",
      "train_loss = 87.7131\n",
      "test_loss = 74.9212\n",
      "****************************\n",
      "Epoch: 2281\n",
      "train_loss = 88.9549\n",
      "test_loss = 74.2372\n",
      "****************************\n",
      "Epoch: 2282\n",
      "train_loss = 87.7356\n",
      "test_loss = 76.4190\n",
      "****************************\n",
      "Epoch: 2283\n",
      "train_loss = 88.1903\n",
      "test_loss = 77.8271\n",
      "****************************\n",
      "Epoch: 2284\n",
      "train_loss = 88.2660\n",
      "test_loss = 74.3206\n",
      "****************************\n",
      "Epoch: 2285\n",
      "train_loss = 87.6705\n",
      "test_loss = 74.9116\n",
      "****************************\n",
      "Epoch: 2286\n",
      "train_loss = 87.8494\n",
      "test_loss = 74.5609\n",
      "****************************\n",
      "Epoch: 2287\n",
      "train_loss = 87.6450\n",
      "test_loss = 74.9282\n",
      "****************************\n",
      "Epoch: 2288\n",
      "train_loss = 87.5680\n",
      "test_loss = 75.1859\n",
      "****************************\n",
      "Epoch: 2289\n",
      "train_loss = 88.5957\n",
      "test_loss = 74.2511\n",
      "****************************\n",
      "Epoch: 2290\n",
      "train_loss = 87.5427\n",
      "test_loss = 75.8836\n",
      "****************************\n",
      "Epoch: 2291\n",
      "train_loss = 89.0185\n",
      "test_loss = 79.6035\n",
      "****************************\n",
      "Epoch: 2292\n",
      "train_loss = 87.5267\n",
      "test_loss = 75.5031\n",
      "****************************\n",
      "Epoch: 2293\n",
      "train_loss = 87.5254\n",
      "test_loss = 75.6760\n",
      "****************************\n",
      "Epoch: 2294\n",
      "train_loss = 88.1194\n",
      "test_loss = 77.9353\n",
      "****************************\n",
      "Epoch: 2295\n",
      "train_loss = 87.5532\n",
      "test_loss = 75.7268\n",
      "****************************\n",
      "Epoch: 2296\n",
      "train_loss = 88.1554\n",
      "test_loss = 74.3402\n",
      "****************************\n",
      "Epoch: 2297\n",
      "train_loss = 87.5627\n",
      "test_loss = 75.7808\n",
      "****************************\n",
      "Epoch: 2298\n",
      "train_loss = 87.5914\n",
      "test_loss = 75.9864\n",
      "****************************\n",
      "Epoch: 2299\n",
      "train_loss = 87.7226\n",
      "test_loss = 76.4721\n",
      "****************************\n",
      "Epoch: 2300\n",
      "train_loss = 87.5683\n",
      "test_loss = 75.3906\n",
      "****************************\n",
      "Epoch: 2301\n",
      "train_loss = 87.9495\n",
      "test_loss = 74.5496\n",
      "****************************\n",
      "Epoch: 2302\n",
      "train_loss = 88.0595\n",
      "test_loss = 77.6049\n",
      "****************************\n",
      "Epoch: 2303\n",
      "train_loss = 87.5674\n",
      "test_loss = 75.5495\n",
      "****************************\n",
      "Epoch: 2304\n",
      "train_loss = 88.3966\n",
      "test_loss = 78.4535\n",
      "****************************\n",
      "Epoch: 2305\n",
      "train_loss = 87.6651\n",
      "test_loss = 76.3571\n",
      "****************************\n",
      "Epoch: 2306\n",
      "train_loss = 88.1539\n",
      "test_loss = 74.3939\n",
      "****************************\n",
      "Epoch: 2307\n",
      "train_loss = 87.5490\n",
      "test_loss = 75.6563\n",
      "****************************\n",
      "Epoch: 2308\n",
      "train_loss = 87.6288\n",
      "test_loss = 76.4202\n",
      "****************************\n",
      "Epoch: 2309\n",
      "train_loss = 88.2711\n",
      "test_loss = 74.7888\n",
      "****************************\n",
      "Epoch: 2310\n",
      "train_loss = 87.5889\n",
      "test_loss = 75.4381\n",
      "****************************\n",
      "Epoch: 2311\n",
      "train_loss = 87.8217\n",
      "test_loss = 74.6317\n",
      "****************************\n",
      "Epoch: 2312\n",
      "train_loss = 88.9793\n",
      "test_loss = 74.1829\n",
      "****************************\n",
      "Epoch: 2313\n",
      "train_loss = 87.7407\n",
      "test_loss = 76.7309\n",
      "****************************\n",
      "Epoch: 2314\n",
      "train_loss = 88.2244\n",
      "test_loss = 77.9786\n",
      "****************************\n",
      "Epoch: 2315\n",
      "train_loss = 87.6531\n",
      "test_loss = 76.2552\n",
      "****************************\n",
      "Epoch: 2316\n",
      "train_loss = 87.6435\n",
      "test_loss = 74.9324\n",
      "****************************\n",
      "Epoch: 2317\n",
      "train_loss = 87.5663\n",
      "test_loss = 75.8007\n",
      "****************************\n",
      "Epoch: 2318\n",
      "train_loss = 88.0832\n",
      "test_loss = 74.4047\n",
      "****************************\n",
      "Epoch: 2319\n",
      "train_loss = 87.8520\n",
      "test_loss = 76.9867\n",
      "****************************\n",
      "Epoch: 2320\n",
      "train_loss = 87.5854\n",
      "test_loss = 75.1952\n",
      "****************************\n",
      "Epoch: 2321\n",
      "train_loss = 87.6159\n",
      "test_loss = 76.1268\n",
      "****************************\n",
      "Epoch: 2322\n",
      "train_loss = 87.7422\n",
      "test_loss = 74.7560\n",
      "****************************\n",
      "Epoch: 2323\n",
      "train_loss = 87.6936\n",
      "test_loss = 76.2482\n",
      "****************************\n",
      "Epoch: 2324\n",
      "train_loss = 87.9113\n",
      "test_loss = 74.9111\n",
      "****************************\n",
      "Epoch: 2325\n",
      "train_loss = 87.7223\n",
      "test_loss = 76.6793\n",
      "****************************\n",
      "Epoch: 2326\n",
      "train_loss = 87.6859\n",
      "test_loss = 76.3581\n",
      "****************************\n",
      "Epoch: 2327\n",
      "train_loss = 87.6227\n",
      "test_loss = 75.1263\n",
      "****************************\n",
      "Epoch: 2328\n",
      "train_loss = 87.5676\n",
      "test_loss = 75.6364\n",
      "****************************\n",
      "Epoch: 2329\n",
      "train_loss = 87.5577\n",
      "test_loss = 75.5821\n",
      "****************************\n",
      "Epoch: 2330\n",
      "train_loss = 87.6943\n",
      "test_loss = 76.3730\n",
      "****************************\n",
      "Epoch: 2331\n",
      "train_loss = 87.8325\n",
      "test_loss = 74.7232\n",
      "****************************\n",
      "Epoch: 2332\n",
      "train_loss = 87.5881\n",
      "test_loss = 76.0515\n",
      "****************************\n",
      "Epoch: 2333\n",
      "train_loss = 87.9401\n",
      "test_loss = 74.9023\n",
      "****************************\n",
      "Epoch: 2334\n",
      "train_loss = 88.0701\n",
      "test_loss = 77.4106\n",
      "****************************\n",
      "Epoch: 2335\n",
      "train_loss = 87.7279\n",
      "test_loss = 75.0073\n",
      "****************************\n",
      "Epoch: 2336\n",
      "train_loss = 89.1652\n",
      "test_loss = 79.7506\n",
      "****************************\n",
      "Epoch: 2337\n",
      "train_loss = 88.3970\n",
      "test_loss = 78.3810\n",
      "****************************\n",
      "Epoch: 2338\n",
      "train_loss = 87.5879\n",
      "test_loss = 76.0755\n",
      "****************************\n",
      "Epoch: 2339\n",
      "train_loss = 88.1216\n",
      "test_loss = 74.4469\n",
      "****************************\n",
      "Epoch: 2340\n",
      "train_loss = 88.4580\n",
      "test_loss = 74.2561\n",
      "****************************\n",
      "Epoch: 2341\n",
      "train_loss = 87.5625\n",
      "test_loss = 75.2668\n",
      "****************************\n",
      "Epoch: 2342\n",
      "train_loss = 87.6045\n",
      "test_loss = 75.2485\n",
      "****************************\n",
      "Epoch: 2343\n",
      "train_loss = 87.6406\n",
      "test_loss = 75.0478\n",
      "****************************\n",
      "Epoch: 2344\n",
      "train_loss = 87.6508\n",
      "test_loss = 75.0017\n",
      "****************************\n",
      "Epoch: 2345\n",
      "train_loss = 87.9648\n",
      "test_loss = 77.4387\n",
      "****************************\n",
      "Epoch: 2346\n",
      "train_loss = 87.6830\n",
      "test_loss = 76.5771\n",
      "****************************\n",
      "Epoch: 2347\n",
      "train_loss = 87.6026\n",
      "test_loss = 76.2811\n",
      "****************************\n",
      "Epoch: 2348\n",
      "train_loss = 87.7911\n",
      "test_loss = 74.6343\n",
      "****************************\n",
      "Epoch: 2349\n",
      "train_loss = 88.3114\n",
      "test_loss = 78.2250\n",
      "****************************\n",
      "Epoch: 2350\n",
      "train_loss = 88.1280\n",
      "test_loss = 74.3851\n",
      "****************************\n",
      "Epoch: 2351\n",
      "train_loss = 88.1580\n",
      "test_loss = 74.3424\n",
      "****************************\n",
      "Epoch: 2352\n",
      "train_loss = 88.4620\n",
      "test_loss = 74.2491\n",
      "****************************\n",
      "Epoch: 2353\n",
      "train_loss = 88.5288\n",
      "test_loss = 74.2519\n",
      "****************************\n",
      "Epoch: 2354\n",
      "train_loss = 87.6350\n",
      "test_loss = 76.1666\n",
      "****************************\n",
      "Epoch: 2355\n",
      "train_loss = 88.8134\n",
      "test_loss = 74.5472\n",
      "****************************\n",
      "Epoch: 2356\n",
      "train_loss = 87.9124\n",
      "test_loss = 77.0286\n",
      "****************************\n",
      "Epoch: 2357\n",
      "train_loss = 87.5944\n",
      "test_loss = 75.1169\n",
      "****************************\n",
      "Epoch: 2358\n",
      "train_loss = 89.2423\n",
      "test_loss = 74.1752\n",
      "****************************\n",
      "Epoch: 2359\n",
      "train_loss = 87.6838\n",
      "test_loss = 74.7723\n",
      "****************************\n",
      "Epoch: 2360\n",
      "train_loss = 88.0184\n",
      "test_loss = 77.5207\n",
      "****************************\n",
      "Epoch: 2361\n",
      "train_loss = 88.1157\n",
      "test_loss = 77.5069\n",
      "****************************\n",
      "Epoch: 2362\n",
      "train_loss = 88.2909\n",
      "test_loss = 78.0496\n",
      "****************************\n",
      "Epoch: 2363\n",
      "train_loss = 87.5599\n",
      "test_loss = 75.9202\n",
      "****************************\n",
      "Epoch: 2364\n",
      "train_loss = 87.5735\n",
      "test_loss = 75.5159\n",
      "****************************\n",
      "Epoch: 2365\n",
      "train_loss = 88.2668\n",
      "test_loss = 78.0373\n",
      "****************************\n",
      "Epoch: 2366\n",
      "train_loss = 87.5355\n",
      "test_loss = 75.3460\n",
      "****************************\n",
      "Epoch: 2367\n",
      "train_loss = 87.5518\n",
      "test_loss = 75.9445\n",
      "****************************\n",
      "Epoch: 2368\n",
      "train_loss = 88.7656\n",
      "test_loss = 74.2017\n",
      "****************************\n",
      "Epoch: 2369\n",
      "train_loss = 88.1285\n",
      "test_loss = 74.3536\n",
      "****************************\n",
      "Epoch: 2370\n",
      "train_loss = 87.9412\n",
      "test_loss = 74.5038\n",
      "****************************\n",
      "Epoch: 2371\n",
      "train_loss = 87.6346\n",
      "test_loss = 75.1181\n",
      "****************************\n",
      "Epoch: 2372\n",
      "train_loss = 87.7298\n",
      "test_loss = 76.4809\n",
      "****************************\n",
      "Epoch: 2373\n",
      "train_loss = 87.6763\n",
      "test_loss = 74.7933\n",
      "****************************\n",
      "Epoch: 2374\n",
      "train_loss = 88.0093\n",
      "test_loss = 77.4399\n",
      "****************************\n",
      "Epoch: 2375\n",
      "train_loss = 87.6028\n",
      "test_loss = 76.0117\n",
      "****************************\n",
      "Epoch: 2376\n",
      "train_loss = 88.1750\n",
      "test_loss = 77.6819\n",
      "****************************\n",
      "Epoch: 2377\n",
      "train_loss = 87.8089\n",
      "test_loss = 74.6473\n",
      "****************************\n",
      "Epoch: 2378\n",
      "train_loss = 87.5463\n",
      "test_loss = 75.2409\n",
      "****************************\n",
      "Epoch: 2379\n",
      "train_loss = 87.8981\n",
      "test_loss = 74.5245\n",
      "****************************\n",
      "Epoch: 2380\n",
      "train_loss = 87.6155\n",
      "test_loss = 76.2872\n",
      "****************************\n",
      "Epoch: 2381\n",
      "train_loss = 87.8953\n",
      "test_loss = 77.0786\n",
      "****************************\n",
      "Epoch: 2382\n",
      "train_loss = 87.7378\n",
      "test_loss = 74.7602\n",
      "****************************\n",
      "Epoch: 2383\n",
      "train_loss = 87.5813\n",
      "test_loss = 75.4075\n",
      "****************************\n",
      "Epoch: 2384\n",
      "train_loss = 87.5849\n",
      "test_loss = 75.7282\n",
      "****************************\n",
      "Epoch: 2385\n",
      "train_loss = 87.5735\n",
      "test_loss = 75.9485\n",
      "****************************\n",
      "Epoch: 2386\n",
      "train_loss = 87.5943\n",
      "test_loss = 75.9409\n",
      "****************************\n",
      "Epoch: 2387\n",
      "train_loss = 87.6041\n",
      "test_loss = 76.2799\n",
      "****************************\n",
      "Epoch: 2388\n",
      "train_loss = 88.6869\n",
      "test_loss = 78.9303\n",
      "****************************\n",
      "Epoch: 2389\n",
      "train_loss = 87.6189\n",
      "test_loss = 75.0673\n",
      "****************************\n",
      "Epoch: 2390\n",
      "train_loss = 87.6971\n",
      "test_loss = 76.2894\n",
      "****************************\n",
      "Epoch: 2391\n",
      "train_loss = 87.7762\n",
      "test_loss = 76.7592\n",
      "****************************\n",
      "Epoch: 2392\n",
      "train_loss = 87.7253\n",
      "test_loss = 76.6646\n",
      "****************************\n",
      "Epoch: 2393\n",
      "train_loss = 87.6563\n",
      "test_loss = 75.0536\n",
      "****************************\n",
      "Epoch: 2394\n",
      "train_loss = 87.7292\n",
      "test_loss = 76.8120\n",
      "****************************\n",
      "Epoch: 2395\n",
      "train_loss = 87.7924\n",
      "test_loss = 76.9320\n",
      "****************************\n",
      "Epoch: 2396\n",
      "train_loss = 87.5605\n",
      "test_loss = 75.3765\n",
      "****************************\n",
      "Epoch: 2397\n",
      "train_loss = 87.6058\n",
      "test_loss = 76.0682\n",
      "****************************\n",
      "Epoch: 2398\n",
      "train_loss = 87.5361\n",
      "test_loss = 75.3504\n",
      "****************************\n",
      "Epoch: 2399\n",
      "train_loss = 88.2863\n",
      "test_loss = 74.2878\n",
      "****************************\n",
      "Epoch: 2400\n",
      "train_loss = 87.7962\n",
      "test_loss = 76.9217\n",
      "****************************\n",
      "Epoch: 2401\n",
      "train_loss = 88.0030\n",
      "test_loss = 74.4362\n",
      "****************************\n",
      "Epoch: 2402\n",
      "train_loss = 87.5573\n",
      "test_loss = 75.5788\n",
      "****************************\n",
      "Epoch: 2403\n",
      "train_loss = 87.6440\n",
      "test_loss = 74.8478\n",
      "****************************\n",
      "Epoch: 2404\n",
      "train_loss = 87.5265\n",
      "test_loss = 75.6734\n",
      "****************************\n",
      "Epoch: 2405\n",
      "train_loss = 87.5669\n",
      "test_loss = 75.1353\n",
      "****************************\n",
      "Epoch: 2406\n",
      "train_loss = 87.5320\n",
      "test_loss = 75.4046\n",
      "****************************\n",
      "Epoch: 2407\n",
      "train_loss = 87.9006\n",
      "test_loss = 77.1610\n",
      "****************************\n",
      "Epoch: 2408\n",
      "train_loss = 87.5421\n",
      "test_loss = 75.4063\n",
      "****************************\n",
      "Epoch: 2409\n",
      "train_loss = 87.6203\n",
      "test_loss = 74.9334\n",
      "****************************\n",
      "Epoch: 2410\n",
      "train_loss = 87.7251\n",
      "test_loss = 74.8003\n",
      "****************************\n",
      "Epoch: 2411\n",
      "train_loss = 87.6243\n",
      "test_loss = 74.9772\n",
      "****************************\n",
      "Epoch: 2412\n",
      "train_loss = 87.5471\n",
      "test_loss = 75.2588\n",
      "****************************\n",
      "Epoch: 2413\n",
      "train_loss = 87.8554\n",
      "test_loss = 74.5913\n",
      "****************************\n",
      "Epoch: 2414\n",
      "train_loss = 88.2439\n",
      "test_loss = 74.3169\n",
      "****************************\n",
      "Epoch: 2415\n",
      "train_loss = 87.6513\n",
      "test_loss = 76.3103\n",
      "****************************\n",
      "Epoch: 2416\n",
      "train_loss = 87.7654\n",
      "test_loss = 76.5666\n",
      "****************************\n",
      "Epoch: 2417\n",
      "train_loss = 87.5307\n",
      "test_loss = 75.5098\n",
      "****************************\n",
      "Epoch: 2418\n",
      "train_loss = 88.3448\n",
      "test_loss = 78.1771\n",
      "****************************\n",
      "Epoch: 2419\n",
      "train_loss = 87.6025\n",
      "test_loss = 75.8246\n",
      "****************************\n",
      "Epoch: 2420\n",
      "train_loss = 87.9129\n",
      "test_loss = 74.4486\n",
      "****************************\n",
      "Epoch: 2421\n",
      "train_loss = 87.7085\n",
      "test_loss = 74.7058\n",
      "****************************\n",
      "Epoch: 2422\n",
      "train_loss = 87.8536\n",
      "test_loss = 76.8738\n",
      "****************************\n",
      "Epoch: 2423\n",
      "train_loss = 87.8867\n",
      "test_loss = 74.5197\n",
      "****************************\n",
      "Epoch: 2424\n",
      "train_loss = 87.6834\n",
      "test_loss = 74.8056\n",
      "****************************\n",
      "Epoch: 2425\n",
      "train_loss = 87.6293\n",
      "test_loss = 76.1345\n",
      "****************************\n",
      "Epoch: 2426\n",
      "train_loss = 88.7551\n",
      "test_loss = 74.1828\n",
      "****************************\n",
      "Epoch: 2427\n",
      "train_loss = 88.2180\n",
      "test_loss = 74.3414\n",
      "****************************\n",
      "Epoch: 2428\n",
      "train_loss = 87.8217\n",
      "test_loss = 74.5902\n",
      "****************************\n",
      "Epoch: 2429\n",
      "train_loss = 87.5797\n",
      "test_loss = 75.8935\n",
      "****************************\n",
      "Epoch: 2430\n",
      "train_loss = 87.5769\n",
      "test_loss = 74.9852\n",
      "****************************\n",
      "Epoch: 2431\n",
      "train_loss = 87.5297\n",
      "test_loss = 75.8327\n",
      "****************************\n",
      "Epoch: 2432\n",
      "train_loss = 87.6680\n",
      "test_loss = 74.8013\n",
      "****************************\n",
      "Epoch: 2433\n",
      "train_loss = 87.6577\n",
      "test_loss = 74.7840\n",
      "****************************\n",
      "Epoch: 2434\n",
      "train_loss = 87.8040\n",
      "test_loss = 76.3801\n",
      "****************************\n",
      "Epoch: 2435\n",
      "train_loss = 87.6493\n",
      "test_loss = 74.9672\n",
      "****************************\n",
      "Epoch: 2436\n",
      "train_loss = 87.5575\n",
      "test_loss = 75.8353\n",
      "****************************\n",
      "Epoch: 2437\n",
      "train_loss = 87.5476\n",
      "test_loss = 75.1239\n",
      "****************************\n",
      "Epoch: 2438\n",
      "train_loss = 87.7285\n",
      "test_loss = 74.6492\n",
      "****************************\n",
      "Epoch: 2439\n",
      "train_loss = 87.8234\n",
      "test_loss = 76.4648\n",
      "****************************\n",
      "Epoch: 2440\n",
      "train_loss = 87.5547\n",
      "test_loss = 75.2700\n",
      "****************************\n",
      "Epoch: 2441\n",
      "train_loss = 88.2250\n",
      "test_loss = 74.3360\n",
      "****************************\n",
      "Epoch: 2442\n",
      "train_loss = 87.5875\n",
      "test_loss = 75.8939\n",
      "****************************\n",
      "Epoch: 2443\n",
      "train_loss = 88.3149\n",
      "test_loss = 74.2759\n",
      "****************************\n",
      "Epoch: 2444\n",
      "train_loss = 87.6405\n",
      "test_loss = 74.9064\n",
      "****************************\n",
      "Epoch: 2445\n",
      "train_loss = 87.8806\n",
      "test_loss = 76.8165\n",
      "****************************\n",
      "Epoch: 2446\n",
      "train_loss = 87.9283\n",
      "test_loss = 74.4683\n",
      "****************************\n",
      "Epoch: 2447\n",
      "train_loss = 88.7586\n",
      "test_loss = 74.1870\n",
      "****************************\n",
      "Epoch: 2448\n",
      "train_loss = 87.5669\n",
      "test_loss = 75.9723\n",
      "****************************\n",
      "Epoch: 2449\n",
      "train_loss = 87.5266\n",
      "test_loss = 75.2267\n",
      "****************************\n",
      "Epoch: 2450\n",
      "train_loss = 87.9772\n",
      "test_loss = 77.4718\n",
      "****************************\n",
      "Epoch: 2451\n",
      "train_loss = 87.6483\n",
      "test_loss = 74.8445\n",
      "****************************\n",
      "Epoch: 2452\n",
      "train_loss = 87.7362\n",
      "test_loss = 74.7094\n",
      "****************************\n",
      "Epoch: 2453\n",
      "train_loss = 87.5463\n",
      "test_loss = 75.1168\n",
      "****************************\n",
      "Epoch: 2454\n",
      "train_loss = 87.5728\n",
      "test_loss = 74.9658\n",
      "****************************\n",
      "Epoch: 2455\n",
      "train_loss = 87.5593\n",
      "test_loss = 75.1106\n",
      "****************************\n",
      "Epoch: 2456\n",
      "train_loss = 87.5849\n",
      "test_loss = 75.9246\n",
      "****************************\n",
      "Epoch: 2457\n",
      "train_loss = 87.6115\n",
      "test_loss = 76.0506\n",
      "****************************\n",
      "Epoch: 2458\n",
      "train_loss = 87.7162\n",
      "test_loss = 74.7009\n",
      "****************************\n",
      "Epoch: 2459\n",
      "train_loss = 87.5775\n",
      "test_loss = 74.9857\n",
      "****************************\n",
      "Epoch: 2460\n",
      "train_loss = 87.5927\n",
      "test_loss = 75.1279\n",
      "****************************\n",
      "Epoch: 2461\n",
      "train_loss = 87.6606\n",
      "test_loss = 74.8121\n",
      "****************************\n",
      "Epoch: 2462\n",
      "train_loss = 87.5580\n",
      "test_loss = 75.6250\n",
      "****************************\n",
      "Epoch: 2463\n",
      "train_loss = 88.1201\n",
      "test_loss = 77.5384\n",
      "****************************\n",
      "Epoch: 2464\n",
      "train_loss = 87.6456\n",
      "test_loss = 74.8963\n",
      "****************************\n",
      "Epoch: 2465\n",
      "train_loss = 89.5585\n",
      "test_loss = 80.2892\n",
      "****************************\n",
      "Epoch: 2466\n",
      "train_loss = 88.3465\n",
      "test_loss = 74.2802\n",
      "****************************\n",
      "Epoch: 2467\n",
      "train_loss = 87.7870\n",
      "test_loss = 76.7676\n",
      "****************************\n",
      "Epoch: 2468\n",
      "train_loss = 87.8738\n",
      "test_loss = 77.1151\n",
      "****************************\n",
      "Epoch: 2469\n",
      "train_loss = 87.5387\n",
      "test_loss = 75.2310\n",
      "****************************\n",
      "Epoch: 2470\n",
      "train_loss = 87.6177\n",
      "test_loss = 76.3246\n",
      "****************************\n",
      "Epoch: 2471\n",
      "train_loss = 87.5549\n",
      "test_loss = 75.0808\n",
      "****************************\n",
      "Epoch: 2472\n",
      "train_loss = 87.5054\n",
      "test_loss = 75.5774\n",
      "****************************\n",
      "Epoch: 2473\n",
      "train_loss = 87.6228\n",
      "test_loss = 76.1273\n",
      "****************************\n",
      "Epoch: 2474\n",
      "train_loss = 89.6579\n",
      "test_loss = 80.3126\n",
      "****************************\n",
      "Epoch: 2475\n",
      "train_loss = 87.8373\n",
      "test_loss = 74.5628\n",
      "****************************\n",
      "Epoch: 2476\n",
      "train_loss = 88.5777\n",
      "test_loss = 78.5585\n",
      "****************************\n",
      "Epoch: 2477\n",
      "train_loss = 87.5798\n",
      "test_loss = 76.0278\n",
      "****************************\n",
      "Epoch: 2478\n",
      "train_loss = 87.5821\n",
      "test_loss = 75.0079\n",
      "****************************\n",
      "Epoch: 2479\n",
      "train_loss = 88.2003\n",
      "test_loss = 74.3152\n",
      "****************************\n",
      "Epoch: 2480\n",
      "train_loss = 88.5381\n",
      "test_loss = 78.4202\n",
      "****************************\n",
      "Epoch: 2481\n",
      "train_loss = 87.5656\n",
      "test_loss = 75.8995\n",
      "****************************\n",
      "Epoch: 2482\n",
      "train_loss = 87.5280\n",
      "test_loss = 75.7704\n",
      "****************************\n",
      "Epoch: 2483\n",
      "train_loss = 87.5468\n",
      "test_loss = 75.3582\n",
      "****************************\n",
      "Epoch: 2484\n",
      "train_loss = 88.0409\n",
      "test_loss = 77.5181\n",
      "****************************\n",
      "Epoch: 2485\n",
      "train_loss = 87.5740\n",
      "test_loss = 76.2330\n",
      "****************************\n",
      "Epoch: 2486\n",
      "train_loss = 87.9668\n",
      "test_loss = 74.3792\n",
      "****************************\n",
      "Epoch: 2487\n",
      "train_loss = 87.6818\n",
      "test_loss = 76.3731\n",
      "****************************\n",
      "Epoch: 2488\n",
      "train_loss = 87.7430\n",
      "test_loss = 76.1336\n",
      "****************************\n",
      "Epoch: 2489\n",
      "train_loss = 87.6056\n",
      "test_loss = 75.8718\n",
      "****************************\n",
      "Epoch: 2490\n",
      "train_loss = 87.5224\n",
      "test_loss = 75.7133\n",
      "****************************\n",
      "Epoch: 2491\n",
      "train_loss = 88.1765\n",
      "test_loss = 77.5989\n",
      "****************************\n",
      "Epoch: 2492\n",
      "train_loss = 87.6119\n",
      "test_loss = 75.8631\n",
      "****************************\n",
      "Epoch: 2493\n",
      "train_loss = 90.4189\n",
      "test_loss = 74.8302\n",
      "****************************\n",
      "Epoch: 2494\n",
      "train_loss = 87.8989\n",
      "test_loss = 76.7792\n",
      "****************************\n",
      "Epoch: 2495\n",
      "train_loss = 87.6197\n",
      "test_loss = 75.5270\n",
      "****************************\n",
      "Epoch: 2496\n",
      "train_loss = 87.9117\n",
      "test_loss = 74.5227\n",
      "****************************\n",
      "Epoch: 2497\n",
      "train_loss = 87.6208\n",
      "test_loss = 75.9987\n",
      "****************************\n",
      "Epoch: 2498\n",
      "train_loss = 88.2188\n",
      "test_loss = 74.3331\n",
      "****************************\n",
      "Epoch: 2499\n",
      "train_loss = 87.5515\n",
      "test_loss = 75.9217\n",
      "****************************\n",
      "Epoch: 2500\n",
      "train_loss = 87.6480\n",
      "test_loss = 74.8686\n",
      "****************************\n",
      "Epoch: 2501\n",
      "train_loss = 87.6054\n",
      "test_loss = 76.1434\n",
      "****************************\n",
      "Epoch: 2502\n",
      "train_loss = 88.3142\n",
      "test_loss = 74.3755\n",
      "****************************\n",
      "Epoch: 2503\n",
      "train_loss = 87.5916\n",
      "test_loss = 75.7024\n",
      "****************************\n",
      "Epoch: 2504\n",
      "train_loss = 89.2167\n",
      "test_loss = 79.5762\n",
      "****************************\n",
      "Epoch: 2505\n",
      "train_loss = 87.6172\n",
      "test_loss = 75.8225\n",
      "****************************\n",
      "Epoch: 2506\n",
      "train_loss = 88.0809\n",
      "test_loss = 74.4920\n",
      "****************************\n",
      "Epoch: 2507\n",
      "train_loss = 88.4468\n",
      "test_loss = 78.3643\n",
      "****************************\n",
      "Epoch: 2508\n",
      "train_loss = 87.5719\n",
      "test_loss = 75.7963\n",
      "****************************\n",
      "Epoch: 2509\n",
      "train_loss = 87.6114\n",
      "test_loss = 75.1078\n",
      "****************************\n",
      "Epoch: 2510\n",
      "train_loss = 88.0335\n",
      "test_loss = 77.4496\n",
      "****************************\n",
      "Epoch: 2511\n",
      "train_loss = 87.5450\n",
      "test_loss = 75.7114\n",
      "****************************\n",
      "Epoch: 2512\n",
      "train_loss = 87.5351\n",
      "test_loss = 75.6325\n",
      "****************************\n",
      "Epoch: 2513\n",
      "train_loss = 87.5435\n",
      "test_loss = 75.4924\n",
      "****************************\n",
      "Epoch: 2514\n",
      "train_loss = 87.5912\n",
      "test_loss = 75.9445\n",
      "****************************\n",
      "Epoch: 2515\n",
      "train_loss = 87.7969\n",
      "test_loss = 74.6063\n",
      "****************************\n",
      "Epoch: 2516\n",
      "train_loss = 87.5748\n",
      "test_loss = 76.0252\n",
      "****************************\n",
      "Epoch: 2517\n",
      "train_loss = 87.5441\n",
      "test_loss = 75.9140\n",
      "****************************\n",
      "Epoch: 2518\n",
      "train_loss = 87.5159\n",
      "test_loss = 75.6710\n",
      "****************************\n",
      "Epoch: 2519\n",
      "train_loss = 87.5229\n",
      "test_loss = 75.8264\n",
      "****************************\n",
      "Epoch: 2520\n",
      "train_loss = 87.6564\n",
      "test_loss = 74.9366\n",
      "****************************\n",
      "Epoch: 2521\n",
      "train_loss = 88.0867\n",
      "test_loss = 74.3841\n",
      "****************************\n",
      "Epoch: 2522\n",
      "train_loss = 87.6218\n",
      "test_loss = 75.0675\n",
      "****************************\n",
      "Epoch: 2523\n",
      "train_loss = 87.7796\n",
      "test_loss = 74.7145\n",
      "****************************\n",
      "Epoch: 2524\n",
      "train_loss = 87.6397\n",
      "test_loss = 75.9814\n",
      "****************************\n",
      "Epoch: 2525\n",
      "train_loss = 87.6317\n",
      "test_loss = 74.8836\n",
      "****************************\n",
      "Epoch: 2526\n",
      "train_loss = 87.6928\n",
      "test_loss = 76.5385\n",
      "****************************\n",
      "Epoch: 2527\n",
      "train_loss = 87.8267\n",
      "test_loss = 74.5440\n",
      "****************************\n",
      "Epoch: 2528\n",
      "train_loss = 87.5360\n",
      "test_loss = 75.7657\n",
      "****************************\n",
      "Epoch: 2529\n",
      "train_loss = 87.6362\n",
      "test_loss = 74.8405\n",
      "****************************\n",
      "Epoch: 2530\n",
      "train_loss = 87.5182\n",
      "test_loss = 75.5535\n",
      "****************************\n",
      "Epoch: 2531\n",
      "train_loss = 87.6089\n",
      "test_loss = 74.8676\n",
      "****************************\n",
      "Epoch: 2532\n",
      "train_loss = 87.5801\n",
      "test_loss = 75.1236\n",
      "****************************\n",
      "Epoch: 2533\n",
      "train_loss = 87.9277\n",
      "test_loss = 74.5909\n",
      "****************************\n",
      "Epoch: 2534\n",
      "train_loss = 90.0261\n",
      "test_loss = 81.2760\n",
      "****************************\n",
      "Epoch: 2535\n",
      "train_loss = 87.7470\n",
      "test_loss = 76.6436\n",
      "****************************\n",
      "Epoch: 2536\n",
      "train_loss = 87.7172\n",
      "test_loss = 76.5064\n",
      "****************************\n",
      "Epoch: 2537\n",
      "train_loss = 87.5934\n",
      "test_loss = 75.9407\n",
      "****************************\n",
      "Epoch: 2538\n",
      "train_loss = 87.8350\n",
      "test_loss = 74.5649\n",
      "****************************\n",
      "Epoch: 2539\n",
      "train_loss = 87.7246\n",
      "test_loss = 74.6979\n",
      "****************************\n",
      "Epoch: 2540\n",
      "train_loss = 87.7091\n",
      "test_loss = 74.6599\n",
      "****************************\n",
      "Epoch: 2541\n",
      "train_loss = 87.5380\n",
      "test_loss = 75.4234\n",
      "****************************\n",
      "Epoch: 2542\n",
      "train_loss = 88.1127\n",
      "test_loss = 74.3412\n",
      "****************************\n",
      "Epoch: 2543\n",
      "train_loss = 87.7811\n",
      "test_loss = 74.6553\n",
      "****************************\n",
      "Epoch: 2544\n",
      "train_loss = 90.0017\n",
      "test_loss = 81.2828\n",
      "****************************\n",
      "Epoch: 2545\n",
      "train_loss = 87.5869\n",
      "test_loss = 76.2590\n",
      "****************************\n",
      "Epoch: 2546\n",
      "train_loss = 87.5367\n",
      "test_loss = 75.3037\n",
      "****************************\n",
      "Epoch: 2547\n",
      "train_loss = 87.5354\n",
      "test_loss = 75.4692\n",
      "****************************\n",
      "Epoch: 2548\n",
      "train_loss = 88.0780\n",
      "test_loss = 74.4455\n",
      "****************************\n",
      "Epoch: 2549\n",
      "train_loss = 87.5779\n",
      "test_loss = 76.0763\n",
      "****************************\n",
      "Epoch: 2550\n",
      "train_loss = 88.1665\n",
      "test_loss = 74.3549\n",
      "****************************\n",
      "Epoch: 2551\n",
      "train_loss = 87.7494\n",
      "test_loss = 74.7091\n",
      "****************************\n",
      "Epoch: 2552\n",
      "train_loss = 87.6110\n",
      "test_loss = 76.2428\n",
      "****************************\n",
      "Epoch: 2553\n",
      "train_loss = 89.8254\n",
      "test_loss = 80.8709\n",
      "****************************\n",
      "Epoch: 2554\n",
      "train_loss = 88.6603\n",
      "test_loss = 74.1976\n",
      "****************************\n",
      "Epoch: 2555\n",
      "train_loss = 88.1573\n",
      "test_loss = 74.3041\n",
      "****************************\n",
      "Epoch: 2556\n",
      "train_loss = 89.0417\n",
      "test_loss = 79.3448\n",
      "****************************\n",
      "Epoch: 2557\n",
      "train_loss = 91.8233\n",
      "test_loss = 83.7734\n",
      "****************************\n",
      "Epoch: 2558\n",
      "train_loss = 87.6241\n",
      "test_loss = 75.2621\n",
      "****************************\n",
      "Epoch: 2559\n",
      "train_loss = 87.5909\n",
      "test_loss = 75.0543\n",
      "****************************\n",
      "Epoch: 2560\n",
      "train_loss = 88.0441\n",
      "test_loss = 74.3996\n",
      "****************************\n",
      "Epoch: 2561\n",
      "train_loss = 87.5447\n",
      "test_loss = 75.3590\n",
      "****************************\n",
      "Epoch: 2562\n",
      "train_loss = 87.5687\n",
      "test_loss = 76.0795\n",
      "****************************\n",
      "Epoch: 2563\n",
      "train_loss = 88.2096\n",
      "test_loss = 74.3411\n",
      "****************************\n",
      "Epoch: 2564\n",
      "train_loss = 88.1904\n",
      "test_loss = 74.3865\n",
      "****************************\n",
      "Epoch: 2565\n",
      "train_loss = 87.8126\n",
      "test_loss = 75.9949\n",
      "****************************\n",
      "Epoch: 2566\n",
      "train_loss = 87.7461\n",
      "test_loss = 76.5030\n",
      "****************************\n",
      "Epoch: 2567\n",
      "train_loss = 87.5870\n",
      "test_loss = 75.5751\n",
      "****************************\n",
      "Epoch: 2568\n",
      "train_loss = 87.6786\n",
      "test_loss = 74.9655\n",
      "****************************\n",
      "Epoch: 2569\n",
      "train_loss = 87.7272\n",
      "test_loss = 74.7667\n",
      "****************************\n",
      "Epoch: 2570\n",
      "train_loss = 87.9698\n",
      "test_loss = 77.2647\n",
      "****************************\n",
      "Epoch: 2571\n",
      "train_loss = 87.5257\n",
      "test_loss = 75.5016\n",
      "****************************\n",
      "Epoch: 2572\n",
      "train_loss = 87.8864\n",
      "test_loss = 74.5304\n",
      "****************************\n",
      "Epoch: 2573\n",
      "train_loss = 87.6283\n",
      "test_loss = 76.1843\n",
      "****************************\n",
      "Epoch: 2574\n",
      "train_loss = 87.5482\n",
      "test_loss = 75.3073\n",
      "****************************\n",
      "Epoch: 2575\n",
      "train_loss = 87.8121\n",
      "test_loss = 76.9669\n",
      "****************************\n",
      "Epoch: 2576\n",
      "train_loss = 88.0033\n",
      "test_loss = 77.2398\n",
      "****************************\n",
      "Epoch: 2577\n",
      "train_loss = 87.9251\n",
      "test_loss = 74.4546\n",
      "****************************\n",
      "Epoch: 2578\n",
      "train_loss = 87.5984\n",
      "test_loss = 76.2164\n",
      "****************************\n",
      "Epoch: 2579\n",
      "train_loss = 87.5225\n",
      "test_loss = 75.7027\n",
      "****************************\n",
      "Epoch: 2580\n",
      "train_loss = 88.4320\n",
      "test_loss = 78.1615\n",
      "****************************\n",
      "Epoch: 2581\n",
      "train_loss = 88.3910\n",
      "test_loss = 74.2051\n",
      "****************************\n",
      "Epoch: 2582\n",
      "train_loss = 87.5831\n",
      "test_loss = 74.9314\n",
      "****************************\n",
      "Epoch: 2583\n",
      "train_loss = 87.9012\n",
      "test_loss = 76.7167\n",
      "****************************\n",
      "Epoch: 2584\n",
      "train_loss = 88.0324\n",
      "test_loss = 74.4377\n",
      "****************************\n",
      "Epoch: 2585\n",
      "train_loss = 88.8699\n",
      "test_loss = 79.0522\n",
      "****************************\n",
      "Epoch: 2586\n",
      "train_loss = 87.6514\n",
      "test_loss = 74.9041\n",
      "****************************\n",
      "Epoch: 2587\n",
      "train_loss = 87.6092\n",
      "test_loss = 75.9246\n",
      "****************************\n",
      "Epoch: 2588\n",
      "train_loss = 87.5699\n",
      "test_loss = 75.1974\n",
      "****************************\n",
      "Epoch: 2589\n",
      "train_loss = 87.5634\n",
      "test_loss = 75.0753\n",
      "****************************\n",
      "Epoch: 2590\n",
      "train_loss = 88.1468\n",
      "test_loss = 77.6703\n",
      "****************************\n",
      "Epoch: 2591\n",
      "train_loss = 87.5556\n",
      "test_loss = 75.4726\n",
      "****************************\n",
      "Epoch: 2592\n",
      "train_loss = 87.5628\n",
      "test_loss = 75.0929\n",
      "****************************\n",
      "Epoch: 2593\n",
      "train_loss = 88.5673\n",
      "test_loss = 78.7626\n",
      "****************************\n",
      "Epoch: 2594\n",
      "train_loss = 87.5658\n",
      "test_loss = 76.0025\n",
      "****************************\n",
      "Epoch: 2595\n",
      "train_loss = 87.5375\n",
      "test_loss = 75.2307\n",
      "****************************\n",
      "Epoch: 2596\n",
      "train_loss = 87.5376\n",
      "test_loss = 75.9149\n",
      "****************************\n",
      "Epoch: 2597\n",
      "train_loss = 87.5007\n",
      "test_loss = 75.6594\n",
      "****************************\n",
      "Epoch: 2598\n",
      "train_loss = 87.5715\n",
      "test_loss = 76.1087\n",
      "****************************\n",
      "Epoch: 2599\n",
      "train_loss = 87.8977\n",
      "test_loss = 74.4616\n",
      "****************************\n",
      "Epoch: 2600\n",
      "train_loss = 88.0367\n",
      "test_loss = 77.4874\n",
      "****************************\n",
      "Epoch: 2601\n",
      "train_loss = 87.5076\n",
      "test_loss = 75.4232\n",
      "****************************\n",
      "Epoch: 2602\n",
      "train_loss = 87.7363\n",
      "test_loss = 74.6312\n",
      "****************************\n",
      "Epoch: 2603\n",
      "train_loss = 88.0438\n",
      "test_loss = 74.3326\n",
      "****************************\n",
      "Epoch: 2604\n",
      "train_loss = 87.9467\n",
      "test_loss = 77.2760\n",
      "****************************\n",
      "Epoch: 2605\n",
      "train_loss = 87.5464\n",
      "test_loss = 75.6743\n",
      "****************************\n",
      "Epoch: 2606\n",
      "train_loss = 87.7361\n",
      "test_loss = 74.6495\n",
      "****************************\n",
      "Epoch: 2607\n",
      "train_loss = 87.7473\n",
      "test_loss = 76.6574\n",
      "****************************\n",
      "Epoch: 2608\n",
      "train_loss = 87.5747\n",
      "test_loss = 76.1563\n",
      "****************************\n",
      "Epoch: 2609\n",
      "train_loss = 87.5861\n",
      "test_loss = 76.2117\n",
      "****************************\n",
      "Epoch: 2610\n",
      "train_loss = 87.7688\n",
      "test_loss = 76.9196\n",
      "****************************\n",
      "Epoch: 2611\n",
      "train_loss = 87.6514\n",
      "test_loss = 76.5497\n",
      "****************************\n",
      "Epoch: 2612\n",
      "train_loss = 87.4961\n",
      "test_loss = 75.6711\n",
      "****************************\n",
      "Epoch: 2613\n",
      "train_loss = 87.6035\n",
      "test_loss = 76.1872\n",
      "****************************\n",
      "Epoch: 2614\n",
      "train_loss = 87.5227\n",
      "test_loss = 75.7906\n",
      "****************************\n",
      "Epoch: 2615\n",
      "train_loss = 87.4913\n",
      "test_loss = 75.6412\n",
      "****************************\n",
      "Epoch: 2616\n",
      "train_loss = 87.5750\n",
      "test_loss = 76.1207\n",
      "****************************\n",
      "Epoch: 2617\n",
      "train_loss = 87.7820\n",
      "test_loss = 74.5725\n",
      "****************************\n",
      "Epoch: 2618\n",
      "train_loss = 87.5379\n",
      "test_loss = 75.0732\n",
      "****************************\n",
      "Epoch: 2619\n",
      "train_loss = 87.4947\n",
      "test_loss = 75.3269\n",
      "****************************\n",
      "Epoch: 2620\n",
      "train_loss = 87.8735\n",
      "test_loss = 77.1333\n",
      "****************************\n",
      "Epoch: 2621\n",
      "train_loss = 87.5885\n",
      "test_loss = 74.8712\n",
      "****************************\n",
      "Epoch: 2622\n",
      "train_loss = 90.3475\n",
      "test_loss = 81.4580\n",
      "****************************\n",
      "Epoch: 2623\n",
      "train_loss = 87.5591\n",
      "test_loss = 75.6066\n",
      "****************************\n",
      "Epoch: 2624\n",
      "train_loss = 87.5225\n",
      "test_loss = 75.1670\n",
      "****************************\n",
      "Epoch: 2625\n",
      "train_loss = 89.9172\n",
      "test_loss = 80.8787\n",
      "****************************\n",
      "Epoch: 2626\n",
      "train_loss = 87.5026\n",
      "test_loss = 75.5915\n",
      "****************************\n",
      "Epoch: 2627\n",
      "train_loss = 88.8119\n",
      "test_loss = 78.6237\n",
      "****************************\n",
      "Epoch: 2628\n",
      "train_loss = 87.7529\n",
      "test_loss = 74.7382\n",
      "****************************\n",
      "Epoch: 2629\n",
      "train_loss = 87.6421\n",
      "test_loss = 75.0899\n",
      "****************************\n",
      "Epoch: 2630\n",
      "train_loss = 87.6531\n",
      "test_loss = 76.2626\n",
      "****************************\n",
      "Epoch: 2631\n",
      "train_loss = 88.0609\n",
      "test_loss = 74.3708\n",
      "****************************\n",
      "Epoch: 2632\n",
      "train_loss = 87.5132\n",
      "test_loss = 75.2966\n",
      "****************************\n",
      "Epoch: 2633\n",
      "train_loss = 87.6907\n",
      "test_loss = 74.6943\n",
      "****************************\n",
      "Epoch: 2634\n",
      "train_loss = 87.5482\n",
      "test_loss = 75.1481\n",
      "****************************\n",
      "Epoch: 2635\n",
      "train_loss = 87.7909\n",
      "test_loss = 74.6510\n",
      "****************************\n",
      "Epoch: 2636\n",
      "train_loss = 88.6213\n",
      "test_loss = 74.1852\n",
      "****************************\n",
      "Epoch: 2637\n",
      "train_loss = 87.5769\n",
      "test_loss = 76.1040\n",
      "****************************\n",
      "Epoch: 2638\n",
      "train_loss = 87.4919\n",
      "test_loss = 75.4010\n",
      "****************************\n",
      "Epoch: 2639\n",
      "train_loss = 87.7050\n",
      "test_loss = 74.6722\n",
      "****************************\n",
      "Epoch: 2640\n",
      "train_loss = 87.6006\n",
      "test_loss = 76.2345\n",
      "****************************\n",
      "Epoch: 2641\n",
      "train_loss = 88.1338\n",
      "test_loss = 74.3051\n",
      "****************************\n",
      "Epoch: 2642\n",
      "train_loss = 89.7316\n",
      "test_loss = 80.3958\n",
      "****************************\n",
      "Epoch: 2643\n",
      "train_loss = 87.8343\n",
      "test_loss = 76.5609\n",
      "****************************\n",
      "Epoch: 2644\n",
      "train_loss = 87.9200\n",
      "test_loss = 74.6190\n",
      "****************************\n",
      "Epoch: 2645\n",
      "train_loss = 87.6380\n",
      "test_loss = 75.7313\n",
      "****************************\n",
      "Epoch: 2646\n",
      "train_loss = 87.7796\n",
      "test_loss = 74.7004\n",
      "****************************\n",
      "Epoch: 2647\n",
      "train_loss = 87.5645\n",
      "test_loss = 75.3402\n",
      "****************************\n",
      "Epoch: 2648\n",
      "train_loss = 88.2183\n",
      "test_loss = 74.4315\n",
      "****************************\n",
      "Epoch: 2649\n",
      "train_loss = 91.3811\n",
      "test_loss = 83.1895\n",
      "****************************\n",
      "Epoch: 2650\n",
      "train_loss = 89.2425\n",
      "test_loss = 79.8465\n",
      "****************************\n",
      "Epoch: 2651\n",
      "train_loss = 87.6234\n",
      "test_loss = 76.0942\n",
      "****************************\n",
      "Epoch: 2652\n",
      "train_loss = 88.2327\n",
      "test_loss = 78.0760\n",
      "****************************\n",
      "Epoch: 2653\n",
      "train_loss = 88.6894\n",
      "test_loss = 78.9106\n",
      "****************************\n",
      "Epoch: 2654\n",
      "train_loss = 88.0461\n",
      "test_loss = 77.3845\n",
      "****************************\n",
      "Epoch: 2655\n",
      "train_loss = 87.6261\n",
      "test_loss = 76.1394\n",
      "****************************\n",
      "Epoch: 2656\n",
      "train_loss = 87.6763\n",
      "test_loss = 76.2761\n",
      "****************************\n",
      "Epoch: 2657\n",
      "train_loss = 87.6499\n",
      "test_loss = 76.0836\n",
      "****************************\n",
      "Epoch: 2658\n",
      "train_loss = 87.6079\n",
      "test_loss = 75.5335\n",
      "****************************\n",
      "Epoch: 2659\n",
      "train_loss = 87.6235\n",
      "test_loss = 74.9791\n",
      "****************************\n",
      "Epoch: 2660\n",
      "train_loss = 87.6025\n",
      "test_loss = 75.4319\n",
      "****************************\n",
      "Epoch: 2661\n",
      "train_loss = 87.7299\n",
      "test_loss = 74.7100\n",
      "****************************\n",
      "Epoch: 2662\n",
      "train_loss = 87.9413\n",
      "test_loss = 74.4233\n",
      "****************************\n",
      "Epoch: 2663\n",
      "train_loss = 87.9257\n",
      "test_loss = 76.8966\n",
      "****************************\n",
      "Epoch: 2664\n",
      "train_loss = 87.5756\n",
      "test_loss = 75.4288\n",
      "****************************\n",
      "Epoch: 2665\n",
      "train_loss = 87.9248\n",
      "test_loss = 75.0122\n",
      "****************************\n",
      "Epoch: 2666\n",
      "train_loss = 88.1112\n",
      "test_loss = 74.4047\n",
      "****************************\n",
      "Epoch: 2667\n",
      "train_loss = 88.4675\n",
      "test_loss = 74.9522\n",
      "****************************\n",
      "Epoch: 2668\n",
      "train_loss = 87.7998\n",
      "test_loss = 74.9215\n",
      "****************************\n",
      "Epoch: 2669\n",
      "train_loss = 87.8401\n",
      "test_loss = 74.8014\n",
      "****************************\n",
      "Epoch: 2670\n",
      "train_loss = 87.6217\n",
      "test_loss = 75.2028\n",
      "****************************\n",
      "Epoch: 2671\n",
      "train_loss = 89.8704\n",
      "test_loss = 80.7480\n",
      "****************************\n",
      "Epoch: 2672\n",
      "train_loss = 87.7234\n",
      "test_loss = 74.8491\n",
      "****************************\n",
      "Epoch: 2673\n",
      "train_loss = 87.5948\n",
      "test_loss = 75.1258\n",
      "****************************\n",
      "Epoch: 2674\n",
      "train_loss = 88.3905\n",
      "test_loss = 78.2499\n",
      "****************************\n",
      "Epoch: 2675\n",
      "train_loss = 87.8270\n",
      "test_loss = 74.6805\n",
      "****************************\n",
      "Epoch: 2676\n",
      "train_loss = 88.1390\n",
      "test_loss = 74.3889\n",
      "****************************\n",
      "Epoch: 2677\n",
      "train_loss = 87.5794\n",
      "test_loss = 76.0836\n",
      "****************************\n",
      "Epoch: 2678\n",
      "train_loss = 87.6435\n",
      "test_loss = 76.3459\n",
      "****************************\n",
      "Epoch: 2679\n",
      "train_loss = 87.5569\n",
      "test_loss = 75.3480\n",
      "****************************\n",
      "Epoch: 2680\n",
      "train_loss = 88.2517\n",
      "test_loss = 77.8625\n",
      "****************************\n",
      "Epoch: 2681\n",
      "train_loss = 87.7967\n",
      "test_loss = 76.7080\n",
      "****************************\n",
      "Epoch: 2682\n",
      "train_loss = 87.7149\n",
      "test_loss = 74.8047\n",
      "****************************\n",
      "Epoch: 2683\n",
      "train_loss = 87.5713\n",
      "test_loss = 75.3121\n",
      "****************************\n",
      "Epoch: 2684\n",
      "train_loss = 87.5708\n",
      "test_loss = 75.0787\n",
      "****************************\n",
      "Epoch: 2685\n",
      "train_loss = 87.8503\n",
      "test_loss = 76.9719\n",
      "****************************\n",
      "Epoch: 2686\n",
      "train_loss = 87.7026\n",
      "test_loss = 74.7874\n",
      "****************************\n",
      "Epoch: 2687\n",
      "train_loss = 87.8498\n",
      "test_loss = 74.5554\n",
      "****************************\n",
      "Epoch: 2688\n",
      "train_loss = 87.7220\n",
      "test_loss = 76.4956\n",
      "****************************\n",
      "Epoch: 2689\n",
      "train_loss = 87.5353\n",
      "test_loss = 75.3854\n",
      "****************************\n",
      "Epoch: 2690\n",
      "train_loss = 87.5582\n",
      "test_loss = 76.0303\n",
      "****************************\n",
      "Epoch: 2691\n",
      "train_loss = 87.5554\n",
      "test_loss = 75.1054\n",
      "****************************\n",
      "Epoch: 2692\n",
      "train_loss = 87.6917\n",
      "test_loss = 74.7280\n",
      "****************************\n",
      "Epoch: 2693\n",
      "train_loss = 87.6540\n",
      "test_loss = 76.4115\n",
      "****************************\n",
      "Epoch: 2694\n",
      "train_loss = 87.5583\n",
      "test_loss = 76.0259\n",
      "****************************\n",
      "Epoch: 2695\n",
      "train_loss = 87.5201\n",
      "test_loss = 75.8516\n",
      "****************************\n",
      "Epoch: 2696\n",
      "train_loss = 87.5085\n",
      "test_loss = 75.5705\n",
      "****************************\n",
      "Epoch: 2697\n",
      "train_loss = 87.5488\n",
      "test_loss = 75.0419\n",
      "****************************\n",
      "Epoch: 2698\n",
      "train_loss = 87.4964\n",
      "test_loss = 75.5293\n",
      "****************************\n",
      "Epoch: 2699\n",
      "train_loss = 87.5328\n",
      "test_loss = 75.6617\n",
      "****************************\n",
      "Epoch: 2700\n",
      "train_loss = 87.5054\n",
      "test_loss = 75.4941\n",
      "****************************\n",
      "Epoch: 2701\n",
      "train_loss = 87.5146\n",
      "test_loss = 75.6922\n",
      "****************************\n",
      "Epoch: 2702\n",
      "train_loss = 88.0639\n",
      "test_loss = 74.3571\n",
      "****************************\n",
      "Epoch: 2703\n",
      "train_loss = 87.9858\n",
      "test_loss = 77.5159\n",
      "****************************\n",
      "Epoch: 2704\n",
      "train_loss = 87.6441\n",
      "test_loss = 74.7748\n",
      "****************************\n",
      "Epoch: 2705\n",
      "train_loss = 87.5797\n",
      "test_loss = 75.3424\n",
      "****************************\n",
      "Epoch: 2706\n",
      "train_loss = 87.5300\n",
      "test_loss = 75.6626\n",
      "****************************\n",
      "Epoch: 2707\n",
      "train_loss = 87.5289\n",
      "test_loss = 75.2303\n",
      "****************************\n",
      "Epoch: 2708\n",
      "train_loss = 89.2310\n",
      "test_loss = 79.8354\n",
      "****************************\n",
      "Epoch: 2709\n",
      "train_loss = 87.5645\n",
      "test_loss = 76.1460\n",
      "****************************\n",
      "Epoch: 2710\n",
      "train_loss = 87.5037\n",
      "test_loss = 75.2331\n",
      "****************************\n",
      "Epoch: 2711\n",
      "train_loss = 87.6153\n",
      "test_loss = 76.3105\n",
      "****************************\n",
      "Epoch: 2712\n",
      "train_loss = 87.4940\n",
      "test_loss = 75.3837\n",
      "****************************\n",
      "Epoch: 2713\n",
      "train_loss = 87.5003\n",
      "test_loss = 75.3276\n",
      "****************************\n",
      "Epoch: 2714\n",
      "train_loss = 87.5405\n",
      "test_loss = 75.9937\n",
      "****************************\n",
      "Epoch: 2715\n",
      "train_loss = 87.5933\n",
      "test_loss = 74.8442\n",
      "****************************\n",
      "Epoch: 2716\n",
      "train_loss = 87.6136\n",
      "test_loss = 76.3539\n",
      "****************************\n",
      "Epoch: 2717\n",
      "train_loss = 87.5959\n",
      "test_loss = 74.9161\n",
      "****************************\n",
      "Epoch: 2718\n",
      "train_loss = 87.5563\n",
      "test_loss = 75.8696\n",
      "****************************\n",
      "Epoch: 2719\n",
      "train_loss = 87.5415\n",
      "test_loss = 75.1330\n",
      "****************************\n",
      "Epoch: 2720\n",
      "train_loss = 87.5139\n",
      "test_loss = 75.4616\n",
      "****************************\n",
      "Epoch: 2721\n",
      "train_loss = 87.8829\n",
      "test_loss = 74.4600\n",
      "****************************\n",
      "Epoch: 2722\n",
      "train_loss = 87.6779\n",
      "test_loss = 76.4632\n",
      "****************************\n",
      "Epoch: 2723\n",
      "train_loss = 89.2711\n",
      "test_loss = 79.8874\n",
      "****************************\n",
      "Epoch: 2724\n",
      "train_loss = 87.6983\n",
      "test_loss = 76.6544\n",
      "****************************\n",
      "Epoch: 2725\n",
      "train_loss = 87.7146\n",
      "test_loss = 74.6910\n",
      "****************************\n",
      "Epoch: 2726\n",
      "train_loss = 87.9046\n",
      "test_loss = 74.4805\n",
      "****************************\n",
      "Epoch: 2727\n",
      "train_loss = 87.5733\n",
      "test_loss = 75.2855\n",
      "****************************\n",
      "Epoch: 2728\n",
      "train_loss = 87.6214\n",
      "test_loss = 74.9577\n",
      "****************************\n",
      "Epoch: 2729\n",
      "train_loss = 88.9996\n",
      "test_loss = 74.1910\n",
      "****************************\n",
      "Epoch: 2730\n",
      "train_loss = 87.9769\n",
      "test_loss = 74.4499\n",
      "****************************\n",
      "Epoch: 2731\n",
      "train_loss = 87.6769\n",
      "test_loss = 76.3211\n",
      "****************************\n",
      "Epoch: 2732\n",
      "train_loss = 87.6468\n",
      "test_loss = 76.2447\n",
      "****************************\n",
      "Epoch: 2733\n",
      "train_loss = 87.7528\n",
      "test_loss = 76.5946\n",
      "****************************\n",
      "Epoch: 2734\n",
      "train_loss = 87.6497\n",
      "test_loss = 74.8048\n",
      "****************************\n",
      "Epoch: 2735\n",
      "train_loss = 87.5796\n",
      "test_loss = 75.8639\n",
      "****************************\n",
      "Epoch: 2736\n",
      "train_loss = 87.7206\n",
      "test_loss = 76.5462\n",
      "****************************\n",
      "Epoch: 2737\n",
      "train_loss = 87.7548\n",
      "test_loss = 74.6286\n",
      "****************************\n",
      "Epoch: 2738\n",
      "train_loss = 87.5136\n",
      "test_loss = 75.3240\n",
      "****************************\n",
      "Epoch: 2739\n",
      "train_loss = 87.5760\n",
      "test_loss = 74.9603\n",
      "****************************\n",
      "Epoch: 2740\n",
      "train_loss = 87.8118\n",
      "test_loss = 74.6159\n",
      "****************************\n",
      "Epoch: 2741\n",
      "train_loss = 87.7637\n",
      "test_loss = 76.8215\n",
      "****************************\n",
      "Epoch: 2742\n",
      "train_loss = 87.5634\n",
      "test_loss = 75.9702\n",
      "****************************\n",
      "Epoch: 2743\n",
      "train_loss = 87.5285\n",
      "test_loss = 75.3580\n",
      "****************************\n",
      "Epoch: 2744\n",
      "train_loss = 88.4895\n",
      "test_loss = 74.2291\n",
      "****************************\n",
      "Epoch: 2745\n",
      "train_loss = 87.6214\n",
      "test_loss = 74.9054\n",
      "****************************\n",
      "Epoch: 2746\n",
      "train_loss = 87.5569\n",
      "test_loss = 75.8320\n",
      "****************************\n",
      "Epoch: 2747\n",
      "train_loss = 87.7379\n",
      "test_loss = 74.6458\n",
      "****************************\n",
      "Epoch: 2748\n",
      "train_loss = 87.5738\n",
      "test_loss = 74.9365\n",
      "****************************\n",
      "Epoch: 2749\n",
      "train_loss = 87.5208\n",
      "test_loss = 75.9602\n",
      "****************************\n",
      "Epoch: 2750\n",
      "train_loss = 88.1739\n",
      "test_loss = 74.8536\n",
      "****************************\n",
      "Epoch: 2751\n",
      "train_loss = 88.7544\n",
      "test_loss = 79.1087\n",
      "****************************\n",
      "Epoch: 2752\n",
      "train_loss = 88.1255\n",
      "test_loss = 74.3341\n",
      "****************************\n",
      "Epoch: 2753\n",
      "train_loss = 87.5681\n",
      "test_loss = 75.9386\n",
      "****************************\n",
      "Epoch: 2754\n",
      "train_loss = 87.6376\n",
      "test_loss = 74.8995\n",
      "****************************\n",
      "Epoch: 2755\n",
      "train_loss = 87.9388\n",
      "test_loss = 77.0931\n",
      "****************************\n",
      "Epoch: 2756\n",
      "train_loss = 87.5329\n",
      "test_loss = 75.2662\n",
      "****************************\n",
      "Epoch: 2757\n",
      "train_loss = 87.6130\n",
      "test_loss = 74.8870\n",
      "****************************\n",
      "Epoch: 2758\n",
      "train_loss = 88.1749\n",
      "test_loss = 74.2882\n",
      "****************************\n",
      "Epoch: 2759\n",
      "train_loss = 87.5785\n",
      "test_loss = 74.9616\n",
      "****************************\n",
      "Epoch: 2760\n",
      "train_loss = 87.6666\n",
      "test_loss = 74.7011\n",
      "****************************\n",
      "Epoch: 2761\n",
      "train_loss = 88.8743\n",
      "test_loss = 79.0258\n",
      "****************************\n",
      "Epoch: 2762\n",
      "train_loss = 88.0045\n",
      "test_loss = 74.3732\n",
      "****************************\n",
      "Epoch: 2763\n",
      "train_loss = 87.5149\n",
      "test_loss = 75.2360\n",
      "****************************\n",
      "Epoch: 2764\n",
      "train_loss = 88.2639\n",
      "test_loss = 74.2215\n",
      "****************************\n",
      "Epoch: 2765\n",
      "train_loss = 88.0671\n",
      "test_loss = 74.3385\n",
      "****************************\n",
      "Epoch: 2766\n",
      "train_loss = 88.1480\n",
      "test_loss = 74.2631\n",
      "****************************\n",
      "Epoch: 2767\n",
      "train_loss = 87.8449\n",
      "test_loss = 74.4689\n",
      "****************************\n",
      "Epoch: 2768\n",
      "train_loss = 87.5480\n",
      "test_loss = 76.0168\n",
      "****************************\n",
      "Epoch: 2769\n",
      "train_loss = 87.5250\n",
      "test_loss = 75.0758\n",
      "****************************\n",
      "Epoch: 2770\n",
      "train_loss = 87.8810\n",
      "test_loss = 74.4444\n",
      "****************************\n",
      "Epoch: 2771\n",
      "train_loss = 87.7710\n",
      "test_loss = 74.5660\n",
      "****************************\n",
      "Epoch: 2772\n",
      "train_loss = 87.5232\n",
      "test_loss = 75.4562\n",
      "****************************\n",
      "Epoch: 2773\n",
      "train_loss = 87.6722\n",
      "test_loss = 74.7465\n",
      "****************************\n",
      "Epoch: 2774\n",
      "train_loss = 87.5504\n",
      "test_loss = 75.7476\n",
      "****************************\n",
      "Epoch: 2775\n",
      "train_loss = 87.5043\n",
      "test_loss = 75.5002\n",
      "****************************\n",
      "Epoch: 2776\n",
      "train_loss = 87.6546\n",
      "test_loss = 74.7437\n",
      "****************************\n",
      "Epoch: 2777\n",
      "train_loss = 87.5026\n",
      "test_loss = 75.1715\n",
      "****************************\n",
      "Epoch: 2778\n",
      "train_loss = 87.4876\n",
      "test_loss = 75.5622\n",
      "****************************\n",
      "Epoch: 2779\n",
      "train_loss = 87.6512\n",
      "test_loss = 74.7248\n",
      "****************************\n",
      "Epoch: 2780\n",
      "train_loss = 87.5427\n",
      "test_loss = 75.8654\n",
      "****************************\n",
      "Epoch: 2781\n",
      "train_loss = 87.6572\n",
      "test_loss = 74.7898\n",
      "****************************\n",
      "Epoch: 2782\n",
      "train_loss = 88.0958\n",
      "test_loss = 77.4485\n",
      "****************************\n",
      "Epoch: 2783\n",
      "train_loss = 87.6012\n",
      "test_loss = 76.0671\n",
      "****************************\n",
      "Epoch: 2784\n",
      "train_loss = 88.2019\n",
      "test_loss = 77.7506\n",
      "****************************\n",
      "Epoch: 2785\n",
      "train_loss = 87.6163\n",
      "test_loss = 74.7919\n",
      "****************************\n",
      "Epoch: 2786\n",
      "train_loss = 87.6441\n",
      "test_loss = 74.7711\n",
      "****************************\n",
      "Epoch: 2787\n",
      "train_loss = 87.5992\n",
      "test_loss = 76.2175\n",
      "****************************\n",
      "Epoch: 2788\n",
      "train_loss = 87.4924\n",
      "test_loss = 75.4898\n",
      "****************************\n",
      "Epoch: 2789\n",
      "train_loss = 88.1000\n",
      "test_loss = 77.6141\n",
      "****************************\n",
      "Epoch: 2790\n",
      "train_loss = 87.9180\n",
      "test_loss = 77.1642\n",
      "****************************\n",
      "Epoch: 2791\n",
      "train_loss = 88.4558\n",
      "test_loss = 78.5074\n",
      "****************************\n",
      "Epoch: 2792\n",
      "train_loss = 92.2410\n",
      "test_loss = 75.1992\n",
      "****************************\n",
      "Epoch: 2793\n",
      "train_loss = 87.7262\n",
      "test_loss = 76.4132\n",
      "****************************\n",
      "Epoch: 2794\n",
      "train_loss = 87.6401\n",
      "test_loss = 75.0538\n",
      "****************************\n",
      "Epoch: 2795\n",
      "train_loss = 87.5628\n",
      "test_loss = 75.8085\n",
      "****************************\n",
      "Epoch: 2796\n",
      "train_loss = 88.2206\n",
      "test_loss = 78.0360\n",
      "****************************\n",
      "Epoch: 2797\n",
      "train_loss = 87.6303\n",
      "test_loss = 76.5299\n",
      "****************************\n",
      "Epoch: 2798\n",
      "train_loss = 87.5430\n",
      "test_loss = 74.9973\n",
      "****************************\n",
      "Epoch: 2799\n",
      "train_loss = 87.5320\n",
      "test_loss = 75.0927\n",
      "****************************\n",
      "Epoch: 2800\n",
      "train_loss = 88.3691\n",
      "test_loss = 78.3398\n",
      "****************************\n",
      "Epoch: 2801\n",
      "train_loss = 87.5933\n",
      "test_loss = 74.9532\n",
      "****************************\n",
      "Epoch: 2802\n",
      "train_loss = 87.5758\n",
      "test_loss = 76.0956\n",
      "****************************\n",
      "Epoch: 2803\n",
      "train_loss = 87.5582\n",
      "test_loss = 75.0901\n",
      "****************************\n",
      "Epoch: 2804\n",
      "train_loss = 87.5699\n",
      "test_loss = 74.9277\n",
      "****************************\n",
      "Epoch: 2805\n",
      "train_loss = 87.5983\n",
      "test_loss = 76.2668\n",
      "****************************\n",
      "Epoch: 2806\n",
      "train_loss = 87.9483\n",
      "test_loss = 74.9562\n",
      "****************************\n",
      "Epoch: 2807\n",
      "train_loss = 87.6343\n",
      "test_loss = 76.1809\n",
      "****************************\n",
      "Epoch: 2808\n",
      "train_loss = 87.8873\n",
      "test_loss = 74.5069\n",
      "****************************\n",
      "Epoch: 2809\n",
      "train_loss = 87.5177\n",
      "test_loss = 75.8890\n",
      "****************************\n",
      "Epoch: 2810\n",
      "train_loss = 90.6996\n",
      "test_loss = 82.4251\n",
      "****************************\n",
      "Epoch: 2811\n",
      "train_loss = 87.5941\n",
      "test_loss = 76.3885\n",
      "****************************\n",
      "Epoch: 2812\n",
      "train_loss = 88.2187\n",
      "test_loss = 78.1609\n",
      "****************************\n",
      "Epoch: 2813\n",
      "train_loss = 88.2143\n",
      "test_loss = 78.0027\n",
      "****************************\n",
      "Epoch: 2814\n",
      "train_loss = 87.5353\n",
      "test_loss = 75.8622\n",
      "****************************\n",
      "Epoch: 2815\n",
      "train_loss = 87.4919\n",
      "test_loss = 75.6735\n",
      "****************************\n",
      "Epoch: 2816\n",
      "train_loss = 87.5589\n",
      "test_loss = 75.0224\n",
      "****************************\n",
      "Epoch: 2817\n",
      "train_loss = 87.8767\n",
      "test_loss = 74.4603\n",
      "****************************\n",
      "Epoch: 2818\n",
      "train_loss = 87.7838\n",
      "test_loss = 76.6744\n",
      "****************************\n",
      "Epoch: 2819\n",
      "train_loss = 87.5530\n",
      "test_loss = 75.1391\n",
      "****************************\n",
      "Epoch: 2820\n",
      "train_loss = 87.5066\n",
      "test_loss = 75.5194\n",
      "****************************\n",
      "Epoch: 2821\n",
      "train_loss = 87.6016\n",
      "test_loss = 74.8523\n",
      "****************************\n",
      "Epoch: 2822\n",
      "train_loss = 87.8637\n",
      "test_loss = 74.4727\n",
      "****************************\n",
      "Epoch: 2823\n",
      "train_loss = 87.4821\n",
      "test_loss = 75.5461\n",
      "****************************\n",
      "Epoch: 2824\n",
      "train_loss = 87.4853\n",
      "test_loss = 75.3502\n",
      "****************************\n",
      "Epoch: 2825\n",
      "train_loss = 88.2653\n",
      "test_loss = 78.1232\n",
      "****************************\n",
      "Epoch: 2826\n",
      "train_loss = 87.9634\n",
      "test_loss = 74.4701\n",
      "****************************\n",
      "Epoch: 2827\n",
      "train_loss = 87.5681\n",
      "test_loss = 75.0271\n",
      "****************************\n",
      "Epoch: 2828\n",
      "train_loss = 87.5869\n",
      "test_loss = 76.1620\n",
      "****************************\n",
      "Epoch: 2829\n",
      "train_loss = 90.1495\n",
      "test_loss = 81.1915\n",
      "****************************\n",
      "Epoch: 2830\n",
      "train_loss = 88.0528\n",
      "test_loss = 77.5124\n",
      "****************************\n",
      "Epoch: 2831\n",
      "train_loss = 87.5716\n",
      "test_loss = 75.9501\n",
      "****************************\n",
      "Epoch: 2832\n",
      "train_loss = 87.7456\n",
      "test_loss = 76.5642\n",
      "****************************\n",
      "Epoch: 2833\n",
      "train_loss = 87.5293\n",
      "test_loss = 75.1168\n",
      "****************************\n",
      "Epoch: 2834\n",
      "train_loss = 87.5660\n",
      "test_loss = 75.0119\n",
      "****************************\n",
      "Epoch: 2835\n",
      "train_loss = 87.5994\n",
      "test_loss = 76.1386\n",
      "****************************\n",
      "Epoch: 2836\n",
      "train_loss = 87.7764\n",
      "test_loss = 74.5287\n",
      "****************************\n",
      "Epoch: 2837\n",
      "train_loss = 87.6015\n",
      "test_loss = 75.0227\n",
      "****************************\n",
      "Epoch: 2838\n",
      "train_loss = 87.6252\n",
      "test_loss = 76.1679\n",
      "****************************\n",
      "Epoch: 2839\n",
      "train_loss = 87.9873\n",
      "test_loss = 74.3909\n",
      "****************************\n",
      "Epoch: 2840\n",
      "train_loss = 87.5134\n",
      "test_loss = 75.4835\n",
      "****************************\n",
      "Epoch: 2841\n",
      "train_loss = 87.5629\n",
      "test_loss = 75.0707\n",
      "****************************\n",
      "Epoch: 2842\n",
      "train_loss = 87.6110\n",
      "test_loss = 75.0877\n",
      "****************************\n",
      "Epoch: 2843\n",
      "train_loss = 87.5765\n",
      "test_loss = 74.9892\n",
      "****************************\n",
      "Epoch: 2844\n",
      "train_loss = 87.7749\n",
      "test_loss = 74.6164\n",
      "****************************\n",
      "Epoch: 2845\n",
      "train_loss = 87.6768\n",
      "test_loss = 76.3629\n",
      "****************************\n",
      "Epoch: 2846\n",
      "train_loss = 87.6071\n",
      "test_loss = 74.8657\n",
      "****************************\n",
      "Epoch: 2847\n",
      "train_loss = 87.8586\n",
      "test_loss = 77.0844\n",
      "****************************\n",
      "Epoch: 2848\n",
      "train_loss = 87.4967\n",
      "test_loss = 75.6174\n",
      "****************************\n",
      "Epoch: 2849\n",
      "train_loss = 87.6097\n",
      "test_loss = 74.8702\n",
      "****************************\n",
      "Epoch: 2850\n",
      "train_loss = 87.5290\n",
      "test_loss = 75.3337\n",
      "****************************\n",
      "Epoch: 2851\n",
      "train_loss = 87.5306\n",
      "test_loss = 75.5898\n",
      "****************************\n",
      "Epoch: 2852\n",
      "train_loss = 87.7074\n",
      "test_loss = 76.6314\n",
      "****************************\n",
      "Epoch: 2853\n",
      "train_loss = 87.8586\n",
      "test_loss = 74.5067\n",
      "****************************\n",
      "Epoch: 2854\n",
      "train_loss = 87.5339\n",
      "test_loss = 75.6232\n",
      "****************************\n",
      "Epoch: 2855\n",
      "train_loss = 87.5177\n",
      "test_loss = 75.5244\n",
      "****************************\n",
      "Epoch: 2856\n",
      "train_loss = 87.5566\n",
      "test_loss = 75.2649\n",
      "****************************\n",
      "Epoch: 2857\n",
      "train_loss = 87.6520\n",
      "test_loss = 74.9661\n",
      "****************************\n",
      "Epoch: 2858\n",
      "train_loss = 87.6708\n",
      "test_loss = 74.7715\n",
      "****************************\n",
      "Epoch: 2859\n",
      "train_loss = 87.7353\n",
      "test_loss = 74.6165\n",
      "****************************\n",
      "Epoch: 2860\n",
      "train_loss = 87.6736\n",
      "test_loss = 74.7201\n",
      "****************************\n",
      "Epoch: 2861\n",
      "train_loss = 87.5954\n",
      "test_loss = 76.2400\n",
      "****************************\n",
      "Epoch: 2862\n",
      "train_loss = 87.7450\n",
      "test_loss = 74.5936\n",
      "****************************\n",
      "Epoch: 2863\n",
      "train_loss = 88.1522\n",
      "test_loss = 77.7993\n",
      "****************************\n",
      "Epoch: 2864\n",
      "train_loss = 87.7639\n",
      "test_loss = 74.6092\n",
      "****************************\n",
      "Epoch: 2865\n",
      "train_loss = 88.7474\n",
      "test_loss = 78.7817\n",
      "****************************\n",
      "Epoch: 2866\n",
      "train_loss = 87.5515\n",
      "test_loss = 75.7732\n",
      "****************************\n",
      "Epoch: 2867\n",
      "train_loss = 89.4875\n",
      "test_loss = 79.9833\n",
      "****************************\n",
      "Epoch: 2868\n",
      "train_loss = 87.5499\n",
      "test_loss = 75.7023\n",
      "****************************\n",
      "Epoch: 2869\n",
      "train_loss = 87.8611\n",
      "test_loss = 74.4674\n",
      "****************************\n",
      "Epoch: 2870\n",
      "train_loss = 89.2083\n",
      "test_loss = 79.5511\n",
      "****************************\n",
      "Epoch: 2871\n",
      "train_loss = 87.8568\n",
      "test_loss = 74.5632\n",
      "****************************\n",
      "Epoch: 2872\n",
      "train_loss = 87.6300\n",
      "test_loss = 74.9134\n",
      "****************************\n",
      "Epoch: 2873\n",
      "train_loss = 87.5286\n",
      "test_loss = 75.5720\n",
      "****************************\n",
      "Epoch: 2874\n",
      "train_loss = 87.5955\n",
      "test_loss = 74.8997\n",
      "****************************\n",
      "Epoch: 2875\n",
      "train_loss = 87.9303\n",
      "test_loss = 74.4400\n",
      "****************************\n",
      "Epoch: 2876\n",
      "train_loss = 87.6030\n",
      "test_loss = 76.2543\n",
      "****************************\n",
      "Epoch: 2877\n",
      "train_loss = 87.7510\n",
      "test_loss = 76.6036\n",
      "****************************\n",
      "Epoch: 2878\n",
      "train_loss = 87.5591\n",
      "test_loss = 74.9430\n",
      "****************************\n",
      "Epoch: 2879\n",
      "train_loss = 87.5307\n",
      "test_loss = 75.9331\n",
      "****************************\n",
      "Epoch: 2880\n",
      "train_loss = 87.8268\n",
      "test_loss = 77.0733\n",
      "****************************\n",
      "Epoch: 2881\n",
      "train_loss = 87.9796\n",
      "test_loss = 74.3668\n",
      "****************************\n",
      "Epoch: 2882\n",
      "train_loss = 87.7756\n",
      "test_loss = 76.7811\n",
      "****************************\n",
      "Epoch: 2883\n",
      "train_loss = 87.5513\n",
      "test_loss = 74.9494\n",
      "****************************\n",
      "Epoch: 2884\n",
      "train_loss = 87.7907\n",
      "test_loss = 74.4975\n",
      "****************************\n",
      "Epoch: 2885\n",
      "train_loss = 88.2501\n",
      "test_loss = 74.5175\n",
      "****************************\n",
      "Epoch: 2886\n",
      "train_loss = 89.0841\n",
      "test_loss = 79.2454\n",
      "****************************\n",
      "Epoch: 2887\n",
      "train_loss = 87.6166\n",
      "test_loss = 74.8778\n",
      "****************************\n",
      "Epoch: 2888\n",
      "train_loss = 89.7998\n",
      "test_loss = 80.7062\n",
      "****************************\n",
      "Epoch: 2889\n",
      "train_loss = 87.5644\n",
      "test_loss = 75.7779\n",
      "****************************\n",
      "Epoch: 2890\n",
      "train_loss = 87.5771\n",
      "test_loss = 74.9425\n",
      "****************************\n",
      "Epoch: 2891\n",
      "train_loss = 87.7703\n",
      "test_loss = 76.8242\n",
      "****************************\n",
      "Epoch: 2892\n",
      "train_loss = 87.4946\n",
      "test_loss = 75.6508\n",
      "****************************\n",
      "Epoch: 2893\n",
      "train_loss = 87.5906\n",
      "test_loss = 76.2132\n",
      "****************************\n",
      "Epoch: 2894\n",
      "train_loss = 87.5997\n",
      "test_loss = 74.8842\n",
      "****************************\n",
      "Epoch: 2895\n",
      "train_loss = 87.7989\n",
      "test_loss = 74.5538\n",
      "****************************\n",
      "Epoch: 2896\n",
      "train_loss = 89.1426\n",
      "test_loss = 79.3999\n",
      "****************************\n",
      "Epoch: 2897\n",
      "train_loss = 87.6533\n",
      "test_loss = 76.3603\n",
      "****************************\n",
      "Epoch: 2898\n",
      "train_loss = 89.9843\n",
      "test_loss = 80.9284\n",
      "****************************\n",
      "Epoch: 2899\n",
      "train_loss = 87.7192\n",
      "test_loss = 74.6753\n",
      "****************************\n",
      "Epoch: 2900\n",
      "train_loss = 87.6180\n",
      "test_loss = 74.8449\n",
      "****************************\n",
      "Epoch: 2901\n",
      "train_loss = 87.6008\n",
      "test_loss = 76.2042\n",
      "****************************\n",
      "Epoch: 2902\n",
      "train_loss = 87.5333\n",
      "test_loss = 75.1960\n",
      "****************************\n",
      "Epoch: 2903\n",
      "train_loss = 87.7394\n",
      "test_loss = 76.5490\n",
      "****************************\n",
      "Epoch: 2904\n",
      "train_loss = 87.5929\n",
      "test_loss = 75.6336\n",
      "****************************\n",
      "Epoch: 2905\n",
      "train_loss = 87.5212\n",
      "test_loss = 75.4125\n",
      "****************************\n",
      "Epoch: 2906\n",
      "train_loss = 87.5379\n",
      "test_loss = 75.3587\n",
      "****************************\n",
      "Epoch: 2907\n",
      "train_loss = 87.6648\n",
      "test_loss = 74.6791\n",
      "****************************\n",
      "Epoch: 2908\n",
      "train_loss = 87.8204\n",
      "test_loss = 76.6741\n",
      "****************************\n",
      "Epoch: 2909\n",
      "train_loss = 87.5777\n",
      "test_loss = 74.9632\n",
      "****************************\n",
      "Epoch: 2910\n",
      "train_loss = 87.6784\n",
      "test_loss = 74.6917\n",
      "****************************\n",
      "Epoch: 2911\n",
      "train_loss = 90.2813\n",
      "test_loss = 81.1109\n",
      "****************************\n",
      "Epoch: 2912\n",
      "train_loss = 87.5363\n",
      "test_loss = 75.2524\n",
      "****************************\n",
      "Epoch: 2913\n",
      "train_loss = 87.6067\n",
      "test_loss = 75.6718\n",
      "****************************\n",
      "Epoch: 2914\n",
      "train_loss = 88.0088\n",
      "test_loss = 77.3376\n",
      "****************************\n",
      "Epoch: 2915\n",
      "train_loss = 87.5277\n",
      "test_loss = 75.2811\n",
      "****************************\n",
      "Epoch: 2916\n",
      "train_loss = 87.7821\n",
      "test_loss = 74.5183\n",
      "****************************\n",
      "Epoch: 2917\n",
      "train_loss = 87.7842\n",
      "test_loss = 74.5110\n",
      "****************************\n",
      "Epoch: 2918\n",
      "train_loss = 87.5481\n",
      "test_loss = 75.7872\n",
      "****************************\n",
      "Epoch: 2919\n",
      "train_loss = 87.6459\n",
      "test_loss = 74.6699\n",
      "****************************\n",
      "Epoch: 2920\n",
      "train_loss = 87.5421\n",
      "test_loss = 74.9122\n",
      "****************************\n",
      "Epoch: 2921\n",
      "train_loss = 88.6330\n",
      "test_loss = 78.3912\n",
      "****************************\n",
      "Epoch: 2922\n",
      "train_loss = 87.8043\n",
      "test_loss = 76.8596\n",
      "****************************\n",
      "Epoch: 2923\n",
      "train_loss = 87.5271\n",
      "test_loss = 75.8698\n",
      "****************************\n",
      "Epoch: 2924\n",
      "train_loss = 88.0323\n",
      "test_loss = 77.4404\n",
      "****************************\n",
      "Epoch: 2925\n",
      "train_loss = 89.4333\n",
      "test_loss = 80.0954\n",
      "****************************\n",
      "Epoch: 2926\n",
      "train_loss = 87.4990\n",
      "test_loss = 75.4045\n",
      "****************************\n",
      "Epoch: 2927\n",
      "train_loss = 87.4841\n",
      "test_loss = 75.4847\n",
      "****************************\n",
      "Epoch: 2928\n",
      "train_loss = 87.5126\n",
      "test_loss = 75.7930\n",
      "****************************\n",
      "Epoch: 2929\n",
      "train_loss = 87.8708\n",
      "test_loss = 74.4273\n",
      "****************************\n",
      "Epoch: 2930\n",
      "train_loss = 87.9012\n",
      "test_loss = 77.2165\n",
      "****************************\n",
      "Epoch: 2931\n",
      "train_loss = 87.5476\n",
      "test_loss = 74.9718\n",
      "****************************\n",
      "Epoch: 2932\n",
      "train_loss = 88.3750\n",
      "test_loss = 78.3097\n",
      "****************************\n",
      "Epoch: 2933\n",
      "train_loss = 87.6457\n",
      "test_loss = 76.3647\n",
      "****************************\n",
      "Epoch: 2934\n",
      "train_loss = 87.5759\n",
      "test_loss = 74.8868\n",
      "****************************\n",
      "Epoch: 2935\n",
      "train_loss = 87.9209\n",
      "test_loss = 74.3944\n",
      "****************************\n",
      "Epoch: 2936\n",
      "train_loss = 87.5022\n",
      "test_loss = 75.3209\n",
      "****************************\n",
      "Epoch: 2937\n",
      "train_loss = 87.5758\n",
      "test_loss = 74.8873\n",
      "****************************\n",
      "Epoch: 2938\n",
      "train_loss = 88.1653\n",
      "test_loss = 77.7582\n",
      "****************************\n",
      "Epoch: 2939\n",
      "train_loss = 87.5176\n",
      "test_loss = 75.0390\n",
      "****************************\n",
      "Epoch: 2940\n",
      "train_loss = 87.8153\n",
      "test_loss = 74.4833\n",
      "****************************\n",
      "Epoch: 2941\n",
      "train_loss = 87.8320\n",
      "test_loss = 77.0516\n",
      "****************************\n",
      "Epoch: 2942\n",
      "train_loss = 87.9675\n",
      "test_loss = 74.3679\n",
      "****************************\n",
      "Epoch: 2943\n",
      "train_loss = 88.4382\n",
      "test_loss = 78.2343\n",
      "****************************\n",
      "Epoch: 2944\n",
      "train_loss = 87.7359\n",
      "test_loss = 76.5927\n",
      "****************************\n",
      "Epoch: 2945\n",
      "train_loss = 87.6844\n",
      "test_loss = 74.7157\n",
      "****************************\n",
      "Epoch: 2946\n",
      "train_loss = 87.7328\n",
      "test_loss = 76.5633\n",
      "****************************\n",
      "Epoch: 2947\n",
      "train_loss = 87.7309\n",
      "test_loss = 74.6448\n",
      "****************************\n",
      "Epoch: 2948\n",
      "train_loss = 88.2357\n",
      "test_loss = 77.8439\n",
      "****************************\n",
      "Epoch: 2949\n",
      "train_loss = 87.5113\n",
      "test_loss = 75.8083\n",
      "****************************\n",
      "Epoch: 2950\n",
      "train_loss = 87.6053\n",
      "test_loss = 74.8784\n",
      "****************************\n",
      "Epoch: 2951\n",
      "train_loss = 87.8309\n",
      "test_loss = 74.5337\n",
      "****************************\n",
      "Epoch: 2952\n",
      "train_loss = 88.2549\n",
      "test_loss = 74.2773\n",
      "****************************\n",
      "Epoch: 2953\n",
      "train_loss = 87.5755\n",
      "test_loss = 74.9405\n",
      "****************************\n",
      "Epoch: 2954\n",
      "train_loss = 87.5273\n",
      "test_loss = 75.1362\n",
      "****************************\n",
      "Epoch: 2955\n",
      "train_loss = 87.8801\n",
      "test_loss = 74.4825\n",
      "****************************\n",
      "Epoch: 2956\n",
      "train_loss = 87.5133\n",
      "test_loss = 75.2652\n",
      "****************************\n",
      "Epoch: 2957\n",
      "train_loss = 88.0326\n",
      "test_loss = 74.3776\n",
      "****************************\n",
      "Epoch: 2958\n",
      "train_loss = 87.5895\n",
      "test_loss = 75.2954\n",
      "****************************\n",
      "Epoch: 2959\n",
      "train_loss = 87.5848\n",
      "test_loss = 75.7452\n",
      "****************************\n",
      "Epoch: 2960\n",
      "train_loss = 87.5563\n",
      "test_loss = 75.7113\n",
      "****************************\n",
      "Epoch: 2961\n",
      "train_loss = 87.5945\n",
      "test_loss = 75.8707\n",
      "****************************\n",
      "Epoch: 2962\n",
      "train_loss = 87.5607\n",
      "test_loss = 75.0077\n",
      "****************************\n",
      "Epoch: 2963\n",
      "train_loss = 88.4180\n",
      "test_loss = 78.2652\n",
      "****************************\n",
      "Epoch: 2964\n",
      "train_loss = 87.5067\n",
      "test_loss = 75.5531\n",
      "****************************\n",
      "Epoch: 2965\n",
      "train_loss = 87.5048\n",
      "test_loss = 75.4196\n",
      "****************************\n",
      "Epoch: 2966\n",
      "train_loss = 87.5988\n",
      "test_loss = 76.0427\n",
      "****************************\n",
      "Epoch: 2967\n",
      "train_loss = 87.6179\n",
      "test_loss = 74.8000\n",
      "****************************\n",
      "Epoch: 2968\n",
      "train_loss = 87.5210\n",
      "test_loss = 75.8817\n",
      "****************************\n",
      "Epoch: 2969\n",
      "train_loss = 87.6040\n",
      "test_loss = 74.8132\n",
      "****************************\n",
      "Epoch: 2970\n",
      "train_loss = 88.0533\n",
      "test_loss = 74.3268\n",
      "****************************\n",
      "Epoch: 2971\n",
      "train_loss = 87.5427\n",
      "test_loss = 74.9617\n",
      "****************************\n",
      "Epoch: 2972\n",
      "train_loss = 87.5046\n",
      "test_loss = 75.4889\n",
      "****************************\n",
      "Epoch: 2973\n",
      "train_loss = 87.5113\n",
      "test_loss = 75.9670\n",
      "****************************\n",
      "Epoch: 2974\n",
      "train_loss = 87.5604\n",
      "test_loss = 76.1527\n",
      "****************************\n",
      "Epoch: 2975\n",
      "train_loss = 87.4754\n",
      "test_loss = 75.4126\n",
      "****************************\n",
      "Epoch: 2976\n",
      "train_loss = 87.5526\n",
      "test_loss = 76.0044\n",
      "****************************\n",
      "Epoch: 2977\n",
      "train_loss = 87.5536\n",
      "test_loss = 76.0942\n",
      "****************************\n",
      "Epoch: 2978\n",
      "train_loss = 87.8111\n",
      "test_loss = 74.4666\n",
      "****************************\n",
      "Epoch: 2979\n",
      "train_loss = 87.4982\n",
      "test_loss = 75.8109\n",
      "****************************\n",
      "Epoch: 2980\n",
      "train_loss = 87.4908\n",
      "test_loss = 75.1728\n",
      "****************************\n",
      "Epoch: 2981\n",
      "train_loss = 87.6094\n",
      "test_loss = 74.8362\n",
      "****************************\n",
      "Epoch: 2982\n",
      "train_loss = 88.4369\n",
      "test_loss = 78.3650\n",
      "****************************\n",
      "Epoch: 2983\n",
      "train_loss = 87.5812\n",
      "test_loss = 74.8019\n",
      "****************************\n",
      "Epoch: 2984\n",
      "train_loss = 89.5116\n",
      "test_loss = 80.3447\n",
      "****************************\n",
      "Epoch: 2985\n",
      "train_loss = 88.1103\n",
      "test_loss = 77.5163\n",
      "****************************\n",
      "Epoch: 2986\n",
      "train_loss = 87.7052\n",
      "test_loss = 74.6804\n",
      "****************************\n",
      "Epoch: 2987\n",
      "train_loss = 87.6499\n",
      "test_loss = 74.7275\n",
      "****************************\n",
      "Epoch: 2988\n",
      "train_loss = 87.9028\n",
      "test_loss = 74.4612\n",
      "****************************\n",
      "Epoch: 2989\n",
      "train_loss = 87.4963\n",
      "test_loss = 75.3565\n",
      "****************************\n",
      "Epoch: 2990\n",
      "train_loss = 87.5763\n",
      "test_loss = 74.8470\n",
      "****************************\n",
      "Epoch: 2991\n",
      "train_loss = 87.7174\n",
      "test_loss = 74.6073\n",
      "****************************\n",
      "Epoch: 2992\n",
      "train_loss = 87.5839\n",
      "test_loss = 74.7624\n",
      "****************************\n",
      "Epoch: 2993\n",
      "train_loss = 87.5909\n",
      "test_loss = 76.1552\n",
      "****************************\n",
      "Epoch: 2994\n",
      "train_loss = 87.5357\n",
      "test_loss = 74.9398\n",
      "****************************\n",
      "Epoch: 2995\n",
      "train_loss = 87.5630\n",
      "test_loss = 74.9004\n",
      "****************************\n",
      "Epoch: 2996\n",
      "train_loss = 87.5190\n",
      "test_loss = 75.7898\n",
      "****************************\n",
      "Epoch: 2997\n",
      "train_loss = 87.6321\n",
      "test_loss = 74.8511\n",
      "****************************\n",
      "Epoch: 2998\n",
      "train_loss = 87.8441\n",
      "test_loss = 76.9452\n",
      "****************************\n",
      "Epoch: 2999\n",
      "train_loss = 87.5820\n",
      "test_loss = 76.1052\n",
      "****************************\n",
      "Epoch: 3000\n",
      "train_loss = 87.6404\n",
      "test_loss = 74.7466\n",
      "****************************\n",
      "Epoch: 3001\n",
      "train_loss = 87.5696\n",
      "test_loss = 74.8897\n",
      "****************************\n",
      "Epoch: 3002\n",
      "train_loss = 89.5356\n",
      "test_loss = 74.3703\n",
      "****************************\n",
      "Epoch: 3003\n",
      "train_loss = 87.6631\n",
      "test_loss = 76.3667\n",
      "****************************\n",
      "Epoch: 3004\n",
      "train_loss = 87.5561\n",
      "test_loss = 74.9508\n",
      "****************************\n",
      "Epoch: 3005\n",
      "train_loss = 87.4771\n",
      "test_loss = 75.6739\n",
      "****************************\n",
      "Epoch: 3006\n",
      "train_loss = 87.9529\n",
      "test_loss = 77.4159\n",
      "****************************\n",
      "Epoch: 3007\n",
      "train_loss = 87.5379\n",
      "test_loss = 76.1612\n",
      "****************************\n",
      "Epoch: 3008\n",
      "train_loss = 87.4778\n",
      "test_loss = 75.3290\n",
      "****************************\n",
      "Epoch: 3009\n",
      "train_loss = 87.4847\n",
      "test_loss = 75.2069\n",
      "****************************\n",
      "Epoch: 3010\n",
      "train_loss = 87.4914\n",
      "test_loss = 75.5659\n",
      "****************************\n",
      "Epoch: 3011\n",
      "train_loss = 87.7688\n",
      "test_loss = 74.5393\n",
      "****************************\n",
      "Epoch: 3012\n",
      "train_loss = 87.5870\n",
      "test_loss = 76.3557\n",
      "****************************\n",
      "Epoch: 3013\n",
      "train_loss = 87.9371\n",
      "test_loss = 74.3926\n",
      "****************************\n",
      "Epoch: 3014\n",
      "train_loss = 87.6027\n",
      "test_loss = 76.2650\n",
      "****************************\n",
      "Epoch: 3015\n",
      "train_loss = 87.5909\n",
      "test_loss = 74.7925\n",
      "****************************\n",
      "Epoch: 3016\n",
      "train_loss = 87.4717\n",
      "test_loss = 75.3508\n",
      "****************************\n",
      "Epoch: 3017\n",
      "train_loss = 87.5085\n",
      "test_loss = 75.0902\n",
      "****************************\n",
      "Epoch: 3018\n",
      "train_loss = 87.5135\n",
      "test_loss = 74.9343\n",
      "****************************\n",
      "Epoch: 3019\n",
      "train_loss = 88.1765\n",
      "test_loss = 74.2267\n",
      "****************************\n",
      "Epoch: 3020\n",
      "train_loss = 88.1274\n",
      "test_loss = 77.7894\n",
      "****************************\n",
      "Epoch: 3021\n",
      "train_loss = 88.2081\n",
      "test_loss = 74.7944\n",
      "****************************\n",
      "Epoch: 3022\n",
      "train_loss = 87.5605\n",
      "test_loss = 75.4423\n",
      "****************************\n",
      "Epoch: 3023\n",
      "train_loss = 87.7436\n",
      "test_loss = 74.6409\n",
      "****************************\n",
      "Epoch: 3024\n",
      "train_loss = 87.5700\n",
      "test_loss = 74.9099\n",
      "****************************\n",
      "Epoch: 3025\n",
      "train_loss = 87.5647\n",
      "test_loss = 75.7460\n",
      "****************************\n",
      "Epoch: 3026\n",
      "train_loss = 87.5732\n",
      "test_loss = 74.8909\n",
      "****************************\n",
      "Epoch: 3027\n",
      "train_loss = 87.4825\n",
      "test_loss = 75.3836\n",
      "****************************\n",
      "Epoch: 3028\n",
      "train_loss = 87.5014\n",
      "test_loss = 75.4294\n",
      "****************************\n",
      "Epoch: 3029\n",
      "train_loss = 87.4768\n",
      "test_loss = 75.3821\n",
      "****************************\n",
      "Epoch: 3030\n",
      "train_loss = 87.8316\n",
      "test_loss = 76.9966\n",
      "****************************\n",
      "Epoch: 3031\n",
      "train_loss = 87.4926\n",
      "test_loss = 75.7439\n",
      "****************************\n",
      "Epoch: 3032\n",
      "train_loss = 87.5326\n",
      "test_loss = 75.0175\n",
      "****************************\n",
      "Epoch: 3033\n",
      "train_loss = 87.5776\n",
      "test_loss = 74.8442\n",
      "****************************\n",
      "Epoch: 3034\n",
      "train_loss = 87.6657\n",
      "test_loss = 76.5430\n",
      "****************************\n",
      "Epoch: 3035\n",
      "train_loss = 87.5401\n",
      "test_loss = 76.1259\n",
      "****************************\n",
      "Epoch: 3036\n",
      "train_loss = 88.2377\n",
      "test_loss = 74.2296\n",
      "****************************\n",
      "Epoch: 3037\n",
      "train_loss = 87.4916\n",
      "test_loss = 75.1837\n",
      "****************************\n",
      "Epoch: 3038\n",
      "train_loss = 87.7159\n",
      "test_loss = 74.5639\n",
      "****************************\n",
      "Epoch: 3039\n",
      "train_loss = 88.6243\n",
      "test_loss = 78.6673\n",
      "****************************\n",
      "Epoch: 3040\n",
      "train_loss = 88.2019\n",
      "test_loss = 74.2854\n",
      "****************************\n",
      "Epoch: 3041\n",
      "train_loss = 88.6115\n",
      "test_loss = 78.7841\n",
      "****************************\n",
      "Epoch: 3042\n",
      "train_loss = 87.4624\n",
      "test_loss = 75.4742\n",
      "****************************\n",
      "Epoch: 3043\n",
      "train_loss = 87.6631\n",
      "test_loss = 74.6838\n",
      "****************************\n",
      "Epoch: 3044\n",
      "train_loss = 87.8656\n",
      "test_loss = 74.4016\n",
      "****************************\n",
      "Epoch: 3045\n",
      "train_loss = 87.8805\n",
      "test_loss = 74.3970\n",
      "****************************\n",
      "Epoch: 3046\n",
      "train_loss = 87.7270\n",
      "test_loss = 76.7750\n",
      "****************************\n",
      "Epoch: 3047\n",
      "train_loss = 87.4767\n",
      "test_loss = 75.3781\n",
      "****************************\n",
      "Epoch: 3048\n",
      "train_loss = 87.5484\n",
      "test_loss = 74.8756\n",
      "****************************\n",
      "Epoch: 3049\n",
      "train_loss = 87.8842\n",
      "test_loss = 77.2540\n",
      "****************************\n",
      "Epoch: 3050\n",
      "train_loss = 89.1004\n",
      "test_loss = 79.6607\n",
      "****************************\n",
      "Epoch: 3051\n",
      "train_loss = 90.8755\n",
      "test_loss = 82.5045\n",
      "****************************\n",
      "Epoch: 3052\n",
      "train_loss = 87.6594\n",
      "test_loss = 76.6171\n",
      "****************************\n",
      "Epoch: 3053\n",
      "train_loss = 88.3804\n",
      "test_loss = 78.3722\n",
      "****************************\n",
      "Epoch: 3054\n",
      "train_loss = 87.5262\n",
      "test_loss = 75.1492\n",
      "****************************\n",
      "Epoch: 3055\n",
      "train_loss = 87.4867\n",
      "test_loss = 75.3571\n",
      "****************************\n",
      "Epoch: 3056\n",
      "train_loss = 87.5276\n",
      "test_loss = 75.1948\n",
      "****************************\n",
      "Epoch: 3057\n",
      "train_loss = 89.0839\n",
      "test_loss = 74.4340\n",
      "****************************\n",
      "Epoch: 3058\n",
      "train_loss = 87.5768\n",
      "test_loss = 75.7670\n",
      "****************************\n",
      "Epoch: 3059\n",
      "train_loss = 87.7175\n",
      "test_loss = 74.8063\n",
      "****************************\n",
      "Epoch: 3060\n",
      "train_loss = 88.8954\n",
      "test_loss = 78.7684\n",
      "****************************\n",
      "Epoch: 3061\n",
      "train_loss = 87.6539\n",
      "test_loss = 74.9543\n",
      "****************************\n",
      "Epoch: 3062\n",
      "train_loss = 87.7585\n",
      "test_loss = 74.7499\n",
      "****************************\n",
      "Epoch: 3063\n",
      "train_loss = 87.5527\n",
      "test_loss = 75.9204\n",
      "****************************\n",
      "Epoch: 3064\n",
      "train_loss = 87.5692\n",
      "test_loss = 75.2406\n",
      "****************************\n",
      "Epoch: 3065\n",
      "train_loss = 87.7032\n",
      "test_loss = 76.5240\n",
      "****************************\n",
      "Epoch: 3066\n",
      "train_loss = 87.5913\n",
      "test_loss = 75.1300\n",
      "****************************\n",
      "Epoch: 3067\n",
      "train_loss = 87.9764\n",
      "test_loss = 74.4557\n",
      "****************************\n",
      "Epoch: 3068\n",
      "train_loss = 87.8555\n",
      "test_loss = 74.5552\n",
      "****************************\n",
      "Epoch: 3069\n",
      "train_loss = 88.8138\n",
      "test_loss = 78.9218\n",
      "****************************\n",
      "Epoch: 3070\n",
      "train_loss = 87.7042\n",
      "test_loss = 74.7968\n",
      "****************************\n",
      "Epoch: 3071\n",
      "train_loss = 87.5513\n",
      "test_loss = 75.2717\n",
      "****************************\n",
      "Epoch: 3072\n",
      "train_loss = 87.5672\n",
      "test_loss = 75.8274\n",
      "****************************\n",
      "Epoch: 3073\n",
      "train_loss = 87.6514\n",
      "test_loss = 74.8605\n",
      "****************************\n",
      "Epoch: 3074\n",
      "train_loss = 88.1597\n",
      "test_loss = 74.3279\n",
      "****************************\n",
      "Epoch: 3075\n",
      "train_loss = 87.7730\n",
      "test_loss = 76.8510\n",
      "****************************\n",
      "Epoch: 3076\n",
      "train_loss = 88.3757\n",
      "test_loss = 74.2574\n",
      "****************************\n",
      "Epoch: 3077\n",
      "train_loss = 87.5361\n",
      "test_loss = 75.7314\n",
      "****************************\n",
      "Epoch: 3078\n",
      "train_loss = 87.4907\n",
      "test_loss = 75.5688\n",
      "****************************\n",
      "Epoch: 3079\n",
      "train_loss = 87.7990\n",
      "test_loss = 76.8746\n",
      "****************************\n",
      "Epoch: 3080\n",
      "train_loss = 87.7613\n",
      "test_loss = 76.9206\n",
      "****************************\n",
      "Epoch: 3081\n",
      "train_loss = 87.6771\n",
      "test_loss = 74.8186\n",
      "****************************\n",
      "Epoch: 3082\n",
      "train_loss = 88.1481\n",
      "test_loss = 77.7511\n",
      "****************************\n",
      "Epoch: 3083\n",
      "train_loss = 87.6570\n",
      "test_loss = 76.5491\n",
      "****************************\n",
      "Epoch: 3084\n",
      "train_loss = 87.8503\n",
      "test_loss = 76.9108\n",
      "****************************\n",
      "Epoch: 3085\n",
      "train_loss = 87.7572\n",
      "test_loss = 74.6914\n",
      "****************************\n",
      "Epoch: 3086\n",
      "train_loss = 87.6678\n",
      "test_loss = 76.3311\n",
      "****************************\n",
      "Epoch: 3087\n",
      "train_loss = 87.7956\n",
      "test_loss = 74.5768\n",
      "****************************\n",
      "Epoch: 3088\n",
      "train_loss = 87.5238\n",
      "test_loss = 75.7483\n",
      "****************************\n",
      "Epoch: 3089\n",
      "train_loss = 87.5382\n",
      "test_loss = 75.9092\n",
      "****************************\n",
      "Epoch: 3090\n",
      "train_loss = 87.7172\n",
      "test_loss = 76.4919\n",
      "****************************\n",
      "Epoch: 3091\n",
      "train_loss = 87.7009\n",
      "test_loss = 74.7228\n",
      "****************************\n",
      "Epoch: 3092\n",
      "train_loss = 87.6352\n",
      "test_loss = 76.0296\n",
      "****************************\n",
      "Epoch: 3093\n",
      "train_loss = 87.6741\n",
      "test_loss = 76.1511\n",
      "****************************\n",
      "Epoch: 3094\n",
      "train_loss = 87.6789\n",
      "test_loss = 76.3574\n",
      "****************************\n",
      "Epoch: 3095\n",
      "train_loss = 90.7067\n",
      "test_loss = 82.2042\n",
      "****************************\n",
      "Epoch: 3096\n",
      "train_loss = 87.9179\n",
      "test_loss = 74.4826\n",
      "****************************\n",
      "Epoch: 3097\n",
      "train_loss = 87.5626\n",
      "test_loss = 75.8782\n",
      "****************************\n",
      "Epoch: 3098\n",
      "train_loss = 87.5152\n",
      "test_loss = 75.4793\n",
      "****************************\n",
      "Epoch: 3099\n",
      "train_loss = 87.7226\n",
      "test_loss = 76.4643\n",
      "****************************\n",
      "Epoch: 3100\n",
      "train_loss = 87.5521\n",
      "test_loss = 75.7552\n",
      "****************************\n",
      "Epoch: 3101\n",
      "train_loss = 87.9221\n",
      "test_loss = 74.6229\n",
      "****************************\n",
      "Epoch: 3102\n",
      "train_loss = 87.5312\n",
      "test_loss = 75.1875\n",
      "****************************\n",
      "Epoch: 3103\n",
      "train_loss = 87.5882\n",
      "test_loss = 76.0360\n",
      "****************************\n",
      "Epoch: 3104\n",
      "train_loss = 87.5272\n",
      "test_loss = 75.2164\n",
      "****************************\n",
      "Epoch: 3105\n",
      "train_loss = 87.5731\n",
      "test_loss = 75.5090\n",
      "****************************\n",
      "Epoch: 3106\n",
      "train_loss = 87.8055\n",
      "test_loss = 76.8451\n",
      "****************************\n",
      "Epoch: 3107\n",
      "train_loss = 87.5532\n",
      "test_loss = 75.6494\n",
      "****************************\n",
      "Epoch: 3108\n",
      "train_loss = 87.9501\n",
      "test_loss = 74.4164\n",
      "****************************\n",
      "Epoch: 3109\n",
      "train_loss = 87.5620\n",
      "test_loss = 74.9942\n",
      "****************************\n",
      "Epoch: 3110\n",
      "train_loss = 87.5591\n",
      "test_loss = 75.5299\n",
      "****************************\n",
      "Epoch: 3111\n",
      "train_loss = 87.5215\n",
      "test_loss = 75.4289\n",
      "****************************\n",
      "Epoch: 3112\n",
      "train_loss = 87.7338\n",
      "test_loss = 76.7234\n",
      "****************************\n",
      "Epoch: 3113\n",
      "train_loss = 87.6926\n",
      "test_loss = 74.7417\n",
      "****************************\n",
      "Epoch: 3114\n",
      "train_loss = 87.4904\n",
      "test_loss = 75.4875\n",
      "****************************\n",
      "Epoch: 3115\n",
      "train_loss = 87.5522\n",
      "test_loss = 74.9945\n",
      "****************************\n",
      "Epoch: 3116\n",
      "train_loss = 87.5755\n",
      "test_loss = 74.8586\n",
      "****************************\n",
      "Epoch: 3117\n",
      "train_loss = 87.4696\n",
      "test_loss = 75.5902\n",
      "****************************\n",
      "Epoch: 3118\n",
      "train_loss = 87.7077\n",
      "test_loss = 74.5951\n",
      "****************************\n",
      "Epoch: 3119\n",
      "train_loss = 87.5388\n",
      "test_loss = 75.9928\n",
      "****************************\n",
      "Epoch: 3120\n",
      "train_loss = 87.4801\n",
      "test_loss = 75.8305\n",
      "****************************\n",
      "Epoch: 3121\n",
      "train_loss = 87.5216\n",
      "test_loss = 76.0508\n",
      "****************************\n",
      "Epoch: 3122\n",
      "train_loss = 87.4675\n",
      "test_loss = 75.3490\n",
      "****************************\n",
      "Epoch: 3123\n",
      "train_loss = 87.6367\n",
      "test_loss = 76.4578\n",
      "****************************\n",
      "Epoch: 3124\n",
      "train_loss = 87.4814\n",
      "test_loss = 75.1974\n",
      "****************************\n",
      "Epoch: 3125\n",
      "train_loss = 87.4663\n",
      "test_loss = 75.6075\n",
      "****************************\n",
      "Epoch: 3126\n",
      "train_loss = 87.5622\n",
      "test_loss = 74.8092\n",
      "****************************\n",
      "Epoch: 3127\n",
      "train_loss = 87.4784\n",
      "test_loss = 75.2957\n",
      "****************************\n",
      "Epoch: 3128\n",
      "train_loss = 87.4905\n",
      "test_loss = 75.2304\n",
      "****************************\n",
      "Epoch: 3129\n",
      "train_loss = 87.5548\n",
      "test_loss = 74.8713\n",
      "****************************\n",
      "Epoch: 3130\n",
      "train_loss = 88.8341\n",
      "test_loss = 79.0553\n",
      "****************************\n",
      "Epoch: 3131\n",
      "train_loss = 87.7255\n",
      "test_loss = 74.6751\n",
      "****************************\n",
      "Epoch: 3132\n",
      "train_loss = 87.5026\n",
      "test_loss = 75.1820\n",
      "****************************\n",
      "Epoch: 3133\n",
      "train_loss = 87.5081\n",
      "test_loss = 75.5102\n",
      "****************************\n",
      "Epoch: 3134\n",
      "train_loss = 87.6257\n",
      "test_loss = 76.3673\n",
      "****************************\n",
      "Epoch: 3135\n",
      "train_loss = 87.5680\n",
      "test_loss = 74.9393\n",
      "****************************\n",
      "Epoch: 3136\n",
      "train_loss = 87.5728\n",
      "test_loss = 74.8733\n",
      "****************************\n",
      "Epoch: 3137\n",
      "train_loss = 87.4744\n",
      "test_loss = 75.4443\n",
      "****************************\n",
      "Epoch: 3138\n",
      "train_loss = 88.7062\n",
      "test_loss = 74.1356\n",
      "****************************\n",
      "Epoch: 3139\n",
      "train_loss = 87.5229\n",
      "test_loss = 75.7167\n",
      "****************************\n",
      "Epoch: 3140\n",
      "train_loss = 87.5669\n",
      "test_loss = 74.8847\n",
      "****************************\n",
      "Epoch: 3141\n",
      "train_loss = 87.5352\n",
      "test_loss = 75.9727\n",
      "****************************\n",
      "Epoch: 3142\n",
      "train_loss = 87.5343\n",
      "test_loss = 74.9084\n",
      "****************************\n",
      "Epoch: 3143\n",
      "train_loss = 88.1266\n",
      "test_loss = 77.8189\n",
      "****************************\n",
      "Epoch: 3144\n",
      "train_loss = 87.5207\n",
      "test_loss = 75.0516\n",
      "****************************\n",
      "Epoch: 3145\n",
      "train_loss = 87.5177\n",
      "test_loss = 75.1118\n",
      "****************************\n",
      "Epoch: 3146\n",
      "train_loss = 89.0947\n",
      "test_loss = 74.6099\n",
      "****************************\n",
      "Epoch: 3147\n",
      "train_loss = 87.7371\n",
      "test_loss = 76.0984\n",
      "****************************\n",
      "Epoch: 3148\n",
      "train_loss = 87.5786\n",
      "test_loss = 75.5283\n",
      "****************************\n",
      "Epoch: 3149\n",
      "train_loss = 87.5332\n",
      "test_loss = 75.4647\n",
      "****************************\n",
      "Epoch: 3150\n",
      "train_loss = 88.5333\n",
      "test_loss = 74.2249\n",
      "****************************\n",
      "Epoch: 3151\n",
      "train_loss = 87.7943\n",
      "test_loss = 74.5384\n",
      "****************************\n",
      "Epoch: 3152\n",
      "train_loss = 87.5868\n",
      "test_loss = 74.8664\n",
      "****************************\n",
      "Epoch: 3153\n",
      "train_loss = 87.4881\n",
      "test_loss = 75.2168\n",
      "****************************\n",
      "Epoch: 3154\n",
      "train_loss = 87.8548\n",
      "test_loss = 74.4645\n",
      "****************************\n",
      "Epoch: 3155\n",
      "train_loss = 88.7704\n",
      "test_loss = 74.1342\n",
      "****************************\n",
      "Epoch: 3156\n",
      "train_loss = 87.5212\n",
      "test_loss = 75.7213\n",
      "****************************\n",
      "Epoch: 3157\n",
      "train_loss = 87.5295\n",
      "test_loss = 75.2038\n",
      "****************************\n",
      "Epoch: 3158\n",
      "train_loss = 87.6717\n",
      "test_loss = 76.2969\n",
      "****************************\n",
      "Epoch: 3159\n",
      "train_loss = 87.5633\n",
      "test_loss = 75.1188\n",
      "****************************\n",
      "Epoch: 3160\n",
      "train_loss = 87.5646\n",
      "test_loss = 75.1716\n",
      "****************************\n",
      "Epoch: 3161\n",
      "train_loss = 87.6868\n",
      "test_loss = 76.4378\n",
      "****************************\n",
      "Epoch: 3162\n",
      "train_loss = 87.9865\n",
      "test_loss = 74.4235\n",
      "****************************\n",
      "Epoch: 3163\n",
      "train_loss = 88.7734\n",
      "test_loss = 79.0846\n",
      "****************************\n",
      "Epoch: 3164\n",
      "train_loss = 87.6132\n",
      "test_loss = 76.2190\n",
      "****************************\n",
      "Epoch: 3165\n",
      "train_loss = 88.1384\n",
      "test_loss = 74.2709\n",
      "****************************\n",
      "Epoch: 3166\n",
      "train_loss = 87.5433\n",
      "test_loss = 74.9313\n",
      "****************************\n",
      "Epoch: 3167\n",
      "train_loss = 87.5010\n",
      "test_loss = 75.2251\n",
      "****************************\n",
      "Epoch: 3168\n",
      "train_loss = 88.3951\n",
      "test_loss = 78.1832\n",
      "****************************\n",
      "Epoch: 3169\n",
      "train_loss = 87.7146\n",
      "test_loss = 76.5955\n",
      "****************************\n",
      "Epoch: 3170\n",
      "train_loss = 88.0989\n",
      "test_loss = 77.4093\n",
      "****************************\n",
      "Epoch: 3171\n",
      "train_loss = 87.7444\n",
      "test_loss = 75.1297\n",
      "****************************\n",
      "Epoch: 3172\n",
      "train_loss = 87.6239\n",
      "test_loss = 75.4069\n",
      "****************************\n",
      "Epoch: 3173\n",
      "train_loss = 87.9396\n",
      "test_loss = 77.0258\n",
      "****************************\n",
      "Epoch: 3174\n",
      "train_loss = 87.5458\n",
      "test_loss = 75.7166\n",
      "****************************\n",
      "Epoch: 3175\n",
      "train_loss = 88.4215\n",
      "test_loss = 74.2155\n",
      "****************************\n",
      "Epoch: 3176\n",
      "train_loss = 88.5111\n",
      "test_loss = 74.2100\n",
      "****************************\n",
      "Epoch: 3177\n",
      "train_loss = 87.5689\n",
      "test_loss = 75.8701\n",
      "****************************\n",
      "Epoch: 3178\n",
      "train_loss = 87.5569\n",
      "test_loss = 75.1028\n",
      "****************************\n",
      "Epoch: 3179\n",
      "train_loss = 87.7645\n",
      "test_loss = 74.5511\n",
      "****************************\n",
      "Epoch: 3180\n",
      "train_loss = 87.7018\n",
      "test_loss = 74.6099\n",
      "****************************\n",
      "Epoch: 3181\n",
      "train_loss = 87.6026\n",
      "test_loss = 76.1711\n",
      "****************************\n",
      "Epoch: 3182\n",
      "train_loss = 87.4727\n",
      "test_loss = 75.5107\n",
      "****************************\n",
      "Epoch: 3183\n",
      "train_loss = 87.6663\n",
      "test_loss = 74.7080\n",
      "****************************\n",
      "Epoch: 3184\n",
      "train_loss = 89.0677\n",
      "test_loss = 79.5608\n",
      "****************************\n",
      "Epoch: 3185\n",
      "train_loss = 87.5214\n",
      "test_loss = 75.9409\n",
      "****************************\n",
      "Epoch: 3186\n",
      "train_loss = 87.5349\n",
      "test_loss = 76.1433\n",
      "****************************\n",
      "Epoch: 3187\n",
      "train_loss = 87.5326\n",
      "test_loss = 76.0565\n",
      "****************************\n",
      "Epoch: 3188\n",
      "train_loss = 87.5996\n",
      "test_loss = 74.8539\n",
      "****************************\n",
      "Epoch: 3189\n",
      "train_loss = 87.4832\n",
      "test_loss = 75.7127\n",
      "****************************\n",
      "Epoch: 3190\n",
      "train_loss = 87.7479\n",
      "test_loss = 74.5942\n",
      "****************************\n",
      "Epoch: 3191\n",
      "train_loss = 87.5039\n",
      "test_loss = 75.1794\n",
      "****************************\n",
      "Epoch: 3192\n",
      "train_loss = 87.5088\n",
      "test_loss = 75.2063\n",
      "****************************\n",
      "Epoch: 3193\n",
      "train_loss = 87.5087\n",
      "test_loss = 75.1791\n",
      "****************************\n",
      "Epoch: 3194\n",
      "train_loss = 87.4928\n",
      "test_loss = 75.2922\n",
      "****************************\n",
      "Epoch: 3195\n",
      "train_loss = 87.7325\n",
      "test_loss = 76.7205\n",
      "****************************\n",
      "Epoch: 3196\n",
      "train_loss = 87.5192\n",
      "test_loss = 75.1329\n",
      "****************************\n",
      "Epoch: 3197\n",
      "train_loss = 87.5480\n",
      "test_loss = 76.2091\n",
      "****************************\n",
      "Epoch: 3198\n",
      "train_loss = 87.5271\n",
      "test_loss = 75.0256\n",
      "****************************\n",
      "Epoch: 3199\n",
      "train_loss = 87.5116\n",
      "test_loss = 75.9423\n",
      "****************************\n",
      "Epoch: 3200\n",
      "train_loss = 87.5099\n",
      "test_loss = 75.8351\n",
      "****************************\n",
      "Epoch: 3201\n",
      "train_loss = 87.6657\n",
      "test_loss = 76.4926\n",
      "****************************\n",
      "Epoch: 3202\n",
      "train_loss = 87.8501\n",
      "test_loss = 77.0880\n",
      "****************************\n",
      "Epoch: 3203\n",
      "train_loss = 87.5032\n",
      "test_loss = 75.5240\n",
      "****************************\n",
      "Epoch: 3204\n",
      "train_loss = 88.0960\n",
      "test_loss = 74.3102\n",
      "****************************\n",
      "Epoch: 3205\n",
      "train_loss = 87.7031\n",
      "test_loss = 76.5888\n",
      "****************************\n",
      "Epoch: 3206\n",
      "train_loss = 87.4914\n",
      "test_loss = 75.5942\n",
      "****************************\n",
      "Epoch: 3207\n",
      "train_loss = 87.5354\n",
      "test_loss = 75.8791\n",
      "****************************\n",
      "Epoch: 3208\n",
      "train_loss = 87.8075\n",
      "test_loss = 74.5646\n",
      "****************************\n",
      "Epoch: 3209\n",
      "train_loss = 87.5254\n",
      "test_loss = 75.4516\n",
      "****************************\n",
      "Epoch: 3210\n",
      "train_loss = 88.9335\n",
      "test_loss = 74.1738\n",
      "****************************\n",
      "Epoch: 3211\n",
      "train_loss = 87.5462\n",
      "test_loss = 75.0139\n",
      "****************************\n",
      "Epoch: 3212\n",
      "train_loss = 88.9241\n",
      "test_loss = 79.0727\n",
      "****************************\n",
      "Epoch: 3213\n",
      "train_loss = 87.6319\n",
      "test_loss = 74.8347\n",
      "****************************\n",
      "Epoch: 3214\n",
      "train_loss = 87.5162\n",
      "test_loss = 75.6030\n",
      "****************************\n",
      "Epoch: 3215\n",
      "train_loss = 87.6336\n",
      "test_loss = 74.8133\n",
      "****************************\n",
      "Epoch: 3216\n",
      "train_loss = 87.9048\n",
      "test_loss = 74.4654\n",
      "****************************\n",
      "Epoch: 3217\n",
      "train_loss = 87.7447\n",
      "test_loss = 76.8561\n",
      "****************************\n",
      "Epoch: 3218\n",
      "train_loss = 88.1382\n",
      "test_loss = 77.8407\n",
      "****************************\n",
      "Epoch: 3219\n",
      "train_loss = 87.9757\n",
      "test_loss = 77.4668\n",
      "****************************\n",
      "Epoch: 3220\n",
      "train_loss = 88.1476\n",
      "test_loss = 77.8305\n",
      "****************************\n",
      "Epoch: 3221\n",
      "train_loss = 87.4906\n",
      "test_loss = 75.5553\n",
      "****************************\n",
      "Epoch: 3222\n",
      "train_loss = 87.5240\n",
      "test_loss = 75.2214\n",
      "****************************\n",
      "Epoch: 3223\n",
      "train_loss = 87.6112\n",
      "test_loss = 74.7985\n",
      "****************************\n",
      "Epoch: 3224\n",
      "train_loss = 87.5558\n",
      "test_loss = 76.0813\n",
      "****************************\n",
      "Epoch: 3225\n",
      "train_loss = 88.3913\n",
      "test_loss = 78.2730\n",
      "****************************\n",
      "Epoch: 3226\n",
      "train_loss = 87.5061\n",
      "test_loss = 75.4449\n",
      "****************************\n",
      "Epoch: 3227\n",
      "train_loss = 87.6918\n",
      "test_loss = 76.4036\n",
      "****************************\n",
      "Epoch: 3228\n",
      "train_loss = 87.7099\n",
      "test_loss = 74.5540\n",
      "****************************\n",
      "Epoch: 3229\n",
      "train_loss = 87.6005\n",
      "test_loss = 74.8983\n",
      "****************************\n",
      "Epoch: 3230\n",
      "train_loss = 87.4932\n",
      "test_loss = 75.5072\n",
      "****************************\n",
      "Epoch: 3231\n",
      "train_loss = 87.9023\n",
      "test_loss = 77.1834\n",
      "****************************\n",
      "Epoch: 3232\n",
      "train_loss = 87.7680\n",
      "test_loss = 74.6083\n",
      "****************************\n",
      "Epoch: 3233\n",
      "train_loss = 87.5921\n",
      "test_loss = 74.9223\n",
      "****************************\n",
      "Epoch: 3234\n",
      "train_loss = 87.5463\n",
      "test_loss = 75.0104\n",
      "****************************\n",
      "Epoch: 3235\n",
      "train_loss = 87.6137\n",
      "test_loss = 74.8594\n",
      "****************************\n",
      "Epoch: 3236\n",
      "train_loss = 87.5408\n",
      "test_loss = 75.0901\n",
      "****************************\n",
      "Epoch: 3237\n",
      "train_loss = 87.8916\n",
      "test_loss = 77.0596\n",
      "****************************\n",
      "Epoch: 3238\n",
      "train_loss = 87.5333\n",
      "test_loss = 75.0894\n",
      "****************************\n",
      "Epoch: 3239\n",
      "train_loss = 87.7418\n",
      "test_loss = 74.6290\n",
      "****************************\n",
      "Epoch: 3240\n",
      "train_loss = 87.5273\n",
      "test_loss = 75.1193\n",
      "****************************\n",
      "Epoch: 3241\n",
      "train_loss = 88.1810\n",
      "test_loss = 74.3389\n",
      "****************************\n",
      "Epoch: 3242\n",
      "train_loss = 87.7892\n",
      "test_loss = 74.7655\n",
      "****************************\n",
      "Epoch: 3243\n",
      "train_loss = 87.5989\n",
      "test_loss = 75.0468\n",
      "****************************\n",
      "Epoch: 3244\n",
      "train_loss = 87.7606\n",
      "test_loss = 74.6858\n",
      "****************************\n",
      "Epoch: 3245\n",
      "train_loss = 87.6204\n",
      "test_loss = 76.1174\n",
      "****************************\n",
      "Epoch: 3246\n",
      "train_loss = 87.6571\n",
      "test_loss = 76.3026\n",
      "****************************\n",
      "Epoch: 3247\n",
      "train_loss = 87.5420\n",
      "test_loss = 75.2967\n",
      "****************************\n",
      "Epoch: 3248\n",
      "train_loss = 87.7982\n",
      "test_loss = 76.8359\n",
      "****************************\n",
      "Epoch: 3249\n",
      "train_loss = 87.6163\n",
      "test_loss = 74.8867\n",
      "****************************\n",
      "Epoch: 3250\n",
      "train_loss = 87.4979\n",
      "test_loss = 75.4737\n",
      "****************************\n",
      "Epoch: 3251\n",
      "train_loss = 87.5049\n",
      "test_loss = 75.1813\n",
      "****************************\n",
      "Epoch: 3252\n",
      "train_loss = 87.9865\n",
      "test_loss = 74.4105\n",
      "****************************\n",
      "Epoch: 3253\n",
      "train_loss = 87.9375\n",
      "test_loss = 77.2706\n",
      "****************************\n",
      "Epoch: 3254\n",
      "train_loss = 87.5090\n",
      "test_loss = 75.4390\n",
      "****************************\n",
      "Epoch: 3255\n",
      "train_loss = 87.5815\n",
      "test_loss = 75.0454\n",
      "****************************\n",
      "Epoch: 3256\n",
      "train_loss = 87.5336\n",
      "test_loss = 76.0051\n",
      "****************************\n",
      "Epoch: 3257\n",
      "train_loss = 87.5552\n",
      "test_loss = 76.0946\n",
      "****************************\n",
      "Epoch: 3258\n",
      "train_loss = 87.5789\n",
      "test_loss = 74.8244\n",
      "****************************\n",
      "Epoch: 3259\n",
      "train_loss = 87.6059\n",
      "test_loss = 74.7035\n",
      "****************************\n",
      "Epoch: 3260\n",
      "train_loss = 88.4868\n",
      "test_loss = 74.2031\n",
      "****************************\n",
      "Epoch: 3261\n",
      "train_loss = 88.7523\n",
      "test_loss = 74.1464\n",
      "****************************\n",
      "Epoch: 3262\n",
      "train_loss = 88.1299\n",
      "test_loss = 74.2712\n",
      "****************************\n",
      "Epoch: 3263\n",
      "train_loss = 87.5902\n",
      "test_loss = 76.1452\n",
      "****************************\n",
      "Epoch: 3264\n",
      "train_loss = 87.5769\n",
      "test_loss = 74.9050\n",
      "****************************\n",
      "Epoch: 3265\n",
      "train_loss = 87.5295\n",
      "test_loss = 75.8667\n",
      "****************************\n",
      "Epoch: 3266\n",
      "train_loss = 87.5078\n",
      "test_loss = 75.8138\n",
      "****************************\n",
      "Epoch: 3267\n",
      "train_loss = 87.6302\n",
      "test_loss = 76.5344\n",
      "****************************\n",
      "Epoch: 3268\n",
      "train_loss = 87.7235\n",
      "test_loss = 75.7480\n",
      "****************************\n",
      "Epoch: 3269\n",
      "train_loss = 87.5793\n",
      "test_loss = 75.1120\n",
      "****************************\n",
      "Epoch: 3270\n",
      "train_loss = 87.6339\n",
      "test_loss = 76.4749\n",
      "****************************\n",
      "Epoch: 3271\n",
      "train_loss = 87.7865\n",
      "test_loss = 76.9381\n",
      "****************************\n",
      "Epoch: 3272\n",
      "train_loss = 87.6768\n",
      "test_loss = 76.6573\n",
      "****************************\n",
      "Epoch: 3273\n",
      "train_loss = 87.8662\n",
      "test_loss = 77.2835\n",
      "****************************\n",
      "Epoch: 3274\n",
      "train_loss = 87.4669\n",
      "test_loss = 75.3531\n",
      "****************************\n",
      "Epoch: 3275\n",
      "train_loss = 87.4888\n",
      "test_loss = 75.8500\n",
      "****************************\n",
      "Epoch: 3276\n",
      "train_loss = 87.9972\n",
      "test_loss = 77.4919\n",
      "****************************\n",
      "Epoch: 3277\n",
      "train_loss = 87.5506\n",
      "test_loss = 76.0541\n",
      "****************************\n",
      "Epoch: 3278\n",
      "train_loss = 88.1999\n",
      "test_loss = 74.2186\n",
      "****************************\n",
      "Epoch: 3279\n",
      "train_loss = 87.7462\n",
      "test_loss = 76.6248\n",
      "****************************\n",
      "Epoch: 3280\n",
      "train_loss = 87.6573\n",
      "test_loss = 74.7942\n",
      "****************************\n",
      "Epoch: 3281\n",
      "train_loss = 87.5597\n",
      "test_loss = 74.8891\n",
      "****************************\n",
      "Epoch: 3282\n",
      "train_loss = 87.7011\n",
      "test_loss = 76.3599\n",
      "****************************\n",
      "Epoch: 3283\n",
      "train_loss = 87.6343\n",
      "test_loss = 75.9089\n",
      "****************************\n",
      "Epoch: 3284\n",
      "train_loss = 87.7376\n",
      "test_loss = 76.6369\n",
      "****************************\n",
      "Epoch: 3285\n",
      "train_loss = 87.5310\n",
      "test_loss = 75.1697\n",
      "****************************\n",
      "Epoch: 3286\n",
      "train_loss = 87.7831\n",
      "test_loss = 76.9857\n",
      "****************************\n",
      "Epoch: 3287\n",
      "train_loss = 87.6466\n",
      "test_loss = 76.4440\n",
      "****************************\n",
      "Epoch: 3288\n",
      "train_loss = 87.5080\n",
      "test_loss = 75.3769\n",
      "****************************\n",
      "Epoch: 3289\n",
      "train_loss = 87.5271\n",
      "test_loss = 75.0326\n",
      "****************************\n",
      "Epoch: 3290\n",
      "train_loss = 87.7717\n",
      "test_loss = 74.5730\n",
      "****************************\n",
      "Epoch: 3291\n",
      "train_loss = 87.5122\n",
      "test_loss = 75.0878\n",
      "****************************\n",
      "Epoch: 3292\n",
      "train_loss = 87.4873\n",
      "test_loss = 75.3220\n",
      "****************************\n",
      "Epoch: 3293\n",
      "train_loss = 87.6508\n",
      "test_loss = 76.5312\n",
      "****************************\n",
      "Epoch: 3294\n",
      "train_loss = 87.4924\n",
      "test_loss = 75.1841\n",
      "****************************\n",
      "Epoch: 3295\n",
      "train_loss = 88.1525\n",
      "test_loss = 74.2612\n",
      "****************************\n",
      "Epoch: 3296\n",
      "train_loss = 87.7794\n",
      "test_loss = 76.6591\n",
      "****************************\n",
      "Epoch: 3297\n",
      "train_loss = 87.4839\n",
      "test_loss = 75.3617\n",
      "****************************\n",
      "Epoch: 3298\n",
      "train_loss = 87.5228\n",
      "test_loss = 75.9021\n",
      "****************************\n",
      "Epoch: 3299\n",
      "train_loss = 87.5810\n",
      "test_loss = 76.2606\n",
      "****************************\n",
      "Epoch: 3300\n",
      "train_loss = 87.7322\n",
      "test_loss = 76.9607\n",
      "****************************\n",
      "Epoch: 3301\n",
      "train_loss = 87.5308\n",
      "test_loss = 76.2137\n",
      "****************************\n",
      "Epoch: 3302\n",
      "train_loss = 87.6406\n",
      "test_loss = 76.5795\n",
      "****************************\n",
      "Epoch: 3303\n",
      "train_loss = 88.5020\n",
      "test_loss = 74.1894\n",
      "****************************\n",
      "Epoch: 3304\n",
      "train_loss = 87.4666\n",
      "test_loss = 75.4875\n",
      "****************************\n",
      "Epoch: 3305\n",
      "train_loss = 87.5113\n",
      "test_loss = 76.0322\n",
      "****************************\n",
      "Epoch: 3306\n",
      "train_loss = 87.4857\n",
      "test_loss = 75.5518\n",
      "****************************\n",
      "Epoch: 3307\n",
      "train_loss = 88.4951\n",
      "test_loss = 74.1934\n",
      "****************************\n",
      "Epoch: 3308\n",
      "train_loss = 87.6054\n",
      "test_loss = 74.7551\n",
      "****************************\n",
      "Epoch: 3309\n",
      "train_loss = 87.5740\n",
      "test_loss = 74.8794\n",
      "****************************\n",
      "Epoch: 3310\n",
      "train_loss = 87.5521\n",
      "test_loss = 74.8646\n",
      "****************************\n",
      "Epoch: 3311\n",
      "train_loss = 87.5316\n",
      "test_loss = 74.8842\n",
      "****************************\n",
      "Epoch: 3312\n",
      "train_loss = 87.7984\n",
      "test_loss = 74.4862\n",
      "****************************\n",
      "Epoch: 3313\n",
      "train_loss = 88.5868\n",
      "test_loss = 78.6557\n",
      "****************************\n",
      "Epoch: 3314\n",
      "train_loss = 87.5474\n",
      "test_loss = 76.1257\n",
      "****************************\n",
      "Epoch: 3315\n",
      "train_loss = 87.5569\n",
      "test_loss = 74.9205\n",
      "****************************\n",
      "Epoch: 3316\n",
      "train_loss = 89.0618\n",
      "test_loss = 74.1563\n",
      "****************************\n",
      "Epoch: 3317\n",
      "train_loss = 88.2501\n",
      "test_loss = 78.0503\n",
      "****************************\n",
      "Epoch: 3318\n",
      "train_loss = 87.5405\n",
      "test_loss = 74.9009\n",
      "****************************\n",
      "Epoch: 3319\n",
      "train_loss = 88.1472\n",
      "test_loss = 77.9664\n",
      "****************************\n",
      "Epoch: 3320\n",
      "train_loss = 87.6399\n",
      "test_loss = 74.7102\n",
      "****************************\n",
      "Epoch: 3321\n",
      "train_loss = 89.2263\n",
      "test_loss = 79.7477\n",
      "****************************\n",
      "Epoch: 3322\n",
      "train_loss = 87.6310\n",
      "test_loss = 74.8644\n",
      "****************************\n",
      "Epoch: 3323\n",
      "train_loss = 87.6107\n",
      "test_loss = 75.1995\n",
      "****************************\n",
      "Epoch: 3324\n",
      "train_loss = 87.5630\n",
      "test_loss = 75.4229\n",
      "****************************\n",
      "Epoch: 3325\n",
      "train_loss = 88.0834\n",
      "test_loss = 77.4714\n",
      "****************************\n",
      "Epoch: 3326\n",
      "train_loss = 87.5400\n",
      "test_loss = 75.8251\n",
      "****************************\n",
      "Epoch: 3327\n",
      "train_loss = 87.5556\n",
      "test_loss = 74.9676\n",
      "****************************\n",
      "Epoch: 3328\n",
      "train_loss = 87.4997\n",
      "test_loss = 75.5146\n",
      "****************************\n",
      "Epoch: 3329\n",
      "train_loss = 87.5480\n",
      "test_loss = 74.9971\n",
      "****************************\n",
      "Epoch: 3330\n",
      "train_loss = 87.5611\n",
      "test_loss = 76.1372\n",
      "****************************\n",
      "Epoch: 3331\n",
      "train_loss = 87.6956\n",
      "test_loss = 74.6219\n",
      "****************************\n",
      "Epoch: 3332\n",
      "train_loss = 88.4382\n",
      "test_loss = 78.1734\n",
      "****************************\n",
      "Epoch: 3333\n",
      "train_loss = 87.6075\n",
      "test_loss = 75.2706\n",
      "****************************\n",
      "Epoch: 3334\n",
      "train_loss = 88.0317\n",
      "test_loss = 74.4460\n",
      "****************************\n",
      "Epoch: 3335\n",
      "train_loss = 87.9777\n",
      "test_loss = 74.4150\n",
      "****************************\n",
      "Epoch: 3336\n",
      "train_loss = 87.5858\n",
      "test_loss = 76.1148\n",
      "****************************\n",
      "Epoch: 3337\n",
      "train_loss = 87.9359\n",
      "test_loss = 77.0664\n",
      "****************************\n",
      "Epoch: 3338\n",
      "train_loss = 87.8321\n",
      "test_loss = 76.8769\n",
      "****************************\n",
      "Epoch: 3339\n",
      "train_loss = 87.6013\n",
      "test_loss = 74.9232\n",
      "****************************\n",
      "Epoch: 3340\n",
      "train_loss = 87.5484\n",
      "test_loss = 75.3923\n",
      "****************************\n",
      "Epoch: 3341\n",
      "train_loss = 87.6706\n",
      "test_loss = 76.2330\n",
      "****************************\n",
      "Epoch: 3342\n",
      "train_loss = 87.5511\n",
      "test_loss = 75.5515\n",
      "****************************\n",
      "Epoch: 3343\n",
      "train_loss = 87.8650\n",
      "test_loss = 74.4734\n",
      "****************************\n",
      "Epoch: 3344\n",
      "train_loss = 87.5159\n",
      "test_loss = 75.0775\n",
      "****************************\n",
      "Epoch: 3345\n",
      "train_loss = 87.5314\n",
      "test_loss = 74.9326\n",
      "****************************\n",
      "Epoch: 3346\n",
      "train_loss = 88.7466\n",
      "test_loss = 74.1150\n",
      "****************************\n",
      "Epoch: 3347\n",
      "train_loss = 89.1105\n",
      "test_loss = 74.1314\n",
      "****************************\n",
      "Epoch: 3348\n",
      "train_loss = 88.7497\n",
      "test_loss = 78.9385\n",
      "****************************\n",
      "Epoch: 3349\n",
      "train_loss = 87.7568\n",
      "test_loss = 74.5608\n",
      "****************************\n",
      "Epoch: 3350\n",
      "train_loss = 87.5142\n",
      "test_loss = 75.7106\n",
      "****************************\n",
      "Epoch: 3351\n",
      "train_loss = 87.5693\n",
      "test_loss = 76.0343\n",
      "****************************\n",
      "Epoch: 3352\n",
      "train_loss = 88.0520\n",
      "test_loss = 74.2910\n",
      "****************************\n",
      "Epoch: 3353\n",
      "train_loss = 87.5019\n",
      "test_loss = 75.8028\n",
      "****************************\n",
      "Epoch: 3354\n",
      "train_loss = 89.2093\n",
      "test_loss = 79.7993\n",
      "****************************\n",
      "Epoch: 3355\n",
      "train_loss = 87.9011\n",
      "test_loss = 74.4324\n",
      "****************************\n",
      "Epoch: 3356\n",
      "train_loss = 87.4770\n",
      "test_loss = 75.4282\n",
      "****************************\n",
      "Epoch: 3357\n",
      "train_loss = 87.6990\n",
      "test_loss = 74.6679\n",
      "****************************\n",
      "Epoch: 3358\n",
      "train_loss = 87.8471\n",
      "test_loss = 77.1251\n",
      "****************************\n",
      "Epoch: 3359\n",
      "train_loss = 87.7964\n",
      "test_loss = 74.5373\n",
      "****************************\n",
      "Epoch: 3360\n",
      "train_loss = 87.7099\n",
      "test_loss = 76.5490\n",
      "****************************\n",
      "Epoch: 3361\n",
      "train_loss = 87.5556\n",
      "test_loss = 75.1346\n",
      "****************************\n",
      "Epoch: 3362\n",
      "train_loss = 89.3478\n",
      "test_loss = 74.4145\n",
      "****************************\n",
      "Epoch: 3363\n",
      "train_loss = 87.5678\n",
      "test_loss = 75.5825\n",
      "****************************\n",
      "Epoch: 3364\n",
      "train_loss = 87.5805\n",
      "test_loss = 75.0191\n",
      "****************************\n",
      "Epoch: 3365\n",
      "train_loss = 87.5976\n",
      "test_loss = 76.1613\n",
      "****************************\n",
      "Epoch: 3366\n",
      "train_loss = 87.8391\n",
      "test_loss = 76.8732\n",
      "****************************\n",
      "Epoch: 3367\n",
      "train_loss = 87.5728\n",
      "test_loss = 75.6585\n",
      "****************************\n",
      "Epoch: 3368\n",
      "train_loss = 87.5306\n",
      "test_loss = 75.8645\n",
      "****************************\n",
      "Epoch: 3369\n",
      "train_loss = 87.4867\n",
      "test_loss = 75.4302\n",
      "****************************\n",
      "Epoch: 3370\n",
      "train_loss = 87.4894\n",
      "test_loss = 75.4903\n",
      "****************************\n",
      "Epoch: 3371\n",
      "train_loss = 87.4906\n",
      "test_loss = 75.6374\n",
      "****************************\n",
      "Epoch: 3372\n",
      "train_loss = 87.4702\n",
      "test_loss = 75.3763\n",
      "****************************\n",
      "Epoch: 3373\n",
      "train_loss = 87.8164\n",
      "test_loss = 74.6159\n",
      "****************************\n",
      "Epoch: 3374\n",
      "train_loss = 87.6775\n",
      "test_loss = 76.3888\n",
      "****************************\n",
      "Epoch: 3375\n",
      "train_loss = 87.5319\n",
      "test_loss = 75.8186\n",
      "****************************\n",
      "Epoch: 3376\n",
      "train_loss = 87.4923\n",
      "test_loss = 75.3156\n",
      "****************************\n",
      "Epoch: 3377\n",
      "train_loss = 87.5425\n",
      "test_loss = 75.0438\n",
      "****************************\n",
      "Epoch: 3378\n",
      "train_loss = 88.7035\n",
      "test_loss = 79.0156\n",
      "****************************\n",
      "Epoch: 3379\n",
      "train_loss = 87.6559\n",
      "test_loss = 74.7322\n",
      "****************************\n",
      "Epoch: 3380\n",
      "train_loss = 88.1313\n",
      "test_loss = 74.2734\n",
      "****************************\n",
      "Epoch: 3381\n",
      "train_loss = 87.8717\n",
      "test_loss = 76.9492\n",
      "****************************\n",
      "Epoch: 3382\n",
      "train_loss = 87.4846\n",
      "test_loss = 75.2807\n",
      "****************************\n",
      "Epoch: 3383\n",
      "train_loss = 87.7659\n",
      "test_loss = 76.7378\n",
      "****************************\n",
      "Epoch: 3384\n",
      "train_loss = 87.6622\n",
      "test_loss = 74.6994\n",
      "****************************\n",
      "Epoch: 3385\n",
      "train_loss = 87.6145\n",
      "test_loss = 76.2980\n",
      "****************************\n",
      "Epoch: 3386\n",
      "train_loss = 87.5271\n",
      "test_loss = 76.0145\n",
      "****************************\n",
      "Epoch: 3387\n",
      "train_loss = 87.5674\n",
      "test_loss = 74.8903\n",
      "****************************\n",
      "Epoch: 3388\n",
      "train_loss = 87.8442\n",
      "test_loss = 74.4541\n",
      "****************************\n",
      "Epoch: 3389\n",
      "train_loss = 87.6004\n",
      "test_loss = 74.7999\n",
      "****************************\n",
      "Epoch: 3390\n",
      "train_loss = 88.1148\n",
      "test_loss = 77.5988\n",
      "****************************\n",
      "Epoch: 3391\n",
      "train_loss = 88.7157\n",
      "test_loss = 74.1274\n",
      "****************************\n",
      "Epoch: 3392\n",
      "train_loss = 89.5424\n",
      "test_loss = 80.2983\n",
      "****************************\n",
      "Epoch: 3393\n",
      "train_loss = 87.6652\n",
      "test_loss = 76.5429\n",
      "****************************\n",
      "Epoch: 3394\n",
      "train_loss = 87.5562\n",
      "test_loss = 76.1471\n",
      "****************************\n",
      "Epoch: 3395\n",
      "train_loss = 87.4905\n",
      "test_loss = 75.5903\n",
      "****************************\n",
      "Epoch: 3396\n",
      "train_loss = 87.6584\n",
      "test_loss = 74.6909\n",
      "****************************\n",
      "Epoch: 3397\n",
      "train_loss = 87.5635\n",
      "test_loss = 75.0165\n",
      "****************************\n",
      "Epoch: 3398\n",
      "train_loss = 87.7643\n",
      "test_loss = 76.7921\n",
      "****************************\n",
      "Epoch: 3399\n",
      "train_loss = 87.7652\n",
      "test_loss = 74.5535\n",
      "****************************\n",
      "Epoch: 3400\n",
      "train_loss = 87.5016\n",
      "test_loss = 75.1674\n",
      "****************************\n",
      "Epoch: 3401\n",
      "train_loss = 87.5548\n",
      "test_loss = 74.8955\n",
      "****************************\n",
      "Epoch: 3402\n",
      "train_loss = 87.5347\n",
      "test_loss = 74.9778\n",
      "****************************\n",
      "Epoch: 3403\n",
      "train_loss = 87.8727\n",
      "test_loss = 74.4327\n",
      "****************************\n",
      "Epoch: 3404\n",
      "train_loss = 87.5909\n",
      "test_loss = 76.3924\n",
      "****************************\n",
      "Epoch: 3405\n",
      "train_loss = 87.4663\n",
      "test_loss = 75.1808\n",
      "****************************\n",
      "Epoch: 3406\n",
      "train_loss = 87.5228\n",
      "test_loss = 76.1263\n",
      "****************************\n",
      "Epoch: 3407\n",
      "train_loss = 87.6387\n",
      "test_loss = 74.6824\n",
      "****************************\n",
      "Epoch: 3408\n",
      "train_loss = 87.4896\n",
      "test_loss = 75.3614\n",
      "****************************\n",
      "Epoch: 3409\n",
      "train_loss = 87.4772\n",
      "test_loss = 75.3741\n",
      "****************************\n",
      "Epoch: 3410\n",
      "train_loss = 87.4986\n",
      "test_loss = 75.8824\n",
      "****************************\n",
      "Epoch: 3411\n",
      "train_loss = 87.4964\n",
      "test_loss = 75.1341\n",
      "****************************\n",
      "Epoch: 3412\n",
      "train_loss = 87.4685\n",
      "test_loss = 75.2470\n",
      "****************************\n",
      "Epoch: 3413\n",
      "train_loss = 87.4667\n",
      "test_loss = 75.7863\n",
      "****************************\n",
      "Epoch: 3414\n",
      "train_loss = 87.5567\n",
      "test_loss = 76.3103\n",
      "****************************\n",
      "Epoch: 3415\n",
      "train_loss = 87.4703\n",
      "test_loss = 75.4101\n",
      "****************************\n",
      "Epoch: 3416\n",
      "train_loss = 87.4753\n",
      "test_loss = 75.8792\n",
      "****************************\n",
      "Epoch: 3417\n",
      "train_loss = 87.8210\n",
      "test_loss = 74.4708\n",
      "****************************\n",
      "Epoch: 3418\n",
      "train_loss = 87.4653\n",
      "test_loss = 75.4001\n",
      "****************************\n",
      "Epoch: 3419\n",
      "train_loss = 88.3321\n",
      "test_loss = 74.1804\n",
      "****************************\n",
      "Epoch: 3420\n",
      "train_loss = 87.4838\n",
      "test_loss = 75.2016\n",
      "****************************\n",
      "Epoch: 3421\n",
      "train_loss = 87.5569\n",
      "test_loss = 74.8884\n",
      "****************************\n",
      "Epoch: 3422\n",
      "train_loss = 87.5237\n",
      "test_loss = 75.0545\n",
      "****************************\n",
      "Epoch: 3423\n",
      "train_loss = 87.4862\n",
      "test_loss = 75.4599\n",
      "****************************\n",
      "Epoch: 3424\n",
      "train_loss = 87.5025\n",
      "test_loss = 75.0056\n",
      "****************************\n",
      "Epoch: 3425\n",
      "train_loss = 87.5371\n",
      "test_loss = 75.1885\n",
      "****************************\n",
      "Epoch: 3426\n",
      "train_loss = 88.1119\n",
      "test_loss = 77.7201\n",
      "****************************\n",
      "Epoch: 3427\n",
      "train_loss = 87.4504\n",
      "test_loss = 75.4694\n",
      "****************************\n",
      "Epoch: 3428\n",
      "train_loss = 88.1742\n",
      "test_loss = 77.9701\n",
      "****************************\n",
      "Epoch: 3429\n",
      "train_loss = 87.6068\n",
      "test_loss = 76.5207\n",
      "****************************\n",
      "Epoch: 3430\n",
      "train_loss = 87.4665\n",
      "test_loss = 75.8599\n",
      "****************************\n",
      "Epoch: 3431\n",
      "train_loss = 87.5131\n",
      "test_loss = 74.9145\n",
      "****************************\n",
      "Epoch: 3432\n",
      "train_loss = 87.4334\n",
      "test_loss = 75.2022\n",
      "****************************\n",
      "Epoch: 3433\n",
      "train_loss = 87.4761\n",
      "test_loss = 75.1567\n",
      "****************************\n",
      "Epoch: 3434\n",
      "train_loss = 87.5192\n",
      "test_loss = 75.9148\n",
      "****************************\n",
      "Epoch: 3435\n",
      "train_loss = 87.4815\n",
      "test_loss = 75.0255\n",
      "****************************\n",
      "Epoch: 3436\n",
      "train_loss = 87.5686\n",
      "test_loss = 76.0455\n",
      "****************************\n",
      "Epoch: 3437\n",
      "train_loss = 87.4821\n",
      "test_loss = 75.1252\n",
      "****************************\n",
      "Epoch: 3438\n",
      "train_loss = 87.7671\n",
      "test_loss = 74.4699\n",
      "****************************\n",
      "Epoch: 3439\n",
      "train_loss = 87.6928\n",
      "test_loss = 76.6235\n",
      "****************************\n",
      "Epoch: 3440\n",
      "train_loss = 87.9626\n",
      "test_loss = 74.3101\n",
      "****************************\n",
      "Epoch: 3441\n",
      "train_loss = 87.4563\n",
      "test_loss = 75.1233\n",
      "****************************\n",
      "Epoch: 3442\n",
      "train_loss = 87.4878\n",
      "test_loss = 75.0106\n",
      "****************************\n",
      "Epoch: 3443\n",
      "train_loss = 89.1112\n",
      "test_loss = 79.5313\n",
      "****************************\n",
      "Epoch: 3444\n",
      "train_loss = 87.4787\n",
      "test_loss = 75.8658\n",
      "****************************\n",
      "Epoch: 3445\n",
      "train_loss = 87.5224\n",
      "test_loss = 76.0709\n",
      "****************************\n",
      "Epoch: 3446\n",
      "train_loss = 87.7003\n",
      "test_loss = 76.6057\n",
      "****************************\n",
      "Epoch: 3447\n",
      "train_loss = 87.4954\n",
      "test_loss = 75.2160\n",
      "****************************\n",
      "Epoch: 3448\n",
      "train_loss = 87.5181\n",
      "test_loss = 75.9593\n",
      "****************************\n",
      "Epoch: 3449\n",
      "train_loss = 88.0829\n",
      "test_loss = 77.6659\n",
      "****************************\n",
      "Epoch: 3450\n",
      "train_loss = 87.5152\n",
      "test_loss = 74.9183\n",
      "****************************\n",
      "Epoch: 3451\n",
      "train_loss = 87.8897\n",
      "test_loss = 77.3207\n",
      "****************************\n",
      "Epoch: 3452\n",
      "train_loss = 87.5628\n",
      "test_loss = 76.2235\n",
      "****************************\n",
      "Epoch: 3453\n",
      "train_loss = 87.4468\n",
      "test_loss = 75.3599\n",
      "****************************\n",
      "Epoch: 3454\n",
      "train_loss = 87.4685\n",
      "test_loss = 75.0981\n",
      "****************************\n",
      "Epoch: 3455\n",
      "train_loss = 87.4595\n",
      "test_loss = 75.3296\n",
      "****************************\n",
      "Epoch: 3456\n",
      "train_loss = 88.2721\n",
      "test_loss = 78.1155\n",
      "****************************\n",
      "Epoch: 3457\n",
      "train_loss = 87.4399\n",
      "test_loss = 75.4861\n",
      "****************************\n",
      "Epoch: 3458\n",
      "train_loss = 89.3775\n",
      "test_loss = 80.1268\n",
      "****************************\n",
      "Epoch: 3459\n",
      "train_loss = 87.7427\n",
      "test_loss = 76.7945\n",
      "****************************\n",
      "Epoch: 3460\n",
      "train_loss = 87.7063\n",
      "test_loss = 76.7440\n",
      "****************************\n",
      "Epoch: 3461\n",
      "train_loss = 87.7017\n",
      "test_loss = 76.7230\n",
      "****************************\n",
      "Epoch: 3462\n",
      "train_loss = 87.5330\n",
      "test_loss = 74.9292\n",
      "****************************\n",
      "Epoch: 3463\n",
      "train_loss = 87.9230\n",
      "test_loss = 77.2682\n",
      "****************************\n",
      "Epoch: 3464\n",
      "train_loss = 87.5637\n",
      "test_loss = 76.2313\n",
      "****************************\n",
      "Epoch: 3465\n",
      "train_loss = 87.4703\n",
      "test_loss = 75.6100\n",
      "****************************\n",
      "Epoch: 3466\n",
      "train_loss = 87.5194\n",
      "test_loss = 74.9867\n",
      "****************************\n",
      "Epoch: 3467\n",
      "train_loss = 87.5120\n",
      "test_loss = 74.9498\n",
      "****************************\n",
      "Epoch: 3468\n",
      "train_loss = 88.1782\n",
      "test_loss = 74.1960\n",
      "****************************\n",
      "Epoch: 3469\n",
      "train_loss = 87.4799\n",
      "test_loss = 75.0434\n",
      "****************************\n",
      "Epoch: 3470\n",
      "train_loss = 87.7563\n",
      "test_loss = 76.9290\n",
      "****************************\n",
      "Epoch: 3471\n",
      "train_loss = 87.6145\n",
      "test_loss = 74.6801\n",
      "****************************\n",
      "Epoch: 3472\n",
      "train_loss = 87.4592\n",
      "test_loss = 75.4531\n",
      "****************************\n",
      "Epoch: 3473\n",
      "train_loss = 87.7012\n",
      "test_loss = 76.6605\n",
      "****************************\n",
      "Epoch: 3474\n",
      "train_loss = 87.9972\n",
      "test_loss = 74.2907\n",
      "****************************\n",
      "Epoch: 3475\n",
      "train_loss = 87.4971\n",
      "test_loss = 75.9234\n",
      "****************************\n",
      "Epoch: 3476\n",
      "train_loss = 88.4344\n",
      "test_loss = 78.5713\n",
      "****************************\n",
      "Epoch: 3477\n",
      "train_loss = 87.4564\n",
      "test_loss = 75.3923\n",
      "****************************\n",
      "Epoch: 3478\n",
      "train_loss = 87.5760\n",
      "test_loss = 76.2408\n",
      "****************************\n",
      "Epoch: 3479\n",
      "train_loss = 87.6862\n",
      "test_loss = 74.5543\n",
      "****************************\n",
      "Epoch: 3480\n",
      "train_loss = 87.6743\n",
      "test_loss = 76.5511\n",
      "****************************\n",
      "Epoch: 3481\n",
      "train_loss = 87.5185\n",
      "test_loss = 75.9138\n",
      "****************************\n",
      "Epoch: 3482\n",
      "train_loss = 88.0240\n",
      "test_loss = 74.6669\n",
      "****************************\n",
      "Epoch: 3483\n",
      "train_loss = 87.5228\n",
      "test_loss = 75.1269\n",
      "****************************\n",
      "Epoch: 3484\n",
      "train_loss = 87.4696\n",
      "test_loss = 75.4472\n",
      "****************************\n",
      "Epoch: 3485\n",
      "train_loss = 87.8295\n",
      "test_loss = 74.4192\n",
      "****************************\n",
      "Epoch: 3486\n",
      "train_loss = 87.5335\n",
      "test_loss = 75.4711\n",
      "****************************\n",
      "Epoch: 3487\n",
      "train_loss = 88.5709\n",
      "test_loss = 74.1208\n",
      "****************************\n",
      "Epoch: 3488\n",
      "train_loss = 87.5051\n",
      "test_loss = 75.0381\n",
      "****************************\n",
      "Epoch: 3489\n",
      "train_loss = 88.4363\n",
      "test_loss = 78.3642\n",
      "****************************\n",
      "Epoch: 3490\n",
      "train_loss = 87.4899\n",
      "test_loss = 75.8503\n",
      "****************************\n",
      "Epoch: 3491\n",
      "train_loss = 87.7661\n",
      "test_loss = 74.4978\n",
      "****************************\n",
      "Epoch: 3492\n",
      "train_loss = 87.5316\n",
      "test_loss = 75.9600\n",
      "****************************\n",
      "Epoch: 3493\n",
      "train_loss = 87.8591\n",
      "test_loss = 77.1571\n",
      "****************************\n",
      "Epoch: 3494\n",
      "train_loss = 87.5466\n",
      "test_loss = 74.8986\n",
      "****************************\n",
      "Epoch: 3495\n",
      "train_loss = 87.5797\n",
      "test_loss = 76.1155\n",
      "****************************\n",
      "Epoch: 3496\n",
      "train_loss = 87.6175\n",
      "test_loss = 76.3052\n",
      "****************************\n",
      "Epoch: 3497\n",
      "train_loss = 87.7156\n",
      "test_loss = 76.7797\n",
      "****************************\n",
      "Epoch: 3498\n",
      "train_loss = 87.5408\n",
      "test_loss = 74.9287\n",
      "****************************\n",
      "Epoch: 3499\n",
      "train_loss = 87.5419\n",
      "test_loss = 74.9584\n",
      "****************************\n",
      "Epoch: 3500\n",
      "train_loss = 87.5814\n",
      "test_loss = 76.4668\n",
      "****************************\n",
      "Epoch: 3501\n",
      "train_loss = 87.4874\n",
      "test_loss = 75.2713\n",
      "****************************\n",
      "Epoch: 3502\n",
      "train_loss = 87.6683\n",
      "test_loss = 76.8252\n",
      "****************************\n",
      "Epoch: 3503\n",
      "train_loss = 87.4954\n",
      "test_loss = 76.0195\n",
      "****************************\n",
      "Epoch: 3504\n",
      "train_loss = 87.5084\n",
      "test_loss = 75.1077\n",
      "****************************\n",
      "Epoch: 3505\n",
      "train_loss = 87.4753\n",
      "test_loss = 75.2198\n",
      "****************************\n",
      "Epoch: 3506\n",
      "train_loss = 88.4612\n",
      "test_loss = 78.5428\n",
      "****************************\n",
      "Epoch: 3507\n",
      "train_loss = 87.4550\n",
      "test_loss = 75.5405\n",
      "****************************\n",
      "Epoch: 3508\n",
      "train_loss = 88.3666\n",
      "test_loss = 78.2568\n",
      "****************************\n",
      "Epoch: 3509\n",
      "train_loss = 87.6403\n",
      "test_loss = 74.6837\n",
      "****************************\n",
      "Epoch: 3510\n",
      "train_loss = 87.6897\n",
      "test_loss = 74.5942\n",
      "****************************\n",
      "Epoch: 3511\n",
      "train_loss = 87.4840\n",
      "test_loss = 75.1102\n",
      "****************************\n",
      "Epoch: 3512\n",
      "train_loss = 89.7647\n",
      "test_loss = 80.7951\n",
      "****************************\n",
      "Epoch: 3513\n",
      "train_loss = 87.4985\n",
      "test_loss = 75.0737\n",
      "****************************\n",
      "Epoch: 3514\n",
      "train_loss = 87.4921\n",
      "test_loss = 75.6980\n",
      "****************************\n",
      "Epoch: 3515\n",
      "train_loss = 87.5232\n",
      "test_loss = 74.9399\n",
      "****************************\n",
      "Epoch: 3516\n",
      "train_loss = 87.6182\n",
      "test_loss = 76.3539\n",
      "****************************\n",
      "Epoch: 3517\n",
      "train_loss = 87.8372\n",
      "test_loss = 77.0564\n",
      "****************************\n",
      "Epoch: 3518\n",
      "train_loss = 87.4807\n",
      "test_loss = 75.6387\n",
      "****************************\n",
      "Epoch: 3519\n",
      "train_loss = 87.9153\n",
      "test_loss = 77.3950\n",
      "****************************\n",
      "Epoch: 3520\n",
      "train_loss = 87.4852\n",
      "test_loss = 75.2848\n",
      "****************************\n",
      "Epoch: 3521\n",
      "train_loss = 87.5162\n",
      "test_loss = 74.9758\n",
      "****************************\n",
      "Epoch: 3522\n",
      "train_loss = 87.4704\n",
      "test_loss = 75.8270\n",
      "****************************\n",
      "Epoch: 3523\n",
      "train_loss = 87.6489\n",
      "test_loss = 76.6512\n",
      "****************************\n",
      "Epoch: 3524\n",
      "train_loss = 87.5078\n",
      "test_loss = 75.0072\n",
      "****************************\n",
      "Epoch: 3525\n",
      "train_loss = 87.7940\n",
      "test_loss = 76.9571\n",
      "****************************\n",
      "Epoch: 3526\n",
      "train_loss = 87.7922\n",
      "test_loss = 76.9898\n",
      "****************************\n",
      "Epoch: 3527\n",
      "train_loss = 88.4650\n",
      "test_loss = 74.1370\n",
      "****************************\n",
      "Epoch: 3528\n",
      "train_loss = 88.6886\n",
      "test_loss = 78.5023\n",
      "****************************\n",
      "Epoch: 3529\n",
      "train_loss = 87.5202\n",
      "test_loss = 75.4176\n",
      "****************************\n",
      "Epoch: 3530\n",
      "train_loss = 87.5173\n",
      "test_loss = 75.7542\n",
      "****************************\n",
      "Epoch: 3531\n",
      "train_loss = 87.5255\n",
      "test_loss = 74.8986\n",
      "****************************\n",
      "Epoch: 3532\n",
      "train_loss = 87.5781\n",
      "test_loss = 74.7628\n",
      "****************************\n",
      "Epoch: 3533\n",
      "train_loss = 88.3791\n",
      "test_loss = 74.3719\n",
      "****************************\n",
      "Epoch: 3534\n",
      "train_loss = 87.5513\n",
      "test_loss = 75.0469\n",
      "****************************\n",
      "Epoch: 3535\n",
      "train_loss = 89.2387\n",
      "test_loss = 79.9339\n",
      "****************************\n",
      "Epoch: 3536\n",
      "train_loss = 87.5205\n",
      "test_loss = 75.3967\n",
      "****************************\n",
      "Epoch: 3537\n",
      "train_loss = 88.0506\n",
      "test_loss = 77.5469\n",
      "****************************\n",
      "Epoch: 3538\n",
      "train_loss = 87.6390\n",
      "test_loss = 76.4769\n",
      "****************************\n",
      "Epoch: 3539\n",
      "train_loss = 87.4914\n",
      "test_loss = 75.9671\n",
      "****************************\n",
      "Epoch: 3540\n",
      "train_loss = 87.8715\n",
      "test_loss = 74.3813\n",
      "****************************\n",
      "Epoch: 3541\n",
      "train_loss = 87.5013\n",
      "test_loss = 75.9536\n",
      "****************************\n",
      "Epoch: 3542\n",
      "train_loss = 88.2087\n",
      "test_loss = 74.2055\n",
      "****************************\n",
      "Epoch: 3543\n",
      "train_loss = 87.5620\n",
      "test_loss = 74.9440\n",
      "****************************\n",
      "Epoch: 3544\n",
      "train_loss = 87.8209\n",
      "test_loss = 74.4581\n",
      "****************************\n",
      "Epoch: 3545\n",
      "train_loss = 87.7796\n",
      "test_loss = 76.4884\n",
      "****************************\n",
      "Epoch: 3546\n",
      "train_loss = 88.5506\n",
      "test_loss = 78.0904\n",
      "****************************\n",
      "Epoch: 3547\n",
      "train_loss = 88.4840\n",
      "test_loss = 78.2046\n",
      "****************************\n",
      "Epoch: 3548\n",
      "train_loss = 87.6026\n",
      "test_loss = 76.1373\n",
      "****************************\n",
      "Epoch: 3549\n",
      "train_loss = 87.4963\n",
      "test_loss = 75.6971\n",
      "****************************\n",
      "Epoch: 3550\n",
      "train_loss = 87.4875\n",
      "test_loss = 75.5030\n",
      "****************************\n",
      "Epoch: 3551\n",
      "train_loss = 87.6622\n",
      "test_loss = 74.6483\n",
      "****************************\n",
      "Epoch: 3552\n",
      "train_loss = 87.4733\n",
      "test_loss = 75.6144\n",
      "****************************\n",
      "Epoch: 3553\n",
      "train_loss = 87.4941\n",
      "test_loss = 75.8748\n",
      "****************************\n",
      "Epoch: 3554\n",
      "train_loss = 87.5168\n",
      "test_loss = 74.9623\n",
      "****************************\n",
      "Epoch: 3555\n",
      "train_loss = 87.4930\n",
      "test_loss = 75.1370\n",
      "****************************\n",
      "Epoch: 3556\n",
      "train_loss = 88.3797\n",
      "test_loss = 78.2979\n",
      "****************************\n",
      "Epoch: 3557\n",
      "train_loss = 87.5025\n",
      "test_loss = 76.0780\n",
      "****************************\n",
      "Epoch: 3558\n",
      "train_loss = 87.4610\n",
      "test_loss = 75.4790\n",
      "****************************\n",
      "Epoch: 3559\n",
      "train_loss = 87.4796\n",
      "test_loss = 75.1545\n",
      "****************************\n",
      "Epoch: 3560\n",
      "train_loss = 87.5090\n",
      "test_loss = 75.9699\n",
      "****************************\n",
      "Epoch: 3561\n",
      "train_loss = 87.9807\n",
      "test_loss = 74.3582\n",
      "****************************\n",
      "Epoch: 3562\n",
      "train_loss = 87.5052\n",
      "test_loss = 75.3734\n",
      "****************************\n",
      "Epoch: 3563\n",
      "train_loss = 87.5575\n",
      "test_loss = 75.7885\n",
      "****************************\n",
      "Epoch: 3564\n",
      "train_loss = 87.5011\n",
      "test_loss = 75.8328\n",
      "****************************\n",
      "Epoch: 3565\n",
      "train_loss = 88.0667\n",
      "test_loss = 74.3202\n",
      "****************************\n",
      "Epoch: 3566\n",
      "train_loss = 87.4585\n",
      "test_loss = 75.1900\n",
      "****************************\n",
      "Epoch: 3567\n",
      "train_loss = 87.4842\n",
      "test_loss = 75.0811\n",
      "****************************\n",
      "Epoch: 3568\n",
      "train_loss = 89.8233\n",
      "test_loss = 80.7658\n",
      "****************************\n",
      "Epoch: 3569\n",
      "train_loss = 87.5060\n",
      "test_loss = 75.8681\n",
      "****************************\n",
      "Epoch: 3570\n",
      "train_loss = 88.3132\n",
      "test_loss = 74.1864\n",
      "****************************\n",
      "Epoch: 3571\n",
      "train_loss = 87.6279\n",
      "test_loss = 74.6715\n",
      "****************************\n",
      "Epoch: 3572\n",
      "train_loss = 89.2494\n",
      "test_loss = 79.8642\n",
      "****************************\n",
      "Epoch: 3573\n",
      "train_loss = 87.7000\n",
      "test_loss = 76.5444\n",
      "****************************\n",
      "Epoch: 3574\n",
      "train_loss = 87.9002\n",
      "test_loss = 77.0364\n",
      "****************************\n",
      "Epoch: 3575\n",
      "train_loss = 87.5673\n",
      "test_loss = 74.8689\n",
      "****************************\n",
      "Epoch: 3576\n",
      "train_loss = 87.5054\n",
      "test_loss = 75.1257\n",
      "****************************\n",
      "Epoch: 3577\n",
      "train_loss = 88.1424\n",
      "test_loss = 77.8068\n",
      "****************************\n",
      "Epoch: 3578\n",
      "train_loss = 87.4526\n",
      "test_loss = 75.4375\n",
      "****************************\n",
      "Epoch: 3579\n",
      "train_loss = 87.6570\n",
      "test_loss = 76.5616\n",
      "****************************\n",
      "Epoch: 3580\n",
      "train_loss = 87.4567\n",
      "test_loss = 75.6784\n",
      "****************************\n",
      "Epoch: 3581\n",
      "train_loss = 87.4899\n",
      "test_loss = 75.8898\n",
      "****************************\n",
      "Epoch: 3582\n",
      "train_loss = 87.4849\n",
      "test_loss = 75.9041\n",
      "****************************\n",
      "Epoch: 3583\n",
      "train_loss = 87.6408\n",
      "test_loss = 76.6126\n",
      "****************************\n",
      "Epoch: 3584\n",
      "train_loss = 87.5862\n",
      "test_loss = 74.7927\n",
      "****************************\n",
      "Epoch: 3585\n",
      "train_loss = 87.4539\n",
      "test_loss = 75.7203\n",
      "****************************\n",
      "Epoch: 3586\n",
      "train_loss = 87.5293\n",
      "test_loss = 76.1274\n",
      "****************************\n",
      "Epoch: 3587\n",
      "train_loss = 87.4683\n",
      "test_loss = 75.7424\n",
      "****************************\n",
      "Epoch: 3588\n",
      "train_loss = 87.5287\n",
      "test_loss = 75.6458\n",
      "****************************\n",
      "Epoch: 3589\n",
      "train_loss = 87.9950\n",
      "test_loss = 74.4088\n",
      "****************************\n",
      "Epoch: 3590\n",
      "train_loss = 87.9552\n",
      "test_loss = 74.4164\n",
      "****************************\n",
      "Epoch: 3591\n",
      "train_loss = 87.7651\n",
      "test_loss = 76.8597\n",
      "****************************\n",
      "Epoch: 3592\n",
      "train_loss = 88.6947\n",
      "test_loss = 78.8690\n",
      "****************************\n",
      "Epoch: 3593\n",
      "train_loss = 87.4982\n",
      "test_loss = 75.2076\n",
      "****************************\n",
      "Epoch: 3594\n",
      "train_loss = 87.6716\n",
      "test_loss = 74.6187\n",
      "****************************\n",
      "Epoch: 3595\n",
      "train_loss = 87.4606\n",
      "test_loss = 75.7170\n",
      "****************************\n",
      "Epoch: 3596\n",
      "train_loss = 87.6103\n",
      "test_loss = 74.7450\n",
      "****************************\n",
      "Epoch: 3597\n",
      "train_loss = 87.5469\n",
      "test_loss = 76.3297\n",
      "****************************\n",
      "Epoch: 3598\n",
      "train_loss = 87.4468\n",
      "test_loss = 75.7489\n",
      "****************************\n",
      "Epoch: 3599\n",
      "train_loss = 87.4474\n",
      "test_loss = 75.4958\n",
      "****************************\n",
      "Epoch: 3600\n",
      "train_loss = 87.5705\n",
      "test_loss = 76.2290\n",
      "****************************\n",
      "Epoch: 3601\n",
      "train_loss = 87.5153\n",
      "test_loss = 76.0539\n",
      "****************************\n",
      "Epoch: 3602\n",
      "train_loss = 87.5496\n",
      "test_loss = 74.8382\n",
      "****************************\n",
      "Epoch: 3603\n",
      "train_loss = 89.0693\n",
      "test_loss = 79.3544\n",
      "****************************\n",
      "Epoch: 3604\n",
      "train_loss = 87.5301\n",
      "test_loss = 75.3662\n",
      "****************************\n",
      "Epoch: 3605\n",
      "train_loss = 87.5413\n",
      "test_loss = 75.9789\n",
      "****************************\n",
      "Epoch: 3606\n",
      "train_loss = 87.4722\n",
      "test_loss = 75.1617\n",
      "****************************\n",
      "Epoch: 3607\n",
      "train_loss = 87.6876\n",
      "test_loss = 76.6216\n",
      "****************************\n",
      "Epoch: 3608\n",
      "train_loss = 87.5240\n",
      "test_loss = 75.4823\n",
      "****************************\n",
      "Epoch: 3609\n",
      "train_loss = 87.5023\n",
      "test_loss = 75.3273\n",
      "****************************\n",
      "Epoch: 3610\n",
      "train_loss = 87.4616\n",
      "test_loss = 75.4259\n",
      "****************************\n",
      "Epoch: 3611\n",
      "train_loss = 88.5747\n",
      "test_loss = 78.5580\n",
      "****************************\n",
      "Epoch: 3612\n",
      "train_loss = 88.0420\n",
      "test_loss = 74.3331\n",
      "****************************\n",
      "Epoch: 3613\n",
      "train_loss = 87.7964\n",
      "test_loss = 76.8487\n",
      "****************************\n",
      "Epoch: 3614\n",
      "train_loss = 88.3775\n",
      "test_loss = 74.2111\n",
      "****************************\n",
      "Epoch: 3615\n",
      "train_loss = 87.5220\n",
      "test_loss = 75.9557\n",
      "****************************\n",
      "Epoch: 3616\n",
      "train_loss = 88.8389\n",
      "test_loss = 79.2307\n",
      "****************************\n",
      "Epoch: 3617\n",
      "train_loss = 87.5022\n",
      "test_loss = 76.0036\n",
      "****************************\n",
      "Epoch: 3618\n",
      "train_loss = 87.5356\n",
      "test_loss = 76.2063\n",
      "****************************\n",
      "Epoch: 3619\n",
      "train_loss = 87.6452\n",
      "test_loss = 74.7062\n",
      "****************************\n",
      "Epoch: 3620\n",
      "train_loss = 87.4893\n",
      "test_loss = 75.3470\n",
      "****************************\n",
      "Epoch: 3621\n",
      "train_loss = 87.4906\n",
      "test_loss = 75.7491\n",
      "****************************\n",
      "Epoch: 3622\n",
      "train_loss = 87.5025\n",
      "test_loss = 75.0396\n",
      "****************************\n",
      "Epoch: 3623\n",
      "train_loss = 87.5139\n",
      "test_loss = 74.9474\n",
      "****************************\n",
      "Epoch: 3624\n",
      "train_loss = 87.5758\n",
      "test_loss = 76.3222\n",
      "****************************\n",
      "Epoch: 3625\n",
      "train_loss = 87.9658\n",
      "test_loss = 74.3626\n",
      "****************************\n",
      "Epoch: 3626\n",
      "train_loss = 87.5169\n",
      "test_loss = 75.4991\n",
      "****************************\n",
      "Epoch: 3627\n",
      "train_loss = 87.4873\n",
      "test_loss = 75.1545\n",
      "****************************\n",
      "Epoch: 3628\n",
      "train_loss = 87.8359\n",
      "test_loss = 74.4764\n",
      "****************************\n",
      "Epoch: 3629\n",
      "train_loss = 87.5622\n",
      "test_loss = 75.1005\n",
      "****************************\n",
      "Epoch: 3630\n",
      "train_loss = 87.5411\n",
      "test_loss = 75.7300\n",
      "****************************\n",
      "Epoch: 3631\n",
      "train_loss = 87.5961\n",
      "test_loss = 74.8705\n",
      "****************************\n",
      "Epoch: 3632\n",
      "train_loss = 87.4796\n",
      "test_loss = 75.4232\n",
      "****************************\n",
      "Epoch: 3633\n",
      "train_loss = 87.5406\n",
      "test_loss = 75.3964\n",
      "****************************\n",
      "Epoch: 3634\n",
      "train_loss = 87.6161\n",
      "test_loss = 75.9436\n",
      "****************************\n",
      "Epoch: 3635\n",
      "train_loss = 87.5566\n",
      "test_loss = 75.2393\n",
      "****************************\n",
      "Epoch: 3636\n",
      "train_loss = 87.5890\n",
      "test_loss = 76.0972\n",
      "****************************\n",
      "Epoch: 3637\n",
      "train_loss = 87.7077\n",
      "test_loss = 74.5484\n",
      "****************************\n",
      "Epoch: 3638\n",
      "train_loss = 87.8700\n",
      "test_loss = 77.1981\n",
      "****************************\n",
      "Epoch: 3639\n",
      "train_loss = 87.6132\n",
      "test_loss = 74.6730\n",
      "****************************\n",
      "Epoch: 3640\n",
      "train_loss = 87.5395\n",
      "test_loss = 76.1815\n",
      "****************************\n",
      "Epoch: 3641\n",
      "train_loss = 88.5635\n",
      "test_loss = 78.6226\n",
      "****************************\n",
      "Epoch: 3642\n",
      "train_loss = 89.1657\n",
      "test_loss = 79.6961\n",
      "****************************\n",
      "Epoch: 3643\n",
      "train_loss = 87.5480\n",
      "test_loss = 74.9172\n",
      "****************************\n",
      "Epoch: 3644\n",
      "train_loss = 88.2328\n",
      "test_loss = 77.7425\n",
      "****************************\n",
      "Epoch: 3645\n",
      "train_loss = 88.0586\n",
      "test_loss = 74.2870\n",
      "****************************\n",
      "Epoch: 3646\n",
      "train_loss = 87.6642\n",
      "test_loss = 74.6266\n",
      "****************************\n",
      "Epoch: 3647\n",
      "train_loss = 88.6532\n",
      "test_loss = 78.8525\n",
      "****************************\n",
      "Epoch: 3648\n",
      "train_loss = 87.5953\n",
      "test_loss = 74.7914\n",
      "****************************\n",
      "Epoch: 3649\n",
      "train_loss = 87.4780\n",
      "test_loss = 75.7298\n",
      "****************************\n",
      "Epoch: 3650\n",
      "train_loss = 87.4815\n",
      "test_loss = 75.5738\n",
      "****************************\n",
      "Epoch: 3651\n",
      "train_loss = 87.5036\n",
      "test_loss = 75.1597\n",
      "****************************\n",
      "Epoch: 3652\n",
      "train_loss = 87.5257\n",
      "test_loss = 75.0199\n",
      "****************************\n",
      "Epoch: 3653\n",
      "train_loss = 87.7169\n",
      "test_loss = 74.5835\n",
      "****************************\n",
      "Epoch: 3654\n",
      "train_loss = 87.5334\n",
      "test_loss = 75.7565\n",
      "****************************\n",
      "Epoch: 3655\n",
      "train_loss = 87.6614\n",
      "test_loss = 76.3011\n",
      "****************************\n",
      "Epoch: 3656\n",
      "train_loss = 87.6832\n",
      "test_loss = 76.6073\n",
      "****************************\n",
      "Epoch: 3657\n",
      "train_loss = 87.6366\n",
      "test_loss = 74.8239\n",
      "****************************\n",
      "Epoch: 3658\n",
      "train_loss = 87.6096\n",
      "test_loss = 74.8675\n",
      "****************************\n",
      "Epoch: 3659\n",
      "train_loss = 87.5056\n",
      "test_loss = 75.6344\n",
      "****************************\n",
      "Epoch: 3660\n",
      "train_loss = 87.4901\n",
      "test_loss = 75.6470\n",
      "****************************\n",
      "Epoch: 3661\n",
      "train_loss = 88.9615\n",
      "test_loss = 79.3578\n",
      "****************************\n",
      "Epoch: 3662\n",
      "train_loss = 87.7372\n",
      "test_loss = 74.5743\n",
      "****************************\n",
      "Epoch: 3663\n",
      "train_loss = 87.5139\n",
      "test_loss = 76.1147\n",
      "****************************\n",
      "Epoch: 3664\n",
      "train_loss = 88.0545\n",
      "test_loss = 76.6626\n",
      "****************************\n",
      "Epoch: 3665\n",
      "train_loss = 87.6986\n",
      "test_loss = 76.6960\n",
      "****************************\n",
      "Epoch: 3666\n",
      "train_loss = 87.5512\n",
      "test_loss = 75.1545\n",
      "****************************\n",
      "Epoch: 3667\n",
      "train_loss = 87.5910\n",
      "test_loss = 74.8952\n",
      "****************************\n",
      "Epoch: 3668\n",
      "train_loss = 87.6575\n",
      "test_loss = 76.4700\n",
      "****************************\n",
      "Epoch: 3669\n",
      "train_loss = 87.7461\n",
      "test_loss = 74.6002\n",
      "****************************\n",
      "Epoch: 3670\n",
      "train_loss = 87.5059\n",
      "test_loss = 75.6423\n",
      "****************************\n",
      "Epoch: 3671\n",
      "train_loss = 87.6738\n",
      "test_loss = 76.5128\n",
      "****************************\n",
      "Epoch: 3672\n",
      "train_loss = 87.5614\n",
      "test_loss = 75.9258\n",
      "****************************\n",
      "Epoch: 3673\n",
      "train_loss = 87.8633\n",
      "test_loss = 74.4227\n",
      "****************************\n",
      "Epoch: 3674\n",
      "train_loss = 87.4593\n",
      "test_loss = 75.2401\n",
      "****************************\n",
      "Epoch: 3675\n",
      "train_loss = 87.4792\n",
      "test_loss = 75.4442\n",
      "****************************\n",
      "Epoch: 3676\n",
      "train_loss = 87.6281\n",
      "test_loss = 76.4791\n",
      "****************************\n",
      "Epoch: 3677\n",
      "train_loss = 87.6261\n",
      "test_loss = 76.4744\n",
      "****************************\n",
      "Epoch: 3678\n",
      "train_loss = 88.5606\n",
      "test_loss = 78.5139\n",
      "****************************\n",
      "Epoch: 3679\n",
      "train_loss = 87.5511\n",
      "test_loss = 75.9894\n",
      "****************************\n",
      "Epoch: 3680\n",
      "train_loss = 87.7663\n",
      "test_loss = 74.6228\n",
      "****************************\n",
      "Epoch: 3681\n",
      "train_loss = 87.5501\n",
      "test_loss = 76.0804\n",
      "****************************\n",
      "Epoch: 3682\n",
      "train_loss = 88.2448\n",
      "test_loss = 77.9576\n",
      "****************************\n",
      "Epoch: 3683\n",
      "train_loss = 88.6890\n",
      "test_loss = 74.1805\n",
      "****************************\n",
      "Epoch: 3684\n",
      "train_loss = 87.7633\n",
      "test_loss = 76.9288\n",
      "****************************\n",
      "Epoch: 3685\n",
      "train_loss = 88.0197\n",
      "test_loss = 77.5518\n",
      "****************************\n",
      "Epoch: 3686\n",
      "train_loss = 87.4615\n",
      "test_loss = 75.3676\n",
      "****************************\n",
      "Epoch: 3687\n",
      "train_loss = 87.5624\n",
      "test_loss = 74.8327\n",
      "****************************\n",
      "Epoch: 3688\n",
      "train_loss = 87.7918\n",
      "test_loss = 74.4821\n",
      "****************************\n",
      "Epoch: 3689\n",
      "train_loss = 87.5664\n",
      "test_loss = 76.1740\n",
      "****************************\n",
      "Epoch: 3690\n",
      "train_loss = 87.7172\n",
      "test_loss = 74.6246\n",
      "****************************\n",
      "Epoch: 3691\n",
      "train_loss = 88.1612\n",
      "test_loss = 77.8251\n",
      "****************************\n",
      "Epoch: 3692\n",
      "train_loss = 89.6786\n",
      "test_loss = 80.4559\n",
      "****************************\n",
      "Epoch: 3693\n",
      "train_loss = 88.4534\n",
      "test_loss = 78.3702\n",
      "****************************\n",
      "Epoch: 3694\n",
      "train_loss = 88.0989\n",
      "test_loss = 74.3025\n",
      "****************************\n",
      "Epoch: 3695\n",
      "train_loss = 87.4964\n",
      "test_loss = 75.9071\n",
      "****************************\n",
      "Epoch: 3696\n",
      "train_loss = 87.9142\n",
      "test_loss = 77.1889\n",
      "****************************\n",
      "Epoch: 3697\n",
      "train_loss = 87.4627\n",
      "test_loss = 75.3069\n",
      "****************************\n",
      "Epoch: 3698\n",
      "train_loss = 87.5531\n",
      "test_loss = 76.1484\n",
      "****************************\n",
      "Epoch: 3699\n",
      "train_loss = 87.9354\n",
      "test_loss = 74.4054\n",
      "****************************\n",
      "Epoch: 3700\n",
      "train_loss = 87.8974\n",
      "test_loss = 74.3998\n",
      "****************************\n",
      "Epoch: 3701\n",
      "train_loss = 88.4010\n",
      "test_loss = 78.1542\n",
      "****************************\n",
      "Epoch: 3702\n",
      "train_loss = 87.5452\n",
      "test_loss = 74.8382\n",
      "****************************\n",
      "Epoch: 3703\n",
      "train_loss = 89.0167\n",
      "test_loss = 79.3214\n",
      "****************************\n",
      "Epoch: 3704\n",
      "train_loss = 87.7844\n",
      "test_loss = 76.9092\n",
      "****************************\n",
      "Epoch: 3705\n",
      "train_loss = 87.4649\n",
      "test_loss = 75.2695\n",
      "****************************\n",
      "Epoch: 3706\n",
      "train_loss = 87.7964\n",
      "test_loss = 74.4430\n",
      "****************************\n",
      "Epoch: 3707\n",
      "train_loss = 87.5068\n",
      "test_loss = 76.1102\n",
      "****************************\n",
      "Epoch: 3708\n",
      "train_loss = 87.5858\n",
      "test_loss = 76.3739\n",
      "****************************\n",
      "Epoch: 3709\n",
      "train_loss = 87.4963\n",
      "test_loss = 76.0377\n",
      "****************************\n",
      "Epoch: 3710\n",
      "train_loss = 87.6742\n",
      "test_loss = 76.3786\n",
      "****************************\n",
      "Epoch: 3711\n",
      "train_loss = 87.5371\n",
      "test_loss = 75.0408\n",
      "****************************\n",
      "Epoch: 3712\n",
      "train_loss = 87.5359\n",
      "test_loss = 75.4181\n",
      "****************************\n",
      "Epoch: 3713\n",
      "train_loss = 87.5934\n",
      "test_loss = 74.9427\n",
      "****************************\n",
      "Epoch: 3714\n",
      "train_loss = 87.4927\n",
      "test_loss = 75.2301\n",
      "****************************\n",
      "Epoch: 3715\n",
      "train_loss = 87.4879\n",
      "test_loss = 75.3098\n",
      "****************************\n",
      "Epoch: 3716\n",
      "train_loss = 87.4644\n",
      "test_loss = 75.3524\n",
      "****************************\n",
      "Epoch: 3717\n",
      "train_loss = 88.0144\n",
      "test_loss = 77.5120\n",
      "****************************\n",
      "Epoch: 3718\n",
      "train_loss = 87.4864\n",
      "test_loss = 75.6653\n",
      "****************************\n",
      "Epoch: 3719\n",
      "train_loss = 87.4684\n",
      "test_loss = 75.5329\n",
      "****************************\n",
      "Epoch: 3720\n",
      "train_loss = 87.5240\n",
      "test_loss = 74.9736\n",
      "****************************\n",
      "Epoch: 3721\n",
      "train_loss = 87.9043\n",
      "test_loss = 74.3979\n",
      "****************************\n",
      "Epoch: 3722\n",
      "train_loss = 87.4623\n",
      "test_loss = 75.5145\n",
      "****************************\n",
      "Epoch: 3723\n",
      "train_loss = 87.5301\n",
      "test_loss = 74.9168\n",
      "****************************\n",
      "Epoch: 3724\n",
      "train_loss = 87.8040\n",
      "test_loss = 76.9390\n",
      "****************************\n",
      "Epoch: 3725\n",
      "train_loss = 87.5343\n",
      "test_loss = 75.4343\n",
      "****************************\n",
      "Epoch: 3726\n",
      "train_loss = 87.7490\n",
      "test_loss = 74.5745\n",
      "****************************\n",
      "Epoch: 3727\n",
      "train_loss = 87.9485\n",
      "test_loss = 77.0149\n",
      "****************************\n",
      "Epoch: 3728\n",
      "train_loss = 87.5195\n",
      "test_loss = 75.0167\n",
      "****************************\n",
      "Epoch: 3729\n",
      "train_loss = 87.8399\n",
      "test_loss = 74.4535\n",
      "****************************\n",
      "Epoch: 3730\n",
      "train_loss = 87.4843\n",
      "test_loss = 75.5953\n",
      "****************************\n",
      "Epoch: 3731\n",
      "train_loss = 88.2976\n",
      "test_loss = 77.9486\n",
      "****************************\n",
      "Epoch: 3732\n",
      "train_loss = 88.1202\n",
      "test_loss = 77.6557\n",
      "****************************\n",
      "Epoch: 3733\n",
      "train_loss = 87.5759\n",
      "test_loss = 74.9430\n",
      "****************************\n",
      "Epoch: 3734\n",
      "train_loss = 87.5009\n",
      "test_loss = 75.1038\n",
      "****************************\n",
      "Epoch: 3735\n",
      "train_loss = 87.5437\n",
      "test_loss = 76.0488\n",
      "****************************\n",
      "Epoch: 3736\n",
      "train_loss = 87.4624\n",
      "test_loss = 75.2477\n",
      "****************************\n",
      "Epoch: 3737\n",
      "train_loss = 87.8018\n",
      "test_loss = 77.0723\n",
      "****************************\n",
      "Epoch: 3738\n",
      "train_loss = 87.7317\n",
      "test_loss = 74.6073\n",
      "****************************\n",
      "Epoch: 3739\n",
      "train_loss = 87.9596\n",
      "test_loss = 77.2723\n",
      "****************************\n",
      "Epoch: 3740\n",
      "train_loss = 87.5024\n",
      "test_loss = 75.7305\n",
      "****************************\n",
      "Epoch: 3741\n",
      "train_loss = 88.0207\n",
      "test_loss = 77.4669\n",
      "****************************\n",
      "Epoch: 3742\n",
      "train_loss = 87.5347\n",
      "test_loss = 75.9987\n",
      "****************************\n",
      "Epoch: 3743\n",
      "train_loss = 87.4856\n",
      "test_loss = 75.7752\n",
      "****************************\n",
      "Epoch: 3744\n",
      "train_loss = 87.7529\n",
      "test_loss = 74.5051\n",
      "****************************\n",
      "Epoch: 3745\n",
      "train_loss = 87.5225\n",
      "test_loss = 75.0936\n",
      "****************************\n",
      "Epoch: 3746\n",
      "train_loss = 87.4768\n",
      "test_loss = 75.6906\n",
      "****************************\n",
      "Epoch: 3747\n",
      "train_loss = 88.1409\n",
      "test_loss = 77.7924\n",
      "****************************\n",
      "Epoch: 3748\n",
      "train_loss = 87.6591\n",
      "test_loss = 76.3826\n",
      "****************************\n",
      "Epoch: 3749\n",
      "train_loss = 87.4776\n",
      "test_loss = 75.6123\n",
      "****************************\n",
      "Epoch: 3750\n",
      "train_loss = 87.4684\n",
      "test_loss = 75.4224\n",
      "****************************\n",
      "Epoch: 3751\n",
      "train_loss = 87.9161\n",
      "test_loss = 77.4102\n",
      "****************************\n",
      "Epoch: 3752\n",
      "train_loss = 87.8440\n",
      "test_loss = 77.2508\n",
      "****************************\n",
      "Epoch: 3753\n",
      "train_loss = 87.4679\n",
      "test_loss = 75.1750\n",
      "****************************\n",
      "Epoch: 3754\n",
      "train_loss = 87.4481\n",
      "test_loss = 75.4487\n",
      "****************************\n",
      "Epoch: 3755\n",
      "train_loss = 87.5489\n",
      "test_loss = 76.3192\n",
      "****************************\n",
      "Epoch: 3756\n",
      "train_loss = 87.4718\n",
      "test_loss = 75.2089\n",
      "****************************\n",
      "Epoch: 3757\n",
      "train_loss = 87.8537\n",
      "test_loss = 74.3658\n",
      "****************************\n",
      "Epoch: 3758\n",
      "train_loss = 87.5339\n",
      "test_loss = 74.7753\n",
      "****************************\n",
      "Epoch: 3759\n",
      "train_loss = 87.5616\n",
      "test_loss = 74.8647\n",
      "****************************\n",
      "Epoch: 3760\n",
      "train_loss = 87.7523\n",
      "test_loss = 74.4875\n",
      "****************************\n",
      "Epoch: 3761\n",
      "train_loss = 87.4557\n",
      "test_loss = 75.6981\n",
      "****************************\n",
      "Epoch: 3762\n",
      "train_loss = 87.4593\n",
      "test_loss = 75.3178\n",
      "****************************\n",
      "Epoch: 3763\n",
      "train_loss = 87.4510\n",
      "test_loss = 75.3460\n",
      "****************************\n",
      "Epoch: 3764\n",
      "train_loss = 88.7150\n",
      "test_loss = 74.4945\n",
      "****************************\n",
      "Epoch: 3765\n",
      "train_loss = 87.6606\n",
      "test_loss = 74.7366\n",
      "****************************\n",
      "Epoch: 3766\n",
      "train_loss = 87.5203\n",
      "test_loss = 75.7795\n",
      "****************************\n",
      "Epoch: 3767\n",
      "train_loss = 88.2967\n",
      "test_loss = 78.0800\n",
      "****************************\n",
      "Epoch: 3768\n",
      "train_loss = 87.6282\n",
      "test_loss = 74.7464\n",
      "****************************\n",
      "Epoch: 3769\n",
      "train_loss = 88.0191\n",
      "test_loss = 77.4560\n",
      "****************************\n",
      "Epoch: 3770\n",
      "train_loss = 87.7376\n",
      "test_loss = 74.5546\n",
      "****************************\n",
      "Epoch: 3771\n",
      "train_loss = 87.5131\n",
      "test_loss = 75.8970\n",
      "****************************\n",
      "Epoch: 3772\n",
      "train_loss = 87.5032\n",
      "test_loss = 74.9704\n",
      "****************************\n",
      "Epoch: 3773\n",
      "train_loss = 87.4651\n",
      "test_loss = 75.3874\n",
      "****************************\n",
      "Epoch: 3774\n",
      "train_loss = 88.4281\n",
      "test_loss = 74.1413\n",
      "****************************\n",
      "Epoch: 3775\n",
      "train_loss = 87.7245\n",
      "test_loss = 74.4825\n",
      "****************************\n",
      "Epoch: 3776\n",
      "train_loss = 87.6472\n",
      "test_loss = 74.5935\n",
      "****************************\n",
      "Epoch: 3777\n",
      "train_loss = 87.5387\n",
      "test_loss = 74.7742\n",
      "****************************\n",
      "Epoch: 3778\n",
      "train_loss = 87.6179\n",
      "test_loss = 74.6409\n",
      "****************************\n",
      "Epoch: 3779\n",
      "train_loss = 87.6075\n",
      "test_loss = 74.6926\n",
      "****************************\n",
      "Epoch: 3780\n",
      "train_loss = 87.4886\n",
      "test_loss = 74.9765\n",
      "****************************\n",
      "Epoch: 3781\n",
      "train_loss = 87.6195\n",
      "test_loss = 74.6174\n",
      "****************************\n",
      "Epoch: 3782\n",
      "train_loss = 88.0327\n",
      "test_loss = 74.2527\n",
      "****************************\n",
      "Epoch: 3783\n",
      "train_loss = 87.4745\n",
      "test_loss = 75.6794\n",
      "****************************\n",
      "Epoch: 3784\n",
      "train_loss = 87.5718\n",
      "test_loss = 76.0889\n",
      "****************************\n",
      "Epoch: 3785\n",
      "train_loss = 87.4928\n",
      "test_loss = 75.6749\n",
      "****************************\n",
      "Epoch: 3786\n",
      "train_loss = 87.4824\n",
      "test_loss = 75.7206\n",
      "****************************\n",
      "Epoch: 3787\n",
      "train_loss = 88.6733\n",
      "test_loss = 78.7809\n",
      "****************************\n",
      "Epoch: 3788\n",
      "train_loss = 87.5113\n",
      "test_loss = 74.9132\n",
      "****************************\n",
      "Epoch: 3789\n",
      "train_loss = 87.5612\n",
      "test_loss = 74.8126\n",
      "****************************\n",
      "Epoch: 3790\n",
      "train_loss = 87.5913\n",
      "test_loss = 76.2549\n",
      "****************************\n",
      "Epoch: 3791\n",
      "train_loss = 87.4952\n",
      "test_loss = 74.9885\n",
      "****************************\n",
      "Epoch: 3792\n",
      "train_loss = 87.7858\n",
      "test_loss = 74.4913\n",
      "****************************\n",
      "Epoch: 3793\n",
      "train_loss = 87.4900\n",
      "test_loss = 75.3643\n",
      "****************************\n",
      "Epoch: 3794\n",
      "train_loss = 87.6003\n",
      "test_loss = 74.7684\n",
      "****************************\n",
      "Epoch: 3795\n",
      "train_loss = 87.8198\n",
      "test_loss = 77.0113\n",
      "****************************\n",
      "Epoch: 3796\n",
      "train_loss = 87.7318\n",
      "test_loss = 76.8395\n",
      "****************************\n",
      "Epoch: 3797\n",
      "train_loss = 87.7053\n",
      "test_loss = 74.5295\n",
      "****************************\n",
      "Epoch: 3798\n",
      "train_loss = 87.7417\n",
      "test_loss = 76.8190\n",
      "****************************\n",
      "Epoch: 3799\n",
      "train_loss = 87.5282\n",
      "test_loss = 74.8267\n",
      "****************************\n",
      "Epoch: 3800\n",
      "train_loss = 87.9024\n",
      "test_loss = 77.1732\n",
      "****************************\n",
      "Epoch: 3801\n",
      "train_loss = 87.4583\n",
      "test_loss = 75.6080\n",
      "****************************\n",
      "Epoch: 3802\n",
      "train_loss = 87.5703\n",
      "test_loss = 74.8688\n",
      "****************************\n",
      "Epoch: 3803\n",
      "train_loss = 87.4848\n",
      "test_loss = 75.1429\n",
      "****************************\n",
      "Epoch: 3804\n",
      "train_loss = 87.5116\n",
      "test_loss = 75.0791\n",
      "****************************\n",
      "Epoch: 3805\n",
      "train_loss = 87.4577\n",
      "test_loss = 75.7485\n",
      "****************************\n",
      "Epoch: 3806\n",
      "train_loss = 87.5881\n",
      "test_loss = 76.3655\n",
      "****************************\n",
      "Epoch: 3807\n",
      "train_loss = 87.5643\n",
      "test_loss = 74.8493\n",
      "****************************\n",
      "Epoch: 3808\n",
      "train_loss = 87.4551\n",
      "test_loss = 75.2007\n",
      "****************************\n",
      "Epoch: 3809\n",
      "train_loss = 87.8035\n",
      "test_loss = 77.0537\n",
      "****************************\n",
      "Epoch: 3810\n",
      "train_loss = 87.5859\n",
      "test_loss = 74.7148\n",
      "****************************\n",
      "Epoch: 3811\n",
      "train_loss = 88.3805\n",
      "test_loss = 78.1862\n",
      "****************************\n",
      "Epoch: 3812\n",
      "train_loss = 87.4909\n",
      "test_loss = 75.8610\n",
      "****************************\n",
      "Epoch: 3813\n",
      "train_loss = 87.4729\n",
      "test_loss = 75.9109\n",
      "****************************\n",
      "Epoch: 3814\n",
      "train_loss = 87.5272\n",
      "test_loss = 74.8970\n",
      "****************************\n",
      "Epoch: 3815\n",
      "train_loss = 87.5979\n",
      "test_loss = 76.3499\n",
      "****************************\n",
      "Epoch: 3816\n",
      "train_loss = 87.5746\n",
      "test_loss = 74.7808\n",
      "****************************\n",
      "Epoch: 3817\n",
      "train_loss = 87.5136\n",
      "test_loss = 74.9328\n",
      "****************************\n",
      "Epoch: 3818\n",
      "train_loss = 87.4557\n",
      "test_loss = 75.5046\n",
      "****************************\n",
      "Epoch: 3819\n",
      "train_loss = 87.6576\n",
      "test_loss = 74.6936\n",
      "****************************\n",
      "Epoch: 3820\n",
      "train_loss = 90.0713\n",
      "test_loss = 81.1168\n",
      "****************************\n",
      "Epoch: 3821\n",
      "train_loss = 87.7101\n",
      "test_loss = 76.6897\n",
      "****************************\n",
      "Epoch: 3822\n",
      "train_loss = 87.6961\n",
      "test_loss = 76.5535\n",
      "****************************\n",
      "Epoch: 3823\n",
      "train_loss = 87.5175\n",
      "test_loss = 75.5392\n",
      "****************************\n",
      "Epoch: 3824\n",
      "train_loss = 87.6244\n",
      "test_loss = 76.3935\n",
      "****************************\n",
      "Epoch: 3825\n",
      "train_loss = 89.6186\n",
      "test_loss = 74.7404\n",
      "****************************\n",
      "Epoch: 3826\n",
      "train_loss = 87.6262\n",
      "test_loss = 76.1827\n",
      "****************************\n",
      "Epoch: 3827\n",
      "train_loss = 87.5988\n",
      "test_loss = 76.1902\n",
      "****************************\n",
      "Epoch: 3828\n",
      "train_loss = 87.5094\n",
      "test_loss = 75.5822\n",
      "****************************\n",
      "Epoch: 3829\n",
      "train_loss = 87.9078\n",
      "test_loss = 74.4888\n",
      "****************************\n",
      "Epoch: 3830\n",
      "train_loss = 87.8619\n",
      "test_loss = 74.4752\n",
      "****************************\n",
      "Epoch: 3831\n",
      "train_loss = 87.5041\n",
      "test_loss = 75.9046\n",
      "****************************\n",
      "Epoch: 3832\n",
      "train_loss = 87.5176\n",
      "test_loss = 76.0138\n",
      "****************************\n",
      "Epoch: 3833\n",
      "train_loss = 88.1348\n",
      "test_loss = 74.3159\n",
      "****************************\n",
      "Epoch: 3834\n",
      "train_loss = 87.5581\n",
      "test_loss = 76.0389\n",
      "****************************\n",
      "Epoch: 3835\n",
      "train_loss = 87.5577\n",
      "test_loss = 74.8830\n",
      "****************************\n",
      "Epoch: 3836\n",
      "train_loss = 87.4919\n",
      "test_loss = 75.1501\n",
      "****************************\n",
      "Epoch: 3837\n",
      "train_loss = 88.5233\n",
      "test_loss = 74.1708\n",
      "****************************\n",
      "Epoch: 3838\n",
      "train_loss = 88.0318\n",
      "test_loss = 77.6366\n",
      "****************************\n",
      "Epoch: 3839\n",
      "train_loss = 87.4649\n",
      "test_loss = 75.1960\n",
      "****************************\n",
      "Epoch: 3840\n",
      "train_loss = 87.5258\n",
      "test_loss = 75.0003\n",
      "****************************\n",
      "Epoch: 3841\n",
      "train_loss = 87.4671\n",
      "test_loss = 75.5437\n",
      "****************************\n",
      "Epoch: 3842\n",
      "train_loss = 87.4305\n",
      "test_loss = 75.4366\n",
      "****************************\n",
      "Epoch: 3843\n",
      "train_loss = 87.4564\n",
      "test_loss = 75.3881\n",
      "****************************\n",
      "Epoch: 3844\n",
      "train_loss = 87.8679\n",
      "test_loss = 74.4162\n",
      "****************************\n",
      "Epoch: 3845\n",
      "train_loss = 87.5854\n",
      "test_loss = 76.0102\n",
      "****************************\n",
      "Epoch: 3846\n",
      "train_loss = 87.7181\n",
      "test_loss = 76.6740\n",
      "****************************\n",
      "Epoch: 3847\n",
      "train_loss = 87.5041\n",
      "test_loss = 75.0715\n",
      "****************************\n",
      "Epoch: 3848\n",
      "train_loss = 87.7329\n",
      "test_loss = 74.5479\n",
      "****************************\n",
      "Epoch: 3849\n",
      "train_loss = 87.5891\n",
      "test_loss = 76.3789\n",
      "****************************\n",
      "Epoch: 3850\n",
      "train_loss = 87.5700\n",
      "test_loss = 74.8497\n",
      "****************************\n",
      "Epoch: 3851\n",
      "train_loss = 87.6002\n",
      "test_loss = 74.7407\n",
      "****************************\n",
      "Epoch: 3852\n",
      "train_loss = 87.8243\n",
      "test_loss = 74.4696\n",
      "****************************\n",
      "Epoch: 3853\n",
      "train_loss = 87.8013\n",
      "test_loss = 76.9898\n",
      "****************************\n",
      "Epoch: 3854\n",
      "train_loss = 87.6548\n",
      "test_loss = 76.5618\n",
      "****************************\n",
      "Epoch: 3855\n",
      "train_loss = 87.8274\n",
      "test_loss = 77.0287\n",
      "****************************\n",
      "Epoch: 3856\n",
      "train_loss = 87.5383\n",
      "test_loss = 75.0548\n",
      "****************************\n",
      "Epoch: 3857\n",
      "train_loss = 87.4833\n",
      "test_loss = 75.7169\n",
      "****************************\n",
      "Epoch: 3858\n",
      "train_loss = 87.7118\n",
      "test_loss = 74.6609\n",
      "****************************\n",
      "Epoch: 3859\n",
      "train_loss = 87.5398\n",
      "test_loss = 75.1150\n",
      "****************************\n",
      "Epoch: 3860\n",
      "train_loss = 87.4946\n",
      "test_loss = 75.4518\n",
      "****************************\n",
      "Epoch: 3861\n",
      "train_loss = 87.5647\n",
      "test_loss = 74.9776\n",
      "****************************\n",
      "Epoch: 3862\n",
      "train_loss = 87.7429\n",
      "test_loss = 76.6882\n",
      "****************************\n",
      "Epoch: 3863\n",
      "train_loss = 87.5463\n",
      "test_loss = 74.9671\n",
      "****************************\n",
      "Epoch: 3864\n",
      "train_loss = 87.7260\n",
      "test_loss = 76.5783\n",
      "****************************\n",
      "Epoch: 3865\n",
      "train_loss = 88.2098\n",
      "test_loss = 74.2582\n",
      "****************************\n",
      "Epoch: 3866\n",
      "train_loss = 87.5595\n",
      "test_loss = 74.8995\n",
      "****************************\n",
      "Epoch: 3867\n",
      "train_loss = 87.5096\n",
      "test_loss = 75.0606\n",
      "****************************\n",
      "Epoch: 3868\n",
      "train_loss = 87.6593\n",
      "test_loss = 76.6004\n",
      "****************************\n",
      "Epoch: 3869\n",
      "train_loss = 87.4957\n",
      "test_loss = 74.9913\n",
      "****************************\n",
      "Epoch: 3870\n",
      "train_loss = 87.9347\n",
      "test_loss = 77.4333\n",
      "****************************\n",
      "Epoch: 3871\n",
      "train_loss = 87.5235\n",
      "test_loss = 74.8992\n",
      "****************************\n",
      "Epoch: 3872\n",
      "train_loss = 87.4926\n",
      "test_loss = 76.0982\n",
      "****************************\n",
      "Epoch: 3873\n",
      "train_loss = 87.4490\n",
      "test_loss = 75.5844\n",
      "****************************\n",
      "Epoch: 3874\n",
      "train_loss = 87.4528\n",
      "test_loss = 75.1470\n",
      "****************************\n",
      "Epoch: 3875\n",
      "train_loss = 88.0247\n",
      "test_loss = 77.4541\n",
      "****************************\n",
      "Epoch: 3876\n",
      "train_loss = 87.9575\n",
      "test_loss = 74.3459\n",
      "****************************\n",
      "Epoch: 3877\n",
      "train_loss = 87.5377\n",
      "test_loss = 74.9821\n",
      "****************************\n",
      "Epoch: 3878\n",
      "train_loss = 87.6209\n",
      "test_loss = 74.8612\n",
      "****************************\n",
      "Epoch: 3879\n",
      "train_loss = 87.7099\n",
      "test_loss = 74.6892\n",
      "****************************\n",
      "Epoch: 3880\n",
      "train_loss = 87.6425\n",
      "test_loss = 74.7625\n",
      "****************************\n",
      "Epoch: 3881\n",
      "train_loss = 87.5189\n",
      "test_loss = 75.1094\n",
      "****************************\n",
      "Epoch: 3882\n",
      "train_loss = 87.6003\n",
      "test_loss = 76.2890\n",
      "****************************\n",
      "Epoch: 3883\n",
      "train_loss = 87.6602\n",
      "test_loss = 76.6820\n",
      "****************************\n",
      "Epoch: 3884\n",
      "train_loss = 87.4774\n",
      "test_loss = 75.2006\n",
      "****************************\n",
      "Epoch: 3885\n",
      "train_loss = 87.8570\n",
      "test_loss = 77.1533\n",
      "****************************\n",
      "Epoch: 3886\n",
      "train_loss = 89.3426\n",
      "test_loss = 80.0752\n",
      "****************************\n",
      "Epoch: 3887\n",
      "train_loss = 88.0097\n",
      "test_loss = 74.4893\n",
      "****************************\n",
      "Epoch: 3888\n",
      "train_loss = 87.6543\n",
      "test_loss = 76.4051\n",
      "****************************\n",
      "Epoch: 3889\n",
      "train_loss = 87.7211\n",
      "test_loss = 74.5912\n",
      "****************************\n",
      "Epoch: 3890\n",
      "train_loss = 87.5218\n",
      "test_loss = 75.0312\n",
      "****************************\n",
      "Epoch: 3891\n",
      "train_loss = 87.4759\n",
      "test_loss = 75.6748\n",
      "****************************\n",
      "Epoch: 3892\n",
      "train_loss = 87.4755\n",
      "test_loss = 75.0906\n",
      "****************************\n",
      "Epoch: 3893\n",
      "train_loss = 88.6456\n",
      "test_loss = 74.1189\n",
      "****************************\n",
      "Epoch: 3894\n",
      "train_loss = 87.6345\n",
      "test_loss = 76.3673\n",
      "****************************\n",
      "Epoch: 3895\n",
      "train_loss = 87.5128\n",
      "test_loss = 76.0632\n",
      "****************************\n",
      "Epoch: 3896\n",
      "train_loss = 87.8578\n",
      "test_loss = 76.8769\n",
      "****************************\n",
      "Epoch: 3897\n",
      "train_loss = 87.5125\n",
      "test_loss = 75.1208\n",
      "****************************\n",
      "Epoch: 3898\n",
      "train_loss = 87.5769\n",
      "test_loss = 74.8644\n",
      "****************************\n",
      "Epoch: 3899\n",
      "train_loss = 88.3606\n",
      "test_loss = 74.2077\n",
      "****************************\n",
      "Epoch: 3900\n",
      "train_loss = 87.7264\n",
      "test_loss = 76.6531\n",
      "****************************\n",
      "Epoch: 3901\n",
      "train_loss = 88.4619\n",
      "test_loss = 78.2300\n",
      "****************************\n",
      "Epoch: 3902\n",
      "train_loss = 87.6892\n",
      "test_loss = 74.7263\n",
      "****************************\n",
      "Epoch: 3903\n",
      "train_loss = 87.8943\n",
      "test_loss = 77.1937\n",
      "****************************\n",
      "Epoch: 3904\n",
      "train_loss = 87.5330\n",
      "test_loss = 76.0191\n",
      "****************************\n",
      "Epoch: 3905\n",
      "train_loss = 87.5323\n",
      "test_loss = 75.1960\n",
      "****************************\n",
      "Epoch: 3906\n",
      "train_loss = 87.6398\n",
      "test_loss = 76.4562\n",
      "****************************\n",
      "Epoch: 3907\n",
      "train_loss = 87.5905\n",
      "test_loss = 76.0687\n",
      "****************************\n",
      "Epoch: 3908\n",
      "train_loss = 87.8213\n",
      "test_loss = 76.9580\n",
      "****************************\n",
      "Epoch: 3909\n",
      "train_loss = 87.4727\n",
      "test_loss = 75.5872\n",
      "****************************\n",
      "Epoch: 3910\n",
      "train_loss = 88.1719\n",
      "test_loss = 74.2579\n",
      "****************************\n",
      "Epoch: 3911\n",
      "train_loss = 87.5389\n",
      "test_loss = 75.9007\n",
      "****************************\n",
      "Epoch: 3912\n",
      "train_loss = 87.5592\n",
      "test_loss = 76.0076\n",
      "****************************\n",
      "Epoch: 3913\n",
      "train_loss = 87.5397\n",
      "test_loss = 74.9000\n",
      "****************************\n",
      "Epoch: 3914\n",
      "train_loss = 87.5661\n",
      "test_loss = 74.8006\n",
      "****************************\n",
      "Epoch: 3915\n",
      "train_loss = 88.2106\n",
      "test_loss = 77.8180\n",
      "****************************\n",
      "Epoch: 3916\n",
      "train_loss = 87.4912\n",
      "test_loss = 75.6274\n",
      "****************************\n",
      "Epoch: 3917\n",
      "train_loss = 87.4894\n",
      "test_loss = 75.3057\n",
      "****************************\n",
      "Epoch: 3918\n",
      "train_loss = 88.4673\n",
      "test_loss = 74.1896\n",
      "****************************\n",
      "Epoch: 3919\n",
      "train_loss = 87.5273\n",
      "test_loss = 75.1713\n",
      "****************************\n",
      "Epoch: 3920\n",
      "train_loss = 88.3503\n",
      "test_loss = 78.2028\n",
      "****************************\n",
      "Epoch: 3921\n",
      "train_loss = 87.5246\n",
      "test_loss = 75.7803\n",
      "****************************\n",
      "Epoch: 3922\n",
      "train_loss = 87.5479\n",
      "test_loss = 74.8714\n",
      "****************************\n",
      "Epoch: 3923\n",
      "train_loss = 88.5420\n",
      "test_loss = 78.4795\n",
      "****************************\n",
      "Epoch: 3924\n",
      "train_loss = 87.5348\n",
      "test_loss = 75.2034\n",
      "****************************\n",
      "Epoch: 3925\n",
      "train_loss = 87.7302\n",
      "test_loss = 74.5899\n",
      "****************************\n",
      "Epoch: 3926\n",
      "train_loss = 87.5201\n",
      "test_loss = 75.8115\n",
      "****************************\n",
      "Epoch: 3927\n",
      "train_loss = 88.3087\n",
      "test_loss = 78.2101\n",
      "****************************\n",
      "Epoch: 3928\n",
      "train_loss = 87.8906\n",
      "test_loss = 77.1664\n",
      "****************************\n",
      "Epoch: 3929\n",
      "train_loss = 87.9124\n",
      "test_loss = 77.2434\n",
      "****************************\n",
      "Epoch: 3930\n",
      "train_loss = 87.4753\n",
      "test_loss = 75.4611\n",
      "****************************\n",
      "Epoch: 3931\n",
      "train_loss = 87.4748\n",
      "test_loss = 75.3917\n",
      "****************************\n",
      "Epoch: 3932\n",
      "train_loss = 87.5726\n",
      "test_loss = 76.2420\n",
      "****************************\n",
      "Epoch: 3933\n",
      "train_loss = 90.4398\n",
      "test_loss = 81.6479\n",
      "****************************\n",
      "Epoch: 3934\n",
      "train_loss = 87.4969\n",
      "test_loss = 75.7194\n",
      "****************************\n",
      "Epoch: 3935\n",
      "train_loss = 88.0973\n",
      "test_loss = 77.7399\n",
      "****************************\n",
      "Epoch: 3936\n",
      "train_loss = 87.6902\n",
      "test_loss = 76.6472\n",
      "****************************\n",
      "Epoch: 3937\n",
      "train_loss = 87.4691\n",
      "test_loss = 75.2733\n",
      "****************************\n",
      "Epoch: 3938\n",
      "train_loss = 87.4535\n",
      "test_loss = 75.3896\n",
      "****************************\n",
      "Epoch: 3939\n",
      "train_loss = 87.5528\n",
      "test_loss = 76.2803\n",
      "****************************\n",
      "Epoch: 3940\n",
      "train_loss = 87.4636\n",
      "test_loss = 75.8847\n",
      "****************************\n",
      "Epoch: 3941\n",
      "train_loss = 87.6960\n",
      "test_loss = 74.5326\n",
      "****************************\n",
      "Epoch: 3942\n",
      "train_loss = 87.4355\n",
      "test_loss = 75.2085\n",
      "****************************\n",
      "Epoch: 3943\n",
      "train_loss = 88.7185\n",
      "test_loss = 79.0033\n",
      "****************************\n",
      "Epoch: 3944\n",
      "train_loss = 87.8923\n",
      "test_loss = 77.3185\n",
      "****************************\n",
      "Epoch: 3945\n",
      "train_loss = 88.2061\n",
      "test_loss = 74.2466\n",
      "****************************\n",
      "Epoch: 3946\n",
      "train_loss = 88.0245\n",
      "test_loss = 77.4790\n",
      "****************************\n",
      "Epoch: 3947\n",
      "train_loss = 87.4963\n",
      "test_loss = 75.6378\n",
      "****************************\n",
      "Epoch: 3948\n",
      "train_loss = 87.5113\n",
      "test_loss = 75.9864\n",
      "****************************\n",
      "Epoch: 3949\n",
      "train_loss = 87.7063\n",
      "test_loss = 74.6707\n",
      "****************************\n",
      "Epoch: 3950\n",
      "train_loss = 87.4788\n",
      "test_loss = 75.2868\n",
      "****************************\n",
      "Epoch: 3951\n",
      "train_loss = 87.9745\n",
      "test_loss = 74.3879\n",
      "****************************\n",
      "Epoch: 3952\n",
      "train_loss = 87.5156\n",
      "test_loss = 75.5829\n",
      "****************************\n",
      "Epoch: 3953\n",
      "train_loss = 87.5617\n",
      "test_loss = 76.0159\n",
      "****************************\n",
      "Epoch: 3954\n",
      "train_loss = 87.7143\n",
      "test_loss = 74.6749\n",
      "****************************\n",
      "Epoch: 3955\n",
      "train_loss = 87.6236\n",
      "test_loss = 74.7117\n",
      "****************************\n",
      "Epoch: 3956\n",
      "train_loss = 87.5307\n",
      "test_loss = 75.1656\n",
      "****************************\n",
      "Epoch: 3957\n",
      "train_loss = 88.0833\n",
      "test_loss = 77.5608\n",
      "****************************\n",
      "Epoch: 3958\n",
      "train_loss = 87.6419\n",
      "test_loss = 76.3900\n",
      "****************************\n",
      "Epoch: 3959\n",
      "train_loss = 87.5933\n",
      "test_loss = 74.8397\n",
      "****************************\n",
      "Epoch: 3960\n",
      "train_loss = 87.6321\n",
      "test_loss = 74.8121\n",
      "****************************\n",
      "Epoch: 3961\n",
      "train_loss = 87.7762\n",
      "test_loss = 76.9380\n",
      "****************************\n",
      "Epoch: 3962\n",
      "train_loss = 87.7545\n",
      "test_loss = 74.5596\n",
      "****************************\n",
      "Epoch: 3963\n",
      "train_loss = 87.6882\n",
      "test_loss = 74.6487\n",
      "****************************\n",
      "Epoch: 3964\n",
      "train_loss = 87.4930\n",
      "test_loss = 75.0942\n",
      "****************************\n",
      "Epoch: 3965\n",
      "train_loss = 87.7350\n",
      "test_loss = 74.5880\n",
      "****************************\n",
      "Epoch: 3966\n",
      "train_loss = 87.5203\n",
      "test_loss = 75.8631\n",
      "****************************\n",
      "Epoch: 3967\n",
      "train_loss = 87.9459\n",
      "test_loss = 77.2966\n",
      "****************************\n",
      "Epoch: 3968\n",
      "train_loss = 87.9886\n",
      "test_loss = 77.3579\n",
      "****************************\n",
      "Epoch: 3969\n",
      "train_loss = 87.5415\n",
      "test_loss = 75.7417\n",
      "****************************\n",
      "Epoch: 3970\n",
      "train_loss = 87.8820\n",
      "test_loss = 74.4050\n",
      "****************************\n",
      "Epoch: 3971\n",
      "train_loss = 87.6540\n",
      "test_loss = 74.6907\n",
      "****************************\n",
      "Epoch: 3972\n",
      "train_loss = 87.5212\n",
      "test_loss = 74.9308\n",
      "****************************\n",
      "Epoch: 3973\n",
      "train_loss = 87.6139\n",
      "test_loss = 74.7134\n",
      "****************************\n",
      "Epoch: 3974\n",
      "train_loss = 87.8753\n",
      "test_loss = 74.4049\n",
      "****************************\n",
      "Epoch: 3975\n",
      "train_loss = 87.4674\n",
      "test_loss = 75.2313\n",
      "****************************\n",
      "Epoch: 3976\n",
      "train_loss = 87.8694\n",
      "test_loss = 77.0591\n",
      "****************************\n",
      "Epoch: 3977\n",
      "train_loss = 87.8333\n",
      "test_loss = 76.9015\n",
      "****************************\n",
      "Epoch: 3978\n",
      "train_loss = 87.6595\n",
      "test_loss = 74.6547\n",
      "****************************\n",
      "Epoch: 3979\n",
      "train_loss = 87.5245\n",
      "test_loss = 74.9695\n",
      "****************************\n",
      "Epoch: 3980\n",
      "train_loss = 87.5074\n",
      "test_loss = 75.8113\n",
      "****************************\n",
      "Epoch: 3981\n",
      "train_loss = 87.4967\n",
      "test_loss = 74.9557\n",
      "****************************\n",
      "Epoch: 3982\n",
      "train_loss = 87.5501\n",
      "test_loss = 75.8371\n",
      "****************************\n",
      "Epoch: 3983\n",
      "train_loss = 88.4894\n",
      "test_loss = 78.4183\n",
      "****************************\n",
      "Epoch: 3984\n",
      "train_loss = 88.8886\n",
      "test_loss = 74.1740\n",
      "****************************\n",
      "Epoch: 3985\n",
      "train_loss = 87.5196\n",
      "test_loss = 75.0337\n",
      "****************************\n",
      "Epoch: 3986\n",
      "train_loss = 87.4916\n",
      "test_loss = 75.7589\n",
      "****************************\n",
      "Epoch: 3987\n",
      "train_loss = 87.6973\n",
      "test_loss = 74.6281\n",
      "****************************\n",
      "Epoch: 3988\n",
      "train_loss = 87.4697\n",
      "test_loss = 75.4731\n",
      "****************************\n",
      "Epoch: 3989\n",
      "train_loss = 87.5230\n",
      "test_loss = 76.1597\n",
      "****************************\n",
      "Epoch: 3990\n",
      "train_loss = 87.4718\n",
      "test_loss = 75.8724\n",
      "****************************\n",
      "Epoch: 3991\n",
      "train_loss = 87.6277\n",
      "test_loss = 76.4949\n",
      "****************************\n",
      "Epoch: 3992\n",
      "train_loss = 87.4738\n",
      "test_loss = 75.2063\n",
      "****************************\n",
      "Epoch: 3993\n",
      "train_loss = 87.9020\n",
      "test_loss = 77.0264\n",
      "****************************\n",
      "Epoch: 3994\n",
      "train_loss = 87.6638\n",
      "test_loss = 76.4348\n",
      "****************************\n",
      "Epoch: 3995\n",
      "train_loss = 87.8664\n",
      "test_loss = 77.1255\n",
      "****************************\n",
      "Epoch: 3996\n",
      "train_loss = 87.4579\n",
      "test_loss = 75.4377\n",
      "****************************\n",
      "Epoch: 3997\n",
      "train_loss = 87.5708\n",
      "test_loss = 76.1927\n",
      "****************************\n",
      "Epoch: 3998\n",
      "train_loss = 87.4731\n",
      "test_loss = 75.0627\n",
      "****************************\n",
      "Epoch: 3999\n",
      "train_loss = 89.2974\n",
      "test_loss = 80.1175\n",
      "****************************\n",
      "Epoch: 4000\n",
      "train_loss = 87.4796\n",
      "test_loss = 75.3326\n",
      "****************************\n",
      "Epoch: 4001\n",
      "train_loss = 87.4644\n",
      "test_loss = 75.4474\n",
      "****************************\n",
      "Epoch: 4002\n",
      "train_loss = 87.5104\n",
      "test_loss = 74.9887\n",
      "****************************\n",
      "Epoch: 4003\n",
      "train_loss = 87.4618\n",
      "test_loss = 75.7688\n",
      "****************************\n",
      "Epoch: 4004\n",
      "train_loss = 87.5739\n",
      "test_loss = 76.3834\n",
      "****************************\n",
      "Epoch: 4005\n",
      "train_loss = 87.6706\n",
      "test_loss = 74.6057\n",
      "****************************\n",
      "Epoch: 4006\n",
      "train_loss = 87.6310\n",
      "test_loss = 76.3095\n",
      "****************************\n",
      "Epoch: 4007\n",
      "train_loss = 87.4594\n",
      "test_loss = 75.5588\n",
      "****************************\n",
      "Epoch: 4008\n",
      "train_loss = 87.5167\n",
      "test_loss = 76.1713\n",
      "****************************\n",
      "Epoch: 4009\n",
      "train_loss = 87.4607\n",
      "test_loss = 75.1811\n",
      "****************************\n",
      "Epoch: 4010\n",
      "train_loss = 87.9710\n",
      "test_loss = 74.3586\n",
      "****************************\n",
      "Epoch: 4011\n",
      "train_loss = 87.4685\n",
      "test_loss = 75.5567\n",
      "****************************\n",
      "Epoch: 4012\n",
      "train_loss = 87.6941\n",
      "test_loss = 74.5601\n",
      "****************************\n",
      "Epoch: 4013\n",
      "train_loss = 87.4514\n",
      "test_loss = 75.2671\n",
      "****************************\n",
      "Epoch: 4014\n",
      "train_loss = 87.4536\n",
      "test_loss = 75.5768\n",
      "****************************\n",
      "Epoch: 4015\n",
      "train_loss = 87.4818\n",
      "test_loss = 75.6734\n",
      "****************************\n",
      "Epoch: 4016\n",
      "train_loss = 87.5644\n",
      "test_loss = 74.7927\n",
      "****************************\n",
      "Epoch: 4017\n",
      "train_loss = 87.4481\n",
      "test_loss = 75.1979\n",
      "****************************\n",
      "Epoch: 4018\n",
      "train_loss = 87.4609\n",
      "test_loss = 75.2658\n",
      "****************************\n",
      "Epoch: 4019\n",
      "train_loss = 88.4376\n",
      "test_loss = 78.3844\n",
      "****************************\n",
      "Epoch: 4020\n",
      "train_loss = 87.6202\n",
      "test_loss = 74.6763\n",
      "****************************\n",
      "Epoch: 4021\n",
      "train_loss = 87.4735\n",
      "test_loss = 75.2876\n",
      "****************************\n",
      "Epoch: 4022\n",
      "train_loss = 87.5341\n",
      "test_loss = 74.9312\n",
      "****************************\n",
      "Epoch: 4023\n",
      "train_loss = 87.4950\n",
      "test_loss = 76.0445\n",
      "****************************\n",
      "Epoch: 4024\n",
      "train_loss = 87.4720\n",
      "test_loss = 75.2912\n",
      "****************************\n",
      "Epoch: 4025\n",
      "train_loss = 87.5041\n",
      "test_loss = 74.9865\n",
      "****************************\n",
      "Epoch: 4026\n",
      "train_loss = 87.4857\n",
      "test_loss = 75.6367\n",
      "****************************\n",
      "Epoch: 4027\n",
      "train_loss = 87.5465\n",
      "test_loss = 74.8476\n",
      "****************************\n",
      "Epoch: 4028\n",
      "train_loss = 87.4792\n",
      "test_loss = 75.6139\n",
      "****************************\n",
      "Epoch: 4029\n",
      "train_loss = 87.9463\n",
      "test_loss = 74.3304\n",
      "****************************\n",
      "Epoch: 4030\n",
      "train_loss = 87.6764\n",
      "test_loss = 74.6087\n",
      "****************************\n",
      "Epoch: 4031\n",
      "train_loss = 87.4949\n",
      "test_loss = 75.0969\n",
      "****************************\n",
      "Epoch: 4032\n",
      "train_loss = 87.4330\n",
      "test_loss = 75.5823\n",
      "****************************\n",
      "Epoch: 4033\n",
      "train_loss = 87.4606\n",
      "test_loss = 75.7421\n",
      "****************************\n",
      "Epoch: 4034\n",
      "train_loss = 88.1617\n",
      "test_loss = 77.6740\n",
      "****************************\n",
      "Epoch: 4035\n",
      "train_loss = 87.5587\n",
      "test_loss = 75.4000\n",
      "****************************\n",
      "Epoch: 4036\n",
      "train_loss = 87.8247\n",
      "test_loss = 74.4781\n",
      "****************************\n",
      "Epoch: 4037\n",
      "train_loss = 87.8367\n",
      "test_loss = 74.4314\n",
      "****************************\n",
      "Epoch: 4038\n",
      "train_loss = 92.0383\n",
      "test_loss = 84.0734\n",
      "****************************\n",
      "Epoch: 4039\n",
      "train_loss = 87.7100\n",
      "test_loss = 74.5284\n",
      "****************************\n",
      "Epoch: 4040\n",
      "train_loss = 87.4913\n",
      "test_loss = 75.7257\n",
      "****************************\n",
      "Epoch: 4041\n",
      "train_loss = 87.4636\n",
      "test_loss = 75.4855\n",
      "****************************\n",
      "Epoch: 4042\n",
      "train_loss = 87.6632\n",
      "test_loss = 76.4780\n",
      "****************************\n",
      "Epoch: 4043\n",
      "train_loss = 87.5108\n",
      "test_loss = 74.9929\n",
      "****************************\n",
      "Epoch: 4044\n",
      "train_loss = 87.5025\n",
      "test_loss = 75.7084\n",
      "****************************\n",
      "Epoch: 4045\n",
      "train_loss = 87.4674\n",
      "test_loss = 75.2219\n",
      "****************************\n",
      "Epoch: 4046\n",
      "train_loss = 87.6593\n",
      "test_loss = 76.5568\n",
      "****************************\n",
      "Epoch: 4047\n",
      "train_loss = 87.6054\n",
      "test_loss = 74.6658\n",
      "****************************\n",
      "Epoch: 4048\n",
      "train_loss = 87.4794\n",
      "test_loss = 75.8379\n",
      "****************************\n",
      "Epoch: 4049\n",
      "train_loss = 87.6165\n",
      "test_loss = 76.3241\n",
      "****************************\n",
      "Epoch: 4050\n",
      "train_loss = 87.4345\n",
      "test_loss = 75.5097\n",
      "****************************\n",
      "Epoch: 4051\n",
      "train_loss = 88.9630\n",
      "test_loss = 79.2496\n",
      "****************************\n",
      "Epoch: 4052\n",
      "train_loss = 87.6635\n",
      "test_loss = 74.6137\n",
      "****************************\n",
      "Epoch: 4053\n",
      "train_loss = 87.4484\n",
      "test_loss = 75.6084\n",
      "****************************\n",
      "Epoch: 4054\n",
      "train_loss = 87.6041\n",
      "test_loss = 74.7633\n",
      "****************************\n",
      "Epoch: 4055\n",
      "train_loss = 87.4651\n",
      "test_loss = 75.3711\n",
      "****************************\n",
      "Epoch: 4056\n",
      "train_loss = 87.8487\n",
      "test_loss = 74.3994\n",
      "****************************\n",
      "Epoch: 4057\n",
      "train_loss = 87.5060\n",
      "test_loss = 75.3100\n",
      "****************************\n",
      "Epoch: 4058\n",
      "train_loss = 87.5014\n",
      "test_loss = 75.0090\n",
      "****************************\n",
      "Epoch: 4059\n",
      "train_loss = 87.6952\n",
      "test_loss = 76.5869\n",
      "****************************\n",
      "Epoch: 4060\n",
      "train_loss = 87.7180\n",
      "test_loss = 76.7313\n",
      "****************************\n",
      "Epoch: 4061\n",
      "train_loss = 87.5365\n",
      "test_loss = 74.8271\n",
      "****************************\n",
      "Epoch: 4062\n",
      "train_loss = 87.4366\n",
      "test_loss = 75.4862\n",
      "****************************\n",
      "Epoch: 4063\n",
      "train_loss = 87.5006\n",
      "test_loss = 76.1572\n",
      "****************************\n",
      "Epoch: 4064\n",
      "train_loss = 88.6448\n",
      "test_loss = 78.9894\n",
      "****************************\n",
      "Epoch: 4065\n",
      "train_loss = 87.6282\n",
      "test_loss = 75.2328\n",
      "****************************\n",
      "Epoch: 4066\n",
      "train_loss = 87.5942\n",
      "test_loss = 74.8236\n",
      "****************************\n",
      "Epoch: 4067\n",
      "train_loss = 87.7875\n",
      "test_loss = 74.5986\n",
      "****************************\n",
      "Epoch: 4068\n",
      "train_loss = 87.4989\n",
      "test_loss = 76.0355\n",
      "****************************\n",
      "Epoch: 4069\n",
      "train_loss = 87.8193\n",
      "test_loss = 74.4823\n",
      "****************************\n",
      "Epoch: 4070\n",
      "train_loss = 87.6328\n",
      "test_loss = 76.5887\n",
      "****************************\n",
      "Epoch: 4071\n",
      "train_loss = 88.2009\n",
      "test_loss = 74.2275\n",
      "****************************\n",
      "Epoch: 4072\n",
      "train_loss = 87.6098\n",
      "test_loss = 74.6883\n",
      "****************************\n",
      "Epoch: 4073\n",
      "train_loss = 87.5185\n",
      "test_loss = 75.9883\n",
      "****************************\n",
      "Epoch: 4074\n",
      "train_loss = 87.5645\n",
      "test_loss = 74.8888\n",
      "****************************\n",
      "Epoch: 4075\n",
      "train_loss = 87.6447\n",
      "test_loss = 74.7190\n",
      "****************************\n",
      "Epoch: 4076\n",
      "train_loss = 87.6108\n",
      "test_loss = 76.3273\n",
      "****************************\n",
      "Epoch: 4077\n",
      "train_loss = 87.9382\n",
      "test_loss = 77.3438\n",
      "****************************\n",
      "Epoch: 4078\n",
      "train_loss = 87.4899\n",
      "test_loss = 75.0039\n",
      "****************************\n",
      "Epoch: 4079\n",
      "train_loss = 87.4728\n",
      "test_loss = 75.0919\n",
      "****************************\n",
      "Epoch: 4080\n",
      "train_loss = 87.5329\n",
      "test_loss = 76.2117\n",
      "****************************\n",
      "Epoch: 4081\n",
      "train_loss = 87.7631\n",
      "test_loss = 74.5029\n",
      "****************************\n",
      "Epoch: 4082\n",
      "train_loss = 87.5242\n",
      "test_loss = 76.1898\n",
      "****************************\n",
      "Epoch: 4083\n",
      "train_loss = 87.4862\n",
      "test_loss = 75.0016\n",
      "****************************\n",
      "Epoch: 4084\n",
      "train_loss = 87.4882\n",
      "test_loss = 74.9869\n",
      "****************************\n",
      "Epoch: 4085\n",
      "train_loss = 87.5239\n",
      "test_loss = 75.6789\n",
      "****************************\n",
      "Epoch: 4086\n",
      "train_loss = 87.6985\n",
      "test_loss = 74.5480\n",
      "****************************\n",
      "Epoch: 4087\n",
      "train_loss = 87.4857\n",
      "test_loss = 75.3095\n",
      "****************************\n",
      "Epoch: 4088\n",
      "train_loss = 87.4732\n",
      "test_loss = 75.5594\n",
      "****************************\n",
      "Epoch: 4089\n",
      "train_loss = 87.5706\n",
      "test_loss = 74.8686\n",
      "****************************\n",
      "Epoch: 4090\n",
      "train_loss = 88.0503\n",
      "test_loss = 74.2828\n",
      "****************************\n",
      "Epoch: 4091\n",
      "train_loss = 87.5896\n",
      "test_loss = 74.6989\n",
      "****************************\n",
      "Epoch: 4092\n",
      "train_loss = 87.4597\n",
      "test_loss = 75.2461\n",
      "****************************\n",
      "Epoch: 4093\n",
      "train_loss = 87.4741\n",
      "test_loss = 75.7862\n",
      "****************************\n",
      "Epoch: 4094\n",
      "train_loss = 87.8567\n",
      "test_loss = 74.4031\n",
      "****************************\n",
      "Epoch: 4095\n",
      "train_loss = 87.7095\n",
      "test_loss = 76.9069\n",
      "****************************\n",
      "Epoch: 4096\n",
      "train_loss = 87.4437\n",
      "test_loss = 75.2882\n",
      "****************************\n",
      "Epoch: 4097\n",
      "train_loss = 87.4424\n",
      "test_loss = 75.8330\n",
      "****************************\n",
      "Epoch: 4098\n",
      "train_loss = 87.4210\n",
      "test_loss = 75.4189\n",
      "****************************\n",
      "Epoch: 4099\n",
      "train_loss = 87.4924\n",
      "test_loss = 75.5238\n",
      "****************************\n",
      "Epoch: 4100\n",
      "train_loss = 88.0905\n",
      "test_loss = 74.2977\n",
      "****************************\n",
      "Epoch: 4101\n",
      "train_loss = 87.7419\n",
      "test_loss = 76.5476\n",
      "****************************\n",
      "Epoch: 4102\n",
      "train_loss = 87.7698\n",
      "test_loss = 76.6488\n",
      "****************************\n",
      "Epoch: 4103\n",
      "train_loss = 87.8810\n",
      "test_loss = 74.4127\n",
      "****************************\n",
      "Epoch: 4104\n",
      "train_loss = 87.8820\n",
      "test_loss = 77.0801\n",
      "****************************\n",
      "Epoch: 4105\n",
      "train_loss = 88.7419\n",
      "test_loss = 78.9878\n",
      "****************************\n",
      "Epoch: 4106\n",
      "train_loss = 88.3558\n",
      "test_loss = 78.0921\n",
      "****************************\n",
      "Epoch: 4107\n",
      "train_loss = 87.5083\n",
      "test_loss = 75.0069\n",
      "****************************\n",
      "Epoch: 4108\n",
      "train_loss = 87.4961\n",
      "test_loss = 75.9434\n",
      "****************************\n",
      "Epoch: 4109\n",
      "train_loss = 87.5246\n",
      "test_loss = 74.8363\n",
      "****************************\n",
      "Epoch: 4110\n",
      "train_loss = 87.7046\n",
      "test_loss = 74.6130\n",
      "****************************\n",
      "Epoch: 4111\n",
      "train_loss = 87.9528\n",
      "test_loss = 77.2238\n",
      "****************************\n",
      "Epoch: 4112\n",
      "train_loss = 89.3825\n",
      "test_loss = 79.8652\n",
      "****************************\n",
      "Epoch: 4113\n",
      "train_loss = 87.5658\n",
      "test_loss = 74.8309\n",
      "****************************\n",
      "Epoch: 4114\n",
      "train_loss = 87.4510\n",
      "test_loss = 75.3488\n",
      "****************************\n",
      "Epoch: 4115\n",
      "train_loss = 87.9218\n",
      "test_loss = 77.3631\n",
      "****************************\n",
      "Epoch: 4116\n",
      "train_loss = 87.4725\n",
      "test_loss = 75.7172\n",
      "****************************\n",
      "Epoch: 4117\n",
      "train_loss = 87.4761\n",
      "test_loss = 75.3092\n",
      "****************************\n",
      "Epoch: 4118\n",
      "train_loss = 87.6236\n",
      "test_loss = 74.7600\n",
      "****************************\n",
      "Epoch: 4119\n",
      "train_loss = 87.5777\n",
      "test_loss = 74.7997\n",
      "****************************\n",
      "Epoch: 4120\n",
      "train_loss = 87.5037\n",
      "test_loss = 74.9499\n",
      "****************************\n",
      "Epoch: 4121\n",
      "train_loss = 87.6618\n",
      "test_loss = 74.6228\n",
      "****************************\n",
      "Epoch: 4122\n",
      "train_loss = 87.7717\n",
      "test_loss = 74.4724\n",
      "****************************\n",
      "Epoch: 4123\n",
      "train_loss = 87.5329\n",
      "test_loss = 74.8777\n",
      "****************************\n",
      "Epoch: 4124\n",
      "train_loss = 87.6513\n",
      "test_loss = 74.5958\n",
      "****************************\n",
      "Epoch: 4125\n",
      "train_loss = 88.4009\n",
      "test_loss = 78.3889\n",
      "****************************\n",
      "Epoch: 4126\n",
      "train_loss = 88.1293\n",
      "test_loss = 77.6904\n",
      "****************************\n",
      "Epoch: 4127\n",
      "train_loss = 88.7433\n",
      "test_loss = 78.9399\n",
      "****************************\n",
      "Epoch: 4128\n",
      "train_loss = 87.4895\n",
      "test_loss = 75.2916\n",
      "****************************\n",
      "Epoch: 4129\n",
      "train_loss = 87.4873\n",
      "test_loss = 75.0798\n",
      "****************************\n",
      "Epoch: 4130\n",
      "train_loss = 87.4685\n",
      "test_loss = 75.3813\n",
      "****************************\n",
      "Epoch: 4131\n",
      "train_loss = 87.4411\n",
      "test_loss = 75.5526\n",
      "****************************\n",
      "Epoch: 4132\n",
      "train_loss = 87.5542\n",
      "test_loss = 75.7561\n",
      "****************************\n",
      "Epoch: 4133\n",
      "train_loss = 87.5989\n",
      "test_loss = 76.3339\n",
      "****************************\n",
      "Epoch: 4134\n",
      "train_loss = 87.4950\n",
      "test_loss = 75.8028\n",
      "****************************\n",
      "Epoch: 4135\n",
      "train_loss = 87.8149\n",
      "test_loss = 74.5206\n",
      "****************************\n",
      "Epoch: 4136\n",
      "train_loss = 88.6018\n",
      "test_loss = 74.1628\n",
      "****************************\n",
      "Epoch: 4137\n",
      "train_loss = 87.5959\n",
      "test_loss = 74.8111\n",
      "****************************\n",
      "Epoch: 4138\n",
      "train_loss = 88.1933\n",
      "test_loss = 74.3692\n",
      "****************************\n",
      "Epoch: 4139\n",
      "train_loss = 87.8328\n",
      "test_loss = 76.8257\n",
      "****************************\n",
      "Epoch: 4140\n",
      "train_loss = 88.3190\n",
      "test_loss = 74.2374\n",
      "****************************\n",
      "Epoch: 4141\n",
      "train_loss = 87.7341\n",
      "test_loss = 76.5632\n",
      "****************************\n",
      "Epoch: 4142\n",
      "train_loss = 88.2866\n",
      "test_loss = 74.2098\n",
      "****************************\n",
      "Epoch: 4143\n",
      "train_loss = 87.8824\n",
      "test_loss = 77.2231\n",
      "****************************\n",
      "Epoch: 4144\n",
      "train_loss = 87.6266\n",
      "test_loss = 74.7214\n",
      "****************************\n",
      "Epoch: 4145\n",
      "train_loss = 87.6043\n",
      "test_loss = 76.0879\n",
      "****************************\n",
      "Epoch: 4146\n",
      "train_loss = 87.5171\n",
      "test_loss = 75.6273\n",
      "****************************\n",
      "Epoch: 4147\n",
      "train_loss = 87.5208\n",
      "test_loss = 75.0353\n",
      "****************************\n",
      "Epoch: 4148\n",
      "train_loss = 87.5280\n",
      "test_loss = 75.1511\n",
      "****************************\n",
      "Epoch: 4149\n",
      "train_loss = 87.8872\n",
      "test_loss = 76.4993\n",
      "****************************\n",
      "Epoch: 4150\n",
      "train_loss = 87.5639\n",
      "test_loss = 75.9060\n",
      "****************************\n",
      "Epoch: 4151\n",
      "train_loss = 89.3048\n",
      "test_loss = 79.7727\n",
      "****************************\n",
      "Epoch: 4152\n",
      "train_loss = 87.7650\n",
      "test_loss = 74.6246\n",
      "****************************\n",
      "Epoch: 4153\n",
      "train_loss = 87.5375\n",
      "test_loss = 75.0707\n",
      "****************************\n",
      "Epoch: 4154\n",
      "train_loss = 87.5954\n",
      "test_loss = 76.2437\n",
      "****************************\n",
      "Epoch: 4155\n",
      "train_loss = 87.6287\n",
      "test_loss = 76.2429\n",
      "****************************\n",
      "Epoch: 4156\n",
      "train_loss = 87.5135\n",
      "test_loss = 75.3649\n",
      "****************************\n",
      "Epoch: 4157\n",
      "train_loss = 87.5199\n",
      "test_loss = 75.2442\n",
      "****************************\n",
      "Epoch: 4158\n",
      "train_loss = 87.5668\n",
      "test_loss = 75.9905\n",
      "****************************\n",
      "Epoch: 4159\n",
      "train_loss = 88.2310\n",
      "test_loss = 77.8007\n",
      "****************************\n",
      "Epoch: 4160\n",
      "train_loss = 88.3078\n",
      "test_loss = 78.0280\n",
      "****************************\n",
      "Epoch: 4161\n",
      "train_loss = 87.4901\n",
      "test_loss = 75.6901\n",
      "****************************\n",
      "Epoch: 4162\n",
      "train_loss = 87.7477\n",
      "test_loss = 76.8963\n",
      "****************************\n",
      "Epoch: 4163\n",
      "train_loss = 87.5217\n",
      "test_loss = 76.1384\n",
      "****************************\n",
      "Epoch: 4164\n",
      "train_loss = 87.4531\n",
      "test_loss = 75.3842\n",
      "****************************\n",
      "Epoch: 4165\n",
      "train_loss = 87.4954\n",
      "test_loss = 75.0243\n",
      "****************************\n",
      "Epoch: 4166\n",
      "train_loss = 89.4783\n",
      "test_loss = 80.4447\n",
      "****************************\n",
      "Epoch: 4167\n",
      "train_loss = 87.5105\n",
      "test_loss = 75.7664\n",
      "****************************\n",
      "Epoch: 4168\n",
      "train_loss = 87.4930\n",
      "test_loss = 75.1071\n",
      "****************************\n",
      "Epoch: 4169\n",
      "train_loss = 87.6738\n",
      "test_loss = 74.6899\n",
      "****************************\n",
      "Epoch: 4170\n",
      "train_loss = 87.5140\n",
      "test_loss = 75.7538\n",
      "****************************\n",
      "Epoch: 4171\n",
      "train_loss = 87.8893\n",
      "test_loss = 77.0629\n",
      "****************************\n",
      "Epoch: 4172\n",
      "train_loss = 87.5091\n",
      "test_loss = 75.7048\n",
      "****************************\n",
      "Epoch: 4173\n",
      "train_loss = 87.6234\n",
      "test_loss = 76.4047\n",
      "****************************\n",
      "Epoch: 4174\n",
      "train_loss = 87.7606\n",
      "test_loss = 74.5434\n",
      "****************************\n",
      "Epoch: 4175\n",
      "train_loss = 87.9646\n",
      "test_loss = 74.3636\n",
      "****************************\n",
      "Epoch: 4176\n",
      "train_loss = 88.0164\n",
      "test_loss = 77.3894\n",
      "****************************\n",
      "Epoch: 4177\n",
      "train_loss = 87.4723\n",
      "test_loss = 75.3921\n",
      "****************************\n",
      "Epoch: 4178\n",
      "train_loss = 87.4679\n",
      "test_loss = 75.2530\n",
      "****************************\n",
      "Epoch: 4179\n",
      "train_loss = 88.3071\n",
      "test_loss = 74.4545\n",
      "****************************\n",
      "Epoch: 4180\n",
      "train_loss = 87.5396\n",
      "test_loss = 75.2184\n",
      "****************************\n",
      "Epoch: 4181\n",
      "train_loss = 87.6602\n",
      "test_loss = 76.5244\n",
      "****************************\n",
      "Epoch: 4182\n",
      "train_loss = 87.5099\n",
      "test_loss = 75.1699\n",
      "****************************\n",
      "Epoch: 4183\n",
      "train_loss = 87.6377\n",
      "test_loss = 76.5943\n",
      "****************************\n",
      "Epoch: 4184\n",
      "train_loss = 87.5605\n",
      "test_loss = 76.0490\n",
      "****************************\n",
      "Epoch: 4185\n",
      "train_loss = 87.5229\n",
      "test_loss = 75.9515\n",
      "****************************\n",
      "Epoch: 4186\n",
      "train_loss = 87.5102\n",
      "test_loss = 75.5457\n",
      "****************************\n",
      "Epoch: 4187\n",
      "train_loss = 88.2236\n",
      "test_loss = 77.8749\n",
      "****************************\n",
      "Epoch: 4188\n",
      "train_loss = 87.5291\n",
      "test_loss = 75.9349\n",
      "****************************\n",
      "Epoch: 4189\n",
      "train_loss = 88.4437\n",
      "test_loss = 78.3427\n",
      "****************************\n",
      "Epoch: 4190\n",
      "train_loss = 87.5262\n",
      "test_loss = 75.4069\n",
      "****************************\n",
      "Epoch: 4191\n",
      "train_loss = 87.5711\n",
      "test_loss = 74.9439\n",
      "****************************\n",
      "Epoch: 4192\n",
      "train_loss = 87.6213\n",
      "test_loss = 74.8142\n",
      "****************************\n",
      "Epoch: 4193\n",
      "train_loss = 87.5975\n",
      "test_loss = 74.9653\n",
      "****************************\n",
      "Epoch: 4194\n",
      "train_loss = 87.5056\n",
      "test_loss = 75.1765\n",
      "****************************\n",
      "Epoch: 4195\n",
      "train_loss = 87.6219\n",
      "test_loss = 74.8361\n",
      "****************************\n",
      "Epoch: 4196\n",
      "train_loss = 87.4724\n",
      "test_loss = 75.2285\n",
      "****************************\n",
      "Epoch: 4197\n",
      "train_loss = 87.8543\n",
      "test_loss = 74.4699\n",
      "****************************\n",
      "Epoch: 4198\n",
      "train_loss = 88.0008\n",
      "test_loss = 74.3576\n",
      "****************************\n",
      "Epoch: 4199\n",
      "train_loss = 87.5221\n",
      "test_loss = 75.6998\n",
      "****************************\n",
      "Epoch: 4200\n",
      "train_loss = 87.5847\n",
      "test_loss = 74.8678\n",
      "****************************\n",
      "Epoch: 4201\n",
      "train_loss = 87.7622\n",
      "test_loss = 75.0925\n",
      "****************************\n",
      "Epoch: 4202\n",
      "train_loss = 87.5352\n",
      "test_loss = 75.8528\n",
      "****************************\n",
      "Epoch: 4203\n",
      "train_loss = 87.5319\n",
      "test_loss = 75.8815\n",
      "****************************\n",
      "Epoch: 4204\n",
      "train_loss = 87.6487\n",
      "test_loss = 76.5366\n",
      "****************************\n",
      "Epoch: 4205\n",
      "train_loss = 87.9025\n",
      "test_loss = 74.4597\n",
      "****************************\n",
      "Epoch: 4206\n",
      "train_loss = 87.8822\n",
      "test_loss = 74.4706\n",
      "****************************\n",
      "Epoch: 4207\n",
      "train_loss = 87.4748\n",
      "test_loss = 75.3367\n",
      "****************************\n",
      "Epoch: 4208\n",
      "train_loss = 87.6249\n",
      "test_loss = 76.5018\n",
      "****************************\n",
      "Epoch: 4209\n",
      "train_loss = 87.4968\n",
      "test_loss = 75.9611\n",
      "****************************\n",
      "Epoch: 4210\n",
      "train_loss = 87.4652\n",
      "test_loss = 75.6974\n",
      "****************************\n",
      "Epoch: 4211\n",
      "train_loss = 88.1218\n",
      "test_loss = 77.9154\n",
      "****************************\n",
      "Epoch: 4212\n",
      "train_loss = 87.4552\n",
      "test_loss = 75.5749\n",
      "****************************\n",
      "Epoch: 4213\n",
      "train_loss = 87.4361\n",
      "test_loss = 75.4216\n",
      "****************************\n",
      "Epoch: 4214\n",
      "train_loss = 87.4895\n",
      "test_loss = 74.9558\n",
      "****************************\n",
      "Epoch: 4215\n",
      "train_loss = 87.6864\n",
      "test_loss = 76.2496\n",
      "****************************\n",
      "Epoch: 4216\n",
      "train_loss = 87.4740\n",
      "test_loss = 75.4332\n",
      "****************************\n",
      "Epoch: 4217\n",
      "train_loss = 87.6202\n",
      "test_loss = 74.8122\n",
      "****************************\n",
      "Epoch: 4218\n",
      "train_loss = 88.3215\n",
      "test_loss = 74.2541\n",
      "****************************\n",
      "Epoch: 4219\n",
      "train_loss = 87.6588\n",
      "test_loss = 76.5143\n",
      "****************************\n",
      "Epoch: 4220\n",
      "train_loss = 87.5072\n",
      "test_loss = 76.2013\n",
      "****************************\n",
      "Epoch: 4221\n",
      "train_loss = 87.4411\n",
      "test_loss = 75.5640\n",
      "****************************\n",
      "Epoch: 4222\n",
      "train_loss = 88.4691\n",
      "test_loss = 78.6551\n",
      "****************************\n",
      "Epoch: 4223\n",
      "train_loss = 87.7452\n",
      "test_loss = 74.5866\n",
      "****************************\n",
      "Epoch: 4224\n",
      "train_loss = 88.0280\n",
      "test_loss = 77.4587\n",
      "****************************\n",
      "Epoch: 4225\n",
      "train_loss = 88.3417\n",
      "test_loss = 78.1528\n",
      "****************************\n",
      "Epoch: 4226\n",
      "train_loss = 87.5073\n",
      "test_loss = 75.0833\n",
      "****************************\n",
      "Epoch: 4227\n",
      "train_loss = 87.5528\n",
      "test_loss = 75.9501\n",
      "****************************\n",
      "Epoch: 4228\n",
      "train_loss = 88.1566\n",
      "test_loss = 74.2530\n",
      "****************************\n",
      "Epoch: 4229\n",
      "train_loss = 88.4401\n",
      "test_loss = 74.1918\n",
      "****************************\n",
      "Epoch: 4230\n",
      "train_loss = 87.8715\n",
      "test_loss = 74.4138\n",
      "****************************\n",
      "Epoch: 4231\n",
      "train_loss = 87.5722\n",
      "test_loss = 74.7313\n",
      "****************************\n",
      "Epoch: 4232\n",
      "train_loss = 88.0199\n",
      "test_loss = 77.1817\n",
      "****************************\n",
      "Epoch: 4233\n",
      "train_loss = 88.1057\n",
      "test_loss = 77.3737\n",
      "****************************\n",
      "Epoch: 4234\n",
      "train_loss = 87.5595\n",
      "test_loss = 75.9866\n",
      "****************************\n",
      "Epoch: 4235\n",
      "train_loss = 87.5181\n",
      "test_loss = 75.9400\n",
      "****************************\n",
      "Epoch: 4236\n",
      "train_loss = 87.6144\n",
      "test_loss = 76.2496\n",
      "****************************\n",
      "Epoch: 4237\n",
      "train_loss = 87.9042\n",
      "test_loss = 74.3723\n",
      "****************************\n",
      "Epoch: 4238\n",
      "train_loss = 87.6294\n",
      "test_loss = 74.6863\n",
      "****************************\n",
      "Epoch: 4239\n",
      "train_loss = 87.5220\n",
      "test_loss = 74.9904\n",
      "****************************\n",
      "Epoch: 4240\n",
      "train_loss = 87.6129\n",
      "test_loss = 76.1257\n",
      "****************************\n",
      "Epoch: 4241\n",
      "train_loss = 87.4894\n",
      "test_loss = 74.9637\n",
      "****************************\n",
      "Epoch: 4242\n",
      "train_loss = 87.4747\n",
      "test_loss = 75.4568\n",
      "****************************\n",
      "Epoch: 4243\n",
      "train_loss = 87.9073\n",
      "test_loss = 74.3624\n",
      "****************************\n",
      "Epoch: 4244\n",
      "train_loss = 87.4804\n",
      "test_loss = 75.8135\n",
      "****************************\n",
      "Epoch: 4245\n",
      "train_loss = 87.4731\n",
      "test_loss = 75.8025\n",
      "****************************\n",
      "Epoch: 4246\n",
      "train_loss = 88.0116\n",
      "test_loss = 74.3310\n",
      "****************************\n",
      "Epoch: 4247\n",
      "train_loss = 87.4670\n",
      "test_loss = 75.4487\n",
      "****************************\n",
      "Epoch: 4248\n",
      "train_loss = 87.4754\n",
      "test_loss = 75.0854\n",
      "****************************\n",
      "Epoch: 4249\n",
      "train_loss = 88.6978\n",
      "test_loss = 78.8325\n",
      "****************************\n",
      "Epoch: 4250\n",
      "train_loss = 87.5359\n",
      "test_loss = 75.9124\n",
      "****************************\n",
      "Epoch: 4251\n",
      "train_loss = 87.5112\n",
      "test_loss = 75.1528\n",
      "****************************\n",
      "Epoch: 4252\n",
      "train_loss = 87.5058\n",
      "test_loss = 75.1891\n",
      "****************************\n",
      "Epoch: 4253\n",
      "train_loss = 87.5657\n",
      "test_loss = 75.8795\n",
      "****************************\n",
      "Epoch: 4254\n",
      "train_loss = 88.0188\n",
      "test_loss = 74.3480\n",
      "****************************\n",
      "Epoch: 4255\n",
      "train_loss = 87.6460\n",
      "test_loss = 74.9131\n",
      "****************************\n",
      "Epoch: 4256\n",
      "train_loss = 87.5327\n",
      "test_loss = 75.9098\n",
      "****************************\n",
      "Epoch: 4257\n",
      "train_loss = 87.5672\n",
      "test_loss = 76.2634\n",
      "****************************\n",
      "Epoch: 4258\n",
      "train_loss = 87.4688\n",
      "test_loss = 75.4654\n",
      "****************************\n",
      "Epoch: 4259\n",
      "train_loss = 87.6480\n",
      "test_loss = 74.6257\n",
      "****************************\n",
      "Epoch: 4260\n",
      "train_loss = 88.1480\n",
      "test_loss = 74.2210\n",
      "****************************\n",
      "Epoch: 4261\n",
      "train_loss = 88.0716\n",
      "test_loss = 74.2350\n",
      "****************************\n",
      "Epoch: 4262\n",
      "train_loss = 87.5574\n",
      "test_loss = 75.9975\n",
      "****************************\n",
      "Epoch: 4263\n",
      "train_loss = 87.5522\n",
      "test_loss = 75.9662\n",
      "****************************\n",
      "Epoch: 4264\n",
      "train_loss = 87.8867\n",
      "test_loss = 76.9485\n",
      "****************************\n",
      "Epoch: 4265\n",
      "train_loss = 88.1823\n",
      "test_loss = 77.6590\n",
      "****************************\n",
      "Epoch: 4266\n",
      "train_loss = 87.7360\n",
      "test_loss = 76.5173\n",
      "****************************\n",
      "Epoch: 4267\n",
      "train_loss = 87.5657\n",
      "test_loss = 76.0022\n",
      "****************************\n",
      "Epoch: 4268\n",
      "train_loss = 87.5264\n",
      "test_loss = 74.9768\n",
      "****************************\n",
      "Epoch: 4269\n",
      "train_loss = 88.6569\n",
      "test_loss = 78.6288\n",
      "****************************\n",
      "Epoch: 4270\n",
      "train_loss = 87.5237\n",
      "test_loss = 75.6142\n",
      "****************************\n",
      "Epoch: 4271\n",
      "train_loss = 88.3842\n",
      "test_loss = 74.2263\n",
      "****************************\n",
      "Epoch: 4272\n",
      "train_loss = 88.1667\n",
      "test_loss = 74.3083\n",
      "****************************\n",
      "Epoch: 4273\n",
      "train_loss = 87.5624\n",
      "test_loss = 76.0253\n",
      "****************************\n",
      "Epoch: 4274\n",
      "train_loss = 90.5804\n",
      "test_loss = 82.0140\n",
      "****************************\n",
      "Epoch: 4275\n",
      "train_loss = 87.6714\n",
      "test_loss = 76.5773\n",
      "****************************\n",
      "Epoch: 4276\n",
      "train_loss = 87.6223\n",
      "test_loss = 74.7456\n",
      "****************************\n",
      "Epoch: 4277\n",
      "train_loss = 87.6904\n",
      "test_loss = 76.5527\n",
      "****************************\n",
      "Epoch: 4278\n",
      "train_loss = 87.9628\n",
      "test_loss = 77.3626\n",
      "****************************\n",
      "Epoch: 4279\n",
      "train_loss = 88.2717\n",
      "test_loss = 77.9486\n",
      "****************************\n",
      "Epoch: 4280\n",
      "train_loss = 87.7193\n",
      "test_loss = 76.7358\n",
      "****************************\n",
      "Epoch: 4281\n",
      "train_loss = 87.5112\n",
      "test_loss = 75.9437\n",
      "****************************\n",
      "Epoch: 4282\n",
      "train_loss = 87.5770\n",
      "test_loss = 74.7796\n",
      "****************************\n",
      "Epoch: 4283\n",
      "train_loss = 87.4861\n",
      "test_loss = 75.7821\n",
      "****************************\n",
      "Epoch: 4284\n",
      "train_loss = 87.5751\n",
      "test_loss = 76.2226\n",
      "****************************\n",
      "Epoch: 4285\n",
      "train_loss = 87.5210\n",
      "test_loss = 75.9791\n",
      "****************************\n",
      "Epoch: 4286\n",
      "train_loss = 88.2783\n",
      "test_loss = 74.2383\n",
      "****************************\n",
      "Epoch: 4287\n",
      "train_loss = 87.7352\n",
      "test_loss = 76.5047\n",
      "****************************\n",
      "Epoch: 4288\n",
      "train_loss = 87.5005\n",
      "test_loss = 75.5065\n",
      "****************************\n",
      "Epoch: 4289\n",
      "train_loss = 87.6084\n",
      "test_loss = 76.3467\n",
      "****************************\n",
      "Epoch: 4290\n",
      "train_loss = 88.4406\n",
      "test_loss = 74.2000\n",
      "****************************\n",
      "Epoch: 4291\n",
      "train_loss = 87.8101\n",
      "test_loss = 74.4446\n",
      "****************************\n",
      "Epoch: 4292\n",
      "train_loss = 87.5157\n",
      "test_loss = 75.6675\n",
      "****************************\n",
      "Epoch: 4293\n",
      "train_loss = 87.4534\n",
      "test_loss = 75.2417\n",
      "****************************\n",
      "Epoch: 4294\n",
      "train_loss = 87.4836\n",
      "test_loss = 75.6711\n",
      "****************************\n",
      "Epoch: 4295\n",
      "train_loss = 87.4950\n",
      "test_loss = 75.2262\n",
      "****************************\n",
      "Epoch: 4296\n",
      "train_loss = 87.4856\n",
      "test_loss = 75.0919\n",
      "****************************\n",
      "Epoch: 4297\n",
      "train_loss = 87.4657\n",
      "test_loss = 75.1425\n",
      "****************************\n",
      "Epoch: 4298\n",
      "train_loss = 88.1294\n",
      "test_loss = 74.2598\n",
      "****************************\n",
      "Epoch: 4299\n",
      "train_loss = 87.4611\n",
      "test_loss = 75.4909\n",
      "****************************\n",
      "Epoch: 4300\n",
      "train_loss = 89.9555\n",
      "test_loss = 80.9314\n",
      "****************************\n",
      "Epoch: 4301\n",
      "train_loss = 87.4788\n",
      "test_loss = 75.8454\n",
      "****************************\n",
      "Epoch: 4302\n",
      "train_loss = 87.4553\n",
      "test_loss = 75.4909\n",
      "****************************\n",
      "Epoch: 4303\n",
      "train_loss = 87.4900\n",
      "test_loss = 75.2158\n",
      "****************************\n",
      "Epoch: 4304\n",
      "train_loss = 88.0230\n",
      "test_loss = 74.2908\n",
      "****************************\n",
      "Epoch: 4305\n",
      "train_loss = 87.9253\n",
      "test_loss = 74.3470\n",
      "****************************\n",
      "Epoch: 4306\n",
      "train_loss = 87.8631\n",
      "test_loss = 74.3646\n",
      "****************************\n",
      "Epoch: 4307\n",
      "train_loss = 87.5350\n",
      "test_loss = 75.8816\n",
      "****************************\n",
      "Epoch: 4308\n",
      "train_loss = 87.7068\n",
      "test_loss = 76.6566\n",
      "****************************\n",
      "Epoch: 4309\n",
      "train_loss = 87.5902\n",
      "test_loss = 76.3974\n",
      "****************************\n",
      "Epoch: 4310\n",
      "train_loss = 87.5132\n",
      "test_loss = 76.1416\n",
      "****************************\n",
      "Epoch: 4311\n",
      "train_loss = 87.5142\n",
      "test_loss = 74.9407\n",
      "****************************\n",
      "Epoch: 4312\n",
      "train_loss = 87.5811\n",
      "test_loss = 76.5167\n",
      "****************************\n",
      "Epoch: 4313\n",
      "train_loss = 87.7274\n",
      "test_loss = 74.5234\n",
      "****************************\n",
      "Epoch: 4314\n",
      "train_loss = 87.5001\n",
      "test_loss = 74.9876\n",
      "****************************\n",
      "Epoch: 4315\n",
      "train_loss = 87.8555\n",
      "test_loss = 77.2476\n",
      "****************************\n",
      "Epoch: 4316\n",
      "train_loss = 87.4684\n",
      "test_loss = 74.9927\n",
      "****************************\n",
      "Epoch: 4317\n",
      "train_loss = 87.4434\n",
      "test_loss = 75.0941\n",
      "****************************\n",
      "Epoch: 4318\n",
      "train_loss = 87.5881\n",
      "test_loss = 76.4157\n",
      "****************************\n",
      "Epoch: 4319\n",
      "train_loss = 87.5076\n",
      "test_loss = 74.9391\n",
      "****************************\n",
      "Epoch: 4320\n",
      "train_loss = 88.4339\n",
      "test_loss = 74.1296\n",
      "****************************\n",
      "Epoch: 4321\n",
      "train_loss = 87.5094\n",
      "test_loss = 75.8850\n",
      "****************************\n",
      "Epoch: 4322\n",
      "train_loss = 87.8232\n",
      "test_loss = 77.0461\n",
      "****************************\n",
      "Epoch: 4323\n",
      "train_loss = 88.7339\n",
      "test_loss = 74.1115\n",
      "****************************\n",
      "Epoch: 4324\n",
      "train_loss = 87.5425\n",
      "test_loss = 74.7919\n",
      "****************************\n",
      "Epoch: 4325\n",
      "train_loss = 87.4845\n",
      "test_loss = 75.7063\n",
      "****************************\n",
      "Epoch: 4326\n",
      "train_loss = 87.5996\n",
      "test_loss = 76.1669\n",
      "****************************\n",
      "Epoch: 4327\n",
      "train_loss = 87.6288\n",
      "test_loss = 76.4447\n",
      "****************************\n",
      "Epoch: 4328\n",
      "train_loss = 87.4538\n",
      "test_loss = 75.1564\n",
      "****************************\n",
      "Epoch: 4329\n",
      "train_loss = 87.8604\n",
      "test_loss = 77.1749\n",
      "****************************\n",
      "Epoch: 4330\n",
      "train_loss = 87.6238\n",
      "test_loss = 76.3574\n",
      "****************************\n",
      "Epoch: 4331\n",
      "train_loss = 87.4509\n",
      "test_loss = 75.7218\n",
      "****************************\n",
      "Epoch: 4332\n",
      "train_loss = 87.4647\n",
      "test_loss = 75.0501\n",
      "****************************\n",
      "Epoch: 4333\n",
      "train_loss = 87.6735\n",
      "test_loss = 74.5319\n",
      "****************************\n",
      "Epoch: 4334\n",
      "train_loss = 87.4344\n",
      "test_loss = 75.7822\n",
      "****************************\n",
      "Epoch: 4335\n",
      "train_loss = 87.4155\n",
      "test_loss = 75.4667\n",
      "****************************\n",
      "Epoch: 4336\n",
      "train_loss = 87.4441\n",
      "test_loss = 75.1242\n",
      "****************************\n",
      "Epoch: 4337\n",
      "train_loss = 87.5156\n",
      "test_loss = 75.9402\n",
      "****************************\n",
      "Epoch: 4338\n",
      "train_loss = 87.4986\n",
      "test_loss = 75.8966\n",
      "****************************\n",
      "Epoch: 4339\n",
      "train_loss = 87.8468\n",
      "test_loss = 74.4253\n",
      "****************************\n",
      "Epoch: 4340\n",
      "train_loss = 87.7270\n",
      "test_loss = 76.6236\n",
      "****************************\n",
      "Epoch: 4341\n",
      "train_loss = 87.5123\n",
      "test_loss = 75.8795\n",
      "****************************\n",
      "Epoch: 4342\n",
      "train_loss = 87.4519\n",
      "test_loss = 75.3893\n",
      "****************************\n",
      "Epoch: 4343\n",
      "train_loss = 87.5899\n",
      "test_loss = 76.2462\n",
      "****************************\n",
      "Epoch: 4344\n",
      "train_loss = 87.4702\n",
      "test_loss = 75.8784\n",
      "****************************\n",
      "Epoch: 4345\n",
      "train_loss = 87.5424\n",
      "test_loss = 74.8354\n",
      "****************************\n",
      "Epoch: 4346\n",
      "train_loss = 87.4587\n",
      "test_loss = 75.6269\n",
      "****************************\n",
      "Epoch: 4347\n",
      "train_loss = 87.5421\n",
      "test_loss = 76.1167\n",
      "****************************\n",
      "Epoch: 4348\n",
      "train_loss = 88.2513\n",
      "test_loss = 74.1945\n",
      "****************************\n",
      "Epoch: 4349\n",
      "train_loss = 87.5182\n",
      "test_loss = 74.8285\n",
      "****************************\n",
      "Epoch: 4350\n",
      "train_loss = 87.5486\n",
      "test_loss = 74.7802\n",
      "****************************\n",
      "Epoch: 4351\n",
      "train_loss = 87.8420\n",
      "test_loss = 74.4246\n",
      "****************************\n",
      "Epoch: 4352\n",
      "train_loss = 87.5995\n",
      "test_loss = 74.7750\n",
      "****************************\n",
      "Epoch: 4353\n",
      "train_loss = 87.4503\n",
      "test_loss = 75.5542\n",
      "****************************\n",
      "Epoch: 4354\n",
      "train_loss = 87.6405\n",
      "test_loss = 76.0161\n",
      "****************************\n",
      "Epoch: 4355\n",
      "train_loss = 87.7419\n",
      "test_loss = 74.4896\n",
      "****************************\n",
      "Epoch: 4356\n",
      "train_loss = 87.8420\n",
      "test_loss = 74.4452\n",
      "****************************\n",
      "Epoch: 4357\n",
      "train_loss = 87.7531\n",
      "test_loss = 76.6678\n",
      "****************************\n",
      "Epoch: 4358\n",
      "train_loss = 87.4853\n",
      "test_loss = 75.1883\n",
      "****************************\n",
      "Epoch: 4359\n",
      "train_loss = 87.5207\n",
      "test_loss = 74.8277\n",
      "****************************\n",
      "Epoch: 4360\n",
      "train_loss = 87.5049\n",
      "test_loss = 74.8330\n",
      "****************************\n",
      "Epoch: 4361\n",
      "train_loss = 87.7640\n",
      "test_loss = 74.4180\n",
      "****************************\n",
      "Epoch: 4362\n",
      "train_loss = 87.8814\n",
      "test_loss = 77.3028\n",
      "****************************\n",
      "Epoch: 4363\n",
      "train_loss = 88.7546\n",
      "test_loss = 78.8940\n",
      "****************************\n",
      "Epoch: 4364\n",
      "train_loss = 89.2557\n",
      "test_loss = 79.8947\n",
      "****************************\n",
      "Epoch: 4365\n",
      "train_loss = 87.4472\n",
      "test_loss = 75.1124\n",
      "****************************\n",
      "Epoch: 4366\n",
      "train_loss = 87.4501\n",
      "test_loss = 75.2479\n",
      "****************************\n",
      "Epoch: 4367\n",
      "train_loss = 87.5853\n",
      "test_loss = 76.2381\n",
      "****************************\n",
      "Epoch: 4368\n",
      "train_loss = 87.4654\n",
      "test_loss = 75.4768\n",
      "****************************\n",
      "Epoch: 4369\n",
      "train_loss = 87.4369\n",
      "test_loss = 75.3871\n",
      "****************************\n",
      "Epoch: 4370\n",
      "train_loss = 88.0659\n",
      "test_loss = 77.7057\n",
      "****************************\n",
      "Epoch: 4371\n",
      "train_loss = 87.8027\n",
      "test_loss = 77.0364\n",
      "****************************\n",
      "Epoch: 4372\n",
      "train_loss = 87.6069\n",
      "test_loss = 76.5369\n",
      "****************************\n",
      "Epoch: 4373\n",
      "train_loss = 91.7908\n",
      "test_loss = 83.7901\n",
      "****************************\n",
      "Epoch: 4374\n",
      "train_loss = 87.4599\n",
      "test_loss = 75.6153\n",
      "****************************\n",
      "Epoch: 4375\n",
      "train_loss = 87.4634\n",
      "test_loss = 75.1338\n",
      "****************************\n",
      "Epoch: 4376\n",
      "train_loss = 88.1131\n",
      "test_loss = 77.6798\n",
      "****************************\n",
      "Epoch: 4377\n",
      "train_loss = 88.0082\n",
      "test_loss = 74.3333\n",
      "****************************\n",
      "Epoch: 4378\n",
      "train_loss = 88.4837\n",
      "test_loss = 78.5103\n",
      "****************************\n",
      "Epoch: 4379\n",
      "train_loss = 87.4698\n",
      "test_loss = 75.8671\n",
      "****************************\n",
      "Epoch: 4380\n",
      "train_loss = 87.4464\n",
      "test_loss = 75.2035\n",
      "****************************\n",
      "Epoch: 4381\n",
      "train_loss = 87.7190\n",
      "test_loss = 74.5601\n",
      "****************************\n",
      "Epoch: 4382\n",
      "train_loss = 88.1267\n",
      "test_loss = 77.8627\n",
      "****************************\n",
      "Epoch: 4383\n",
      "train_loss = 87.6782\n",
      "test_loss = 76.3997\n",
      "****************************\n",
      "Epoch: 4384\n",
      "train_loss = 87.4778\n",
      "test_loss = 75.0955\n",
      "****************************\n",
      "Epoch: 4385\n",
      "train_loss = 87.6123\n",
      "test_loss = 76.4213\n",
      "****************************\n",
      "Epoch: 4386\n",
      "train_loss = 87.6071\n",
      "test_loss = 76.4312\n",
      "****************************\n",
      "Epoch: 4387\n",
      "train_loss = 87.6038\n",
      "test_loss = 76.4477\n",
      "****************************\n",
      "Epoch: 4388\n",
      "train_loss = 88.9427\n",
      "test_loss = 79.5151\n",
      "****************************\n",
      "Epoch: 4389\n",
      "train_loss = 87.9813\n",
      "test_loss = 77.4856\n",
      "****************************\n",
      "Epoch: 4390\n",
      "train_loss = 87.5755\n",
      "test_loss = 76.3469\n",
      "****************************\n",
      "Epoch: 4391\n",
      "train_loss = 88.7519\n",
      "test_loss = 79.1286\n",
      "****************************\n",
      "Epoch: 4392\n",
      "train_loss = 87.5238\n",
      "test_loss = 74.9596\n",
      "****************************\n",
      "Epoch: 4393\n",
      "train_loss = 88.4831\n",
      "test_loss = 78.5813\n",
      "****************************\n",
      "Epoch: 4394\n",
      "train_loss = 87.7021\n",
      "test_loss = 76.7018\n",
      "****************************\n",
      "Epoch: 4395\n",
      "train_loss = 87.4696\n",
      "test_loss = 75.4692\n",
      "****************************\n",
      "Epoch: 4396\n",
      "train_loss = 87.4825\n",
      "test_loss = 75.4633\n",
      "****************************\n",
      "Epoch: 4397\n",
      "train_loss = 87.5010\n",
      "test_loss = 75.8167\n",
      "****************************\n",
      "Epoch: 4398\n",
      "train_loss = 87.5894\n",
      "test_loss = 74.8488\n",
      "****************************\n",
      "Epoch: 4399\n",
      "train_loss = 87.6233\n",
      "test_loss = 76.4045\n",
      "****************************\n",
      "Epoch: 4400\n",
      "train_loss = 87.4808\n",
      "test_loss = 75.1673\n",
      "****************************\n",
      "Epoch: 4401\n",
      "train_loss = 87.4586\n",
      "test_loss = 75.5715\n",
      "****************************\n",
      "Epoch: 4402\n",
      "train_loss = 87.5131\n",
      "test_loss = 75.9802\n",
      "****************************\n",
      "Epoch: 4403\n",
      "train_loss = 87.5776\n",
      "test_loss = 76.3877\n",
      "****************************\n",
      "Epoch: 4404\n",
      "train_loss = 87.5142\n",
      "test_loss = 76.1372\n",
      "****************************\n",
      "Epoch: 4405\n",
      "train_loss = 87.9740\n",
      "test_loss = 77.3767\n",
      "****************************\n",
      "Epoch: 4406\n",
      "train_loss = 87.6501\n",
      "test_loss = 74.6794\n",
      "****************************\n",
      "Epoch: 4407\n",
      "train_loss = 87.5364\n",
      "test_loss = 76.1225\n",
      "****************************\n",
      "Epoch: 4408\n",
      "train_loss = 87.4855\n",
      "test_loss = 75.3891\n",
      "****************************\n",
      "Epoch: 4409\n",
      "train_loss = 87.5502\n",
      "test_loss = 76.2535\n",
      "****************************\n",
      "Epoch: 4410\n",
      "train_loss = 87.4747\n",
      "test_loss = 75.2620\n",
      "****************************\n",
      "Epoch: 4411\n",
      "train_loss = 88.1389\n",
      "test_loss = 77.7438\n",
      "****************************\n",
      "Epoch: 4412\n",
      "train_loss = 88.9393\n",
      "test_loss = 79.5460\n",
      "****************************\n",
      "Epoch: 4413\n",
      "train_loss = 87.6438\n",
      "test_loss = 74.6701\n",
      "****************************\n",
      "Epoch: 4414\n",
      "train_loss = 87.5514\n",
      "test_loss = 76.2085\n",
      "****************************\n",
      "Epoch: 4415\n",
      "train_loss = 89.2821\n",
      "test_loss = 79.8547\n",
      "****************************\n",
      "Epoch: 4416\n",
      "train_loss = 87.9068\n",
      "test_loss = 76.9980\n",
      "****************************\n",
      "Epoch: 4417\n",
      "train_loss = 87.8420\n",
      "test_loss = 74.5575\n",
      "****************************\n",
      "Epoch: 4418\n",
      "train_loss = 87.5776\n",
      "test_loss = 74.8851\n",
      "****************************\n",
      "Epoch: 4419\n",
      "train_loss = 87.4679\n",
      "test_loss = 75.3617\n",
      "****************************\n",
      "Epoch: 4420\n",
      "train_loss = 88.3782\n",
      "test_loss = 78.4635\n",
      "****************************\n",
      "Epoch: 4421\n",
      "train_loss = 87.9543\n",
      "test_loss = 77.3537\n",
      "****************************\n",
      "Epoch: 4422\n",
      "train_loss = 87.5191\n",
      "test_loss = 75.9573\n",
      "****************************\n",
      "Epoch: 4423\n",
      "train_loss = 87.5659\n",
      "test_loss = 76.2248\n",
      "****************************\n",
      "Epoch: 4424\n",
      "train_loss = 88.8630\n",
      "test_loss = 79.2022\n",
      "****************************\n",
      "Epoch: 4425\n",
      "train_loss = 87.4687\n",
      "test_loss = 75.1757\n",
      "****************************\n",
      "Epoch: 4426\n",
      "train_loss = 87.5818\n",
      "test_loss = 76.2979\n",
      "****************************\n",
      "Epoch: 4427\n",
      "train_loss = 87.4737\n",
      "test_loss = 75.3446\n",
      "****************************\n",
      "Epoch: 4428\n",
      "train_loss = 87.4853\n",
      "test_loss = 75.5013\n",
      "****************************\n",
      "Epoch: 4429\n",
      "train_loss = 87.4823\n",
      "test_loss = 75.7411\n",
      "****************************\n",
      "Epoch: 4430\n",
      "train_loss = 87.5368\n",
      "test_loss = 74.8663\n",
      "****************************\n",
      "Epoch: 4431\n",
      "train_loss = 87.6927\n",
      "test_loss = 74.6100\n",
      "****************************\n",
      "Epoch: 4432\n",
      "train_loss = 87.5797\n",
      "test_loss = 76.4743\n",
      "****************************\n",
      "Epoch: 4433\n",
      "train_loss = 87.6125\n",
      "test_loss = 76.6098\n",
      "****************************\n",
      "Epoch: 4434\n",
      "train_loss = 87.4269\n",
      "test_loss = 75.4100\n",
      "****************************\n",
      "Epoch: 4435\n",
      "train_loss = 87.7780\n",
      "test_loss = 74.4844\n",
      "****************************\n",
      "Epoch: 4436\n",
      "train_loss = 87.8221\n",
      "test_loss = 77.1704\n",
      "****************************\n",
      "Epoch: 4437\n",
      "train_loss = 87.5694\n",
      "test_loss = 76.3499\n",
      "****************************\n",
      "Epoch: 4438\n",
      "train_loss = 88.1455\n",
      "test_loss = 74.2296\n",
      "****************************\n",
      "Epoch: 4439\n",
      "train_loss = 87.4774\n",
      "test_loss = 75.2350\n",
      "****************************\n",
      "Epoch: 4440\n",
      "train_loss = 87.4871\n",
      "test_loss = 75.1477\n",
      "****************************\n",
      "Epoch: 4441\n",
      "train_loss = 87.4962\n",
      "test_loss = 75.0194\n",
      "****************************\n",
      "Epoch: 4442\n",
      "train_loss = 87.5226\n",
      "test_loss = 74.9183\n",
      "****************************\n",
      "Epoch: 4443\n",
      "train_loss = 87.4421\n",
      "test_loss = 75.3136\n",
      "****************************\n",
      "Epoch: 4444\n",
      "train_loss = 87.4615\n",
      "test_loss = 75.8915\n",
      "****************************\n",
      "Epoch: 4445\n",
      "train_loss = 87.5049\n",
      "test_loss = 74.8897\n",
      "****************************\n",
      "Epoch: 4446\n",
      "train_loss = 87.9074\n",
      "test_loss = 77.3208\n",
      "****************************\n",
      "Epoch: 4447\n",
      "train_loss = 87.4883\n",
      "test_loss = 75.9610\n",
      "****************************\n",
      "Epoch: 4448\n",
      "train_loss = 87.4895\n",
      "test_loss = 75.2600\n",
      "****************************\n",
      "Epoch: 4449\n",
      "train_loss = 88.0357\n",
      "test_loss = 74.4279\n",
      "****************************\n",
      "Epoch: 4450\n",
      "train_loss = 88.0500\n",
      "test_loss = 77.6214\n",
      "****************************\n",
      "Epoch: 4451\n",
      "train_loss = 87.5673\n",
      "test_loss = 74.8404\n",
      "****************************\n",
      "Epoch: 4452\n",
      "train_loss = 87.4993\n",
      "test_loss = 75.9639\n",
      "****************************\n",
      "Epoch: 4453\n",
      "train_loss = 87.4511\n",
      "test_loss = 75.3342\n",
      "****************************\n",
      "Epoch: 4454\n",
      "train_loss = 87.5475\n",
      "test_loss = 74.8237\n",
      "****************************\n",
      "Epoch: 4455\n",
      "train_loss = 87.5085\n",
      "test_loss = 75.2022\n",
      "****************************\n",
      "Epoch: 4456\n",
      "train_loss = 87.5879\n",
      "test_loss = 74.7646\n",
      "****************************\n",
      "Epoch: 4457\n",
      "train_loss = 88.6511\n",
      "test_loss = 78.7153\n",
      "****************************\n",
      "Epoch: 4458\n",
      "train_loss = 88.1716\n",
      "test_loss = 74.2456\n",
      "****************************\n",
      "Epoch: 4459\n",
      "train_loss = 88.0433\n",
      "test_loss = 77.5857\n",
      "****************************\n",
      "Epoch: 4460\n",
      "train_loss = 87.7664\n",
      "test_loss = 74.4974\n",
      "****************************\n",
      "Epoch: 4461\n",
      "train_loss = 87.4902\n",
      "test_loss = 75.5185\n",
      "****************************\n",
      "Epoch: 4462\n",
      "train_loss = 88.8620\n",
      "test_loss = 79.0670\n",
      "****************************\n",
      "Epoch: 4463\n",
      "train_loss = 87.7023\n",
      "test_loss = 76.8291\n",
      "****************************\n",
      "Epoch: 4464\n",
      "train_loss = 87.4396\n",
      "test_loss = 75.2563\n",
      "****************************\n",
      "Epoch: 4465\n",
      "train_loss = 87.4403\n",
      "test_loss = 75.1756\n",
      "****************************\n",
      "Epoch: 4466\n",
      "train_loss = 87.4500\n",
      "test_loss = 75.0907\n",
      "****************************\n",
      "Epoch: 4467\n",
      "train_loss = 87.4227\n",
      "test_loss = 75.4086\n",
      "****************************\n",
      "Epoch: 4468\n",
      "train_loss = 87.5206\n",
      "test_loss = 76.1950\n",
      "****************************\n",
      "Epoch: 4469\n",
      "train_loss = 87.5945\n",
      "test_loss = 76.5086\n",
      "****************************\n",
      "Epoch: 4470\n",
      "train_loss = 87.7474\n",
      "test_loss = 74.5323\n",
      "****************************\n",
      "Epoch: 4471\n",
      "train_loss = 87.4549\n",
      "test_loss = 75.4963\n",
      "****************************\n",
      "Epoch: 4472\n",
      "train_loss = 87.5634\n",
      "test_loss = 76.3471\n",
      "****************************\n",
      "Epoch: 4473\n",
      "train_loss = 87.5228\n",
      "test_loss = 76.1341\n",
      "****************************\n",
      "Epoch: 4474\n",
      "train_loss = 88.3299\n",
      "test_loss = 74.2451\n",
      "****************************\n",
      "Epoch: 4475\n",
      "train_loss = 87.7224\n",
      "test_loss = 74.5512\n",
      "****************************\n",
      "Epoch: 4476\n",
      "train_loss = 87.4927\n",
      "test_loss = 75.1015\n",
      "****************************\n",
      "Epoch: 4477\n",
      "train_loss = 87.5196\n",
      "test_loss = 74.9302\n",
      "****************************\n",
      "Epoch: 4478\n",
      "train_loss = 87.4501\n",
      "test_loss = 75.2623\n",
      "****************************\n",
      "Epoch: 4479\n",
      "train_loss = 87.9292\n",
      "test_loss = 74.3551\n",
      "****************************\n",
      "Epoch: 4480\n",
      "train_loss = 88.2608\n",
      "test_loss = 78.0266\n",
      "****************************\n",
      "Epoch: 4481\n",
      "train_loss = 87.4586\n",
      "test_loss = 75.1822\n",
      "****************************\n",
      "Epoch: 4482\n",
      "train_loss = 87.6767\n",
      "test_loss = 76.4116\n",
      "****************************\n",
      "Epoch: 4483\n",
      "train_loss = 87.6419\n",
      "test_loss = 76.4511\n",
      "****************************\n",
      "Epoch: 4484\n",
      "train_loss = 87.4959\n",
      "test_loss = 75.1796\n",
      "****************************\n",
      "Epoch: 4485\n",
      "train_loss = 87.5432\n",
      "test_loss = 74.9414\n",
      "****************************\n",
      "Epoch: 4486\n",
      "train_loss = 87.4746\n",
      "test_loss = 75.1692\n",
      "****************************\n",
      "Epoch: 4487\n",
      "train_loss = 87.7504\n",
      "test_loss = 74.5424\n",
      "****************************\n",
      "Epoch: 4488\n",
      "train_loss = 88.1025\n",
      "test_loss = 77.6284\n",
      "****************************\n",
      "Epoch: 4489\n",
      "train_loss = 87.6994\n",
      "test_loss = 76.7062\n",
      "****************************\n",
      "Epoch: 4490\n",
      "train_loss = 87.5004\n",
      "test_loss = 75.3144\n",
      "****************************\n",
      "Epoch: 4491\n",
      "train_loss = 88.2957\n",
      "test_loss = 77.9307\n",
      "****************************\n",
      "Epoch: 4492\n",
      "train_loss = 87.4931\n",
      "test_loss = 75.3022\n",
      "****************************\n",
      "Epoch: 4493\n",
      "train_loss = 87.4727\n",
      "test_loss = 75.1996\n",
      "****************************\n",
      "Epoch: 4494\n",
      "train_loss = 87.4329\n",
      "test_loss = 75.4619\n",
      "****************************\n",
      "Epoch: 4495\n",
      "train_loss = 87.4654\n",
      "test_loss = 75.3866\n",
      "****************************\n",
      "Epoch: 4496\n",
      "train_loss = 87.6620\n",
      "test_loss = 74.6465\n",
      "****************************\n",
      "Epoch: 4497\n",
      "train_loss = 87.4484\n",
      "test_loss = 75.2355\n",
      "****************************\n",
      "Epoch: 4498\n",
      "train_loss = 87.6873\n",
      "test_loss = 74.5851\n",
      "****************************\n",
      "Epoch: 4499\n",
      "train_loss = 88.0821\n",
      "test_loss = 77.4533\n",
      "****************************\n",
      "Epoch: 4500\n",
      "train_loss = 87.7281\n",
      "test_loss = 76.6795\n",
      "****************************\n",
      "Epoch: 4501\n",
      "train_loss = 87.6246\n",
      "test_loss = 74.7046\n",
      "****************************\n",
      "Epoch: 4502\n",
      "train_loss = 87.4859\n",
      "test_loss = 75.8630\n",
      "****************************\n",
      "Epoch: 4503\n",
      "train_loss = 87.5779\n",
      "test_loss = 76.3252\n",
      "****************************\n",
      "Epoch: 4504\n",
      "train_loss = 87.6574\n",
      "test_loss = 74.6182\n",
      "****************************\n",
      "Epoch: 4505\n",
      "train_loss = 87.6331\n",
      "test_loss = 74.6754\n",
      "****************************\n",
      "Epoch: 4506\n",
      "train_loss = 87.5592\n",
      "test_loss = 76.2979\n",
      "****************************\n",
      "Epoch: 4507\n",
      "train_loss = 87.5187\n",
      "test_loss = 76.1087\n",
      "****************************\n",
      "Epoch: 4508\n",
      "train_loss = 87.4596\n",
      "test_loss = 75.7162\n",
      "****************************\n",
      "Epoch: 4509\n",
      "train_loss = 87.9731\n",
      "test_loss = 77.5748\n",
      "****************************\n",
      "Epoch: 4510\n",
      "train_loss = 87.8798\n",
      "test_loss = 74.4302\n",
      "****************************\n",
      "Epoch: 4511\n",
      "train_loss = 87.6343\n",
      "test_loss = 75.7977\n",
      "****************************\n",
      "Epoch: 4512\n",
      "train_loss = 87.6118\n",
      "test_loss = 74.8912\n",
      "****************************\n",
      "Epoch: 4513\n",
      "train_loss = 87.5680\n",
      "test_loss = 76.0100\n",
      "****************************\n",
      "Epoch: 4514\n",
      "train_loss = 87.5758\n",
      "test_loss = 75.7893\n",
      "****************************\n",
      "Epoch: 4515\n",
      "train_loss = 88.2077\n",
      "test_loss = 77.8436\n",
      "****************************\n",
      "Epoch: 4516\n",
      "train_loss = 88.4389\n",
      "test_loss = 74.2383\n",
      "****************************\n",
      "Epoch: 4517\n",
      "train_loss = 87.5392\n",
      "test_loss = 75.0163\n",
      "****************************\n",
      "Epoch: 4518\n",
      "train_loss = 87.4954\n",
      "test_loss = 75.2240\n",
      "****************************\n",
      "Epoch: 4519\n",
      "train_loss = 87.6452\n",
      "test_loss = 76.5026\n",
      "****************************\n",
      "Epoch: 4520\n",
      "train_loss = 87.6046\n",
      "test_loss = 74.8438\n",
      "****************************\n",
      "Epoch: 4521\n",
      "train_loss = 87.5431\n",
      "test_loss = 75.9986\n",
      "****************************\n",
      "Epoch: 4522\n",
      "train_loss = 87.6858\n",
      "test_loss = 76.4084\n",
      "****************************\n",
      "Epoch: 4523\n",
      "train_loss = 87.5474\n",
      "test_loss = 75.4767\n",
      "****************************\n",
      "Epoch: 4524\n",
      "train_loss = 87.9210\n",
      "test_loss = 77.1068\n",
      "****************************\n",
      "Epoch: 4525\n",
      "train_loss = 87.5447\n",
      "test_loss = 76.2241\n",
      "****************************\n",
      "Epoch: 4526\n",
      "train_loss = 87.6643\n",
      "test_loss = 76.6827\n",
      "****************************\n",
      "Epoch: 4527\n",
      "train_loss = 87.7527\n",
      "test_loss = 74.4872\n",
      "****************************\n",
      "Epoch: 4528\n",
      "train_loss = 87.6612\n",
      "test_loss = 74.5773\n",
      "****************************\n",
      "Epoch: 4529\n",
      "train_loss = 87.8587\n",
      "test_loss = 77.2003\n",
      "****************************\n",
      "Epoch: 4530\n",
      "train_loss = 87.7057\n",
      "test_loss = 74.5287\n",
      "****************************\n",
      "Epoch: 4531\n",
      "train_loss = 87.6196\n",
      "test_loss = 74.6490\n",
      "****************************\n",
      "Epoch: 4532\n",
      "train_loss = 87.4408\n",
      "test_loss = 75.6460\n",
      "****************************\n",
      "Epoch: 4533\n",
      "train_loss = 87.6843\n",
      "test_loss = 74.6090\n",
      "****************************\n",
      "Epoch: 4534\n",
      "train_loss = 87.9935\n",
      "test_loss = 77.5639\n",
      "****************************\n",
      "Epoch: 4535\n",
      "train_loss = 87.4495\n",
      "test_loss = 75.3848\n",
      "****************************\n",
      "Epoch: 4536\n",
      "train_loss = 87.5817\n",
      "test_loss = 74.6882\n",
      "****************************\n",
      "Epoch: 4537\n",
      "train_loss = 87.6255\n",
      "test_loss = 76.4386\n",
      "****************************\n",
      "Epoch: 4538\n",
      "train_loss = 88.7810\n",
      "test_loss = 79.1022\n",
      "****************************\n",
      "Epoch: 4539\n",
      "train_loss = 87.4803\n",
      "test_loss = 75.0708\n",
      "****************************\n",
      "Epoch: 4540\n",
      "train_loss = 87.4799\n",
      "test_loss = 75.0215\n",
      "****************************\n",
      "Epoch: 4541\n",
      "train_loss = 87.4150\n",
      "test_loss = 75.3217\n",
      "****************************\n",
      "Epoch: 4542\n",
      "train_loss = 87.4632\n",
      "test_loss = 75.9054\n",
      "****************************\n",
      "Epoch: 4543\n",
      "train_loss = 87.4635\n",
      "test_loss = 75.8517\n",
      "****************************\n",
      "Epoch: 4544\n",
      "train_loss = 88.2556\n",
      "test_loss = 78.1661\n",
      "****************************\n",
      "Epoch: 4545\n",
      "train_loss = 87.4613\n",
      "test_loss = 75.4691\n",
      "****************************\n",
      "Epoch: 4546\n",
      "train_loss = 87.4370\n",
      "test_loss = 75.2274\n",
      "****************************\n",
      "Epoch: 4547\n",
      "train_loss = 87.6486\n",
      "test_loss = 76.5847\n",
      "****************************\n",
      "Epoch: 4548\n",
      "train_loss = 87.9552\n",
      "test_loss = 77.3240\n",
      "****************************\n",
      "Epoch: 4549\n",
      "train_loss = 87.4432\n",
      "test_loss = 75.5855\n",
      "****************************\n",
      "Epoch: 4550\n",
      "train_loss = 87.4351\n",
      "test_loss = 75.2539\n",
      "****************************\n",
      "Epoch: 4551\n",
      "train_loss = 87.5052\n",
      "test_loss = 75.9994\n",
      "****************************\n",
      "Epoch: 4552\n",
      "train_loss = 88.1952\n",
      "test_loss = 77.2378\n",
      "****************************\n",
      "Epoch: 4553\n",
      "train_loss = 87.5246\n",
      "test_loss = 75.2434\n",
      "****************************\n",
      "Epoch: 4554\n",
      "train_loss = 87.6658\n",
      "test_loss = 74.6774\n",
      "****************************\n",
      "Epoch: 4555\n",
      "train_loss = 87.5283\n",
      "test_loss = 75.9964\n",
      "****************************\n",
      "Epoch: 4556\n",
      "train_loss = 87.5432\n",
      "test_loss = 76.1269\n",
      "****************************\n",
      "Epoch: 4557\n",
      "train_loss = 87.6784\n",
      "test_loss = 76.5054\n",
      "****************************\n",
      "Epoch: 4558\n",
      "train_loss = 87.6848\n",
      "test_loss = 74.7029\n",
      "****************************\n",
      "Epoch: 4559\n",
      "train_loss = 87.7497\n",
      "test_loss = 76.4026\n",
      "****************************\n",
      "Epoch: 4560\n",
      "train_loss = 87.6328\n",
      "test_loss = 74.8124\n",
      "****************************\n",
      "Epoch: 4561\n",
      "train_loss = 87.5135\n",
      "test_loss = 75.1105\n",
      "****************************\n",
      "Epoch: 4562\n",
      "train_loss = 87.8761\n",
      "test_loss = 77.0951\n",
      "****************************\n",
      "Epoch: 4563\n",
      "train_loss = 87.7372\n",
      "test_loss = 74.5348\n",
      "****************************\n",
      "Epoch: 4564\n",
      "train_loss = 88.2708\n",
      "test_loss = 74.2299\n",
      "****************************\n",
      "Epoch: 4565\n",
      "train_loss = 87.5685\n",
      "test_loss = 76.1685\n",
      "****************************\n",
      "Epoch: 4566\n",
      "train_loss = 87.6276\n",
      "test_loss = 76.4301\n",
      "****************************\n",
      "Epoch: 4567\n",
      "train_loss = 87.5715\n",
      "test_loss = 74.8207\n",
      "****************************\n",
      "Epoch: 4568\n",
      "train_loss = 87.5101\n",
      "test_loss = 75.2487\n",
      "****************************\n",
      "Epoch: 4569\n",
      "train_loss = 87.5576\n",
      "test_loss = 76.3419\n",
      "****************************\n",
      "Epoch: 4570\n",
      "train_loss = 87.4828\n",
      "test_loss = 75.6169\n",
      "****************************\n",
      "Epoch: 4571\n",
      "train_loss = 88.3517\n",
      "test_loss = 78.2373\n",
      "****************************\n",
      "Epoch: 4572\n",
      "train_loss = 88.1398\n",
      "test_loss = 74.2990\n",
      "****************************\n",
      "Epoch: 4573\n",
      "train_loss = 87.4669\n",
      "test_loss = 75.1479\n",
      "****************************\n",
      "Epoch: 4574\n",
      "train_loss = 87.4796\n",
      "test_loss = 75.8384\n",
      "****************************\n",
      "Epoch: 4575\n",
      "train_loss = 87.5705\n",
      "test_loss = 74.8115\n",
      "****************************\n",
      "Epoch: 4576\n",
      "train_loss = 87.6295\n",
      "test_loss = 74.6958\n",
      "****************************\n",
      "Epoch: 4577\n",
      "train_loss = 87.4880\n",
      "test_loss = 75.0974\n",
      "****************************\n",
      "Epoch: 4578\n",
      "train_loss = 87.4791\n",
      "test_loss = 75.9196\n",
      "****************************\n",
      "Epoch: 4579\n",
      "train_loss = 87.5894\n",
      "test_loss = 74.7711\n",
      "****************************\n",
      "Epoch: 4580\n",
      "train_loss = 87.5807\n",
      "test_loss = 76.4110\n",
      "****************************\n",
      "Epoch: 4581\n",
      "train_loss = 87.7371\n",
      "test_loss = 74.5152\n",
      "****************************\n",
      "Epoch: 4582\n",
      "train_loss = 87.5575\n",
      "test_loss = 74.7771\n",
      "****************************\n",
      "Epoch: 4583\n",
      "train_loss = 87.4589\n",
      "test_loss = 75.7254\n",
      "****************************\n",
      "Epoch: 4584\n",
      "train_loss = 87.5314\n",
      "test_loss = 74.8283\n",
      "****************************\n",
      "Epoch: 4585\n",
      "train_loss = 87.6258\n",
      "test_loss = 76.4535\n",
      "****************************\n",
      "Epoch: 4586\n",
      "train_loss = 87.5287\n",
      "test_loss = 76.1228\n",
      "****************************\n",
      "Epoch: 4587\n",
      "train_loss = 87.5656\n",
      "test_loss = 76.1386\n",
      "****************************\n",
      "Epoch: 4588\n",
      "train_loss = 87.7586\n",
      "test_loss = 74.4799\n",
      "****************************\n",
      "Epoch: 4589\n",
      "train_loss = 87.5353\n",
      "test_loss = 75.8022\n",
      "****************************\n",
      "Epoch: 4590\n",
      "train_loss = 87.5482\n",
      "test_loss = 74.8844\n",
      "****************************\n",
      "Epoch: 4591\n",
      "train_loss = 87.7126\n",
      "test_loss = 76.5950\n",
      "****************************\n",
      "Epoch: 4592\n",
      "train_loss = 87.5357\n",
      "test_loss = 75.0402\n",
      "****************************\n",
      "Epoch: 4593\n",
      "train_loss = 87.7076\n",
      "test_loss = 76.5942\n",
      "****************************\n",
      "Epoch: 4594\n",
      "train_loss = 88.0679\n",
      "test_loss = 74.3038\n",
      "****************************\n",
      "Epoch: 4595\n",
      "train_loss = 87.5609\n",
      "test_loss = 74.8457\n",
      "****************************\n",
      "Epoch: 4596\n",
      "train_loss = 87.5250\n",
      "test_loss = 74.8419\n",
      "****************************\n",
      "Epoch: 4597\n",
      "train_loss = 87.4656\n",
      "test_loss = 75.0785\n",
      "****************************\n",
      "Epoch: 4598\n",
      "train_loss = 87.4909\n",
      "test_loss = 75.0371\n",
      "****************************\n",
      "Epoch: 4599\n",
      "train_loss = 88.6054\n",
      "test_loss = 78.6872\n",
      "****************************\n",
      "Epoch: 4600\n",
      "train_loss = 87.5588\n",
      "test_loss = 76.2024\n",
      "****************************\n",
      "Epoch: 4601\n",
      "train_loss = 88.5476\n",
      "test_loss = 78.6103\n",
      "****************************\n",
      "Epoch: 4602\n",
      "train_loss = 87.4594\n",
      "test_loss = 75.3628\n",
      "****************************\n",
      "Epoch: 4603\n",
      "train_loss = 87.5321\n",
      "test_loss = 74.9501\n",
      "****************************\n",
      "Epoch: 4604\n",
      "train_loss = 90.2217\n",
      "test_loss = 74.6477\n",
      "****************************\n",
      "Epoch: 4605\n",
      "train_loss = 87.5161\n",
      "test_loss = 75.7045\n",
      "****************************\n",
      "Epoch: 4606\n",
      "train_loss = 88.3967\n",
      "test_loss = 78.3768\n",
      "****************************\n",
      "Epoch: 4607\n",
      "train_loss = 87.5422\n",
      "test_loss = 76.0266\n",
      "****************************\n",
      "Epoch: 4608\n",
      "train_loss = 88.7170\n",
      "test_loss = 74.4627\n",
      "****************************\n",
      "Epoch: 4609\n",
      "train_loss = 88.4090\n",
      "test_loss = 78.1982\n",
      "****************************\n",
      "Epoch: 4610\n",
      "train_loss = 87.5371\n",
      "test_loss = 75.2758\n",
      "****************************\n",
      "Epoch: 4611\n",
      "train_loss = 87.5195\n",
      "test_loss = 75.0689\n",
      "****************************\n",
      "Epoch: 4612\n",
      "train_loss = 87.4507\n",
      "test_loss = 75.4812\n",
      "****************************\n",
      "Epoch: 4613\n",
      "train_loss = 87.7396\n",
      "test_loss = 76.9582\n",
      "****************************\n",
      "Epoch: 4614\n",
      "train_loss = 87.4362\n",
      "test_loss = 75.6028\n",
      "****************************\n",
      "Epoch: 4615\n",
      "train_loss = 87.4899\n",
      "test_loss = 76.1153\n",
      "****************************\n",
      "Epoch: 4616\n",
      "train_loss = 87.4408\n",
      "test_loss = 75.5642\n",
      "****************************\n",
      "Epoch: 4617\n",
      "train_loss = 87.5365\n",
      "test_loss = 75.1356\n",
      "****************************\n",
      "Epoch: 4618\n",
      "train_loss = 87.4666\n",
      "test_loss = 75.3125\n",
      "****************************\n",
      "Epoch: 4619\n",
      "train_loss = 88.8348\n",
      "test_loss = 79.2109\n",
      "****************************\n",
      "Epoch: 4620\n",
      "train_loss = 87.5891\n",
      "test_loss = 76.4876\n",
      "****************************\n",
      "Epoch: 4621\n",
      "train_loss = 87.4459\n",
      "test_loss = 75.1738\n",
      "****************************\n",
      "Epoch: 4622\n",
      "train_loss = 87.5098\n",
      "test_loss = 76.1817\n",
      "****************************\n",
      "Epoch: 4623\n",
      "train_loss = 87.5493\n",
      "test_loss = 74.7412\n",
      "****************************\n",
      "Epoch: 4624\n",
      "train_loss = 88.2275\n",
      "test_loss = 77.9141\n",
      "****************************\n",
      "Epoch: 4625\n",
      "train_loss = 87.7072\n",
      "test_loss = 74.5588\n",
      "****************************\n",
      "Epoch: 4626\n",
      "train_loss = 87.8211\n",
      "test_loss = 77.1217\n",
      "****************************\n",
      "Epoch: 4627\n",
      "train_loss = 87.5623\n",
      "test_loss = 74.7381\n",
      "****************************\n",
      "Epoch: 4628\n",
      "train_loss = 88.2927\n",
      "test_loss = 78.1837\n",
      "****************************\n",
      "Epoch: 4629\n",
      "train_loss = 87.7189\n",
      "test_loss = 74.5584\n",
      "****************************\n",
      "Epoch: 4630\n",
      "train_loss = 87.4765\n",
      "test_loss = 75.2515\n",
      "****************************\n",
      "Epoch: 4631\n",
      "train_loss = 87.5715\n",
      "test_loss = 76.2055\n",
      "****************************\n",
      "Epoch: 4632\n",
      "train_loss = 87.5329\n",
      "test_loss = 74.9517\n",
      "****************************\n",
      "Epoch: 4633\n",
      "train_loss = 87.6071\n",
      "test_loss = 74.6840\n",
      "****************************\n",
      "Epoch: 4634\n",
      "train_loss = 88.0938\n",
      "test_loss = 77.6088\n",
      "****************************\n",
      "Epoch: 4635\n",
      "train_loss = 87.7911\n",
      "test_loss = 74.4521\n",
      "****************************\n",
      "Epoch: 4636\n",
      "train_loss = 87.7770\n",
      "test_loss = 74.5079\n",
      "****************************\n",
      "Epoch: 4637\n",
      "train_loss = 87.7853\n",
      "test_loss = 74.5511\n",
      "****************************\n",
      "Epoch: 4638\n",
      "train_loss = 87.5084\n",
      "test_loss = 75.9215\n",
      "****************************\n",
      "Epoch: 4639\n",
      "train_loss = 87.4971\n",
      "test_loss = 75.8166\n",
      "****************************\n",
      "Epoch: 4640\n",
      "train_loss = 87.4958\n",
      "test_loss = 75.0262\n",
      "****************************\n",
      "Epoch: 4641\n",
      "train_loss = 87.6187\n",
      "test_loss = 74.6869\n",
      "****************************\n",
      "Epoch: 4642\n",
      "train_loss = 87.6648\n",
      "test_loss = 74.9674\n",
      "****************************\n",
      "Epoch: 4643\n",
      "train_loss = 87.5425\n",
      "test_loss = 75.1030\n",
      "****************************\n",
      "Epoch: 4644\n",
      "train_loss = 87.6502\n",
      "test_loss = 76.3670\n",
      "****************************\n",
      "Epoch: 4645\n",
      "train_loss = 87.7216\n",
      "test_loss = 76.7020\n",
      "****************************\n",
      "Epoch: 4646\n",
      "train_loss = 87.8034\n",
      "test_loss = 74.5101\n",
      "****************************\n",
      "Epoch: 4647\n",
      "train_loss = 88.4857\n",
      "test_loss = 78.5902\n",
      "****************************\n",
      "Epoch: 4648\n",
      "train_loss = 88.3354\n",
      "test_loss = 78.3033\n",
      "****************************\n",
      "Epoch: 4649\n",
      "train_loss = 88.2761\n",
      "test_loss = 78.1627\n",
      "****************************\n",
      "Epoch: 4650\n",
      "train_loss = 87.9503\n",
      "test_loss = 74.5173\n",
      "****************************\n",
      "Epoch: 4651\n",
      "train_loss = 87.9710\n",
      "test_loss = 77.1422\n",
      "****************************\n",
      "Epoch: 4652\n",
      "train_loss = 87.5482\n",
      "test_loss = 75.8637\n",
      "****************************\n",
      "Epoch: 4653\n",
      "train_loss = 88.1004\n",
      "test_loss = 74.3322\n",
      "****************************\n",
      "Epoch: 4654\n",
      "train_loss = 87.7142\n",
      "test_loss = 74.6286\n",
      "****************************\n",
      "Epoch: 4655\n",
      "train_loss = 87.6042\n",
      "test_loss = 74.7476\n",
      "****************************\n",
      "Epoch: 4656\n",
      "train_loss = 87.6398\n",
      "test_loss = 76.2718\n",
      "****************************\n",
      "Epoch: 4657\n",
      "train_loss = 87.4383\n",
      "test_loss = 75.4833\n",
      "****************************\n",
      "Epoch: 4658\n",
      "train_loss = 87.4482\n",
      "test_loss = 75.4287\n",
      "****************************\n",
      "Epoch: 4659\n",
      "train_loss = 87.7222\n",
      "test_loss = 76.7896\n",
      "****************************\n",
      "Epoch: 4660\n",
      "train_loss = 87.6280\n",
      "test_loss = 74.6752\n",
      "****************************\n",
      "Epoch: 4661\n",
      "train_loss = 87.4792\n",
      "test_loss = 75.7303\n",
      "****************************\n",
      "Epoch: 4662\n",
      "train_loss = 87.4971\n",
      "test_loss = 75.9882\n",
      "****************************\n",
      "Epoch: 4663\n",
      "train_loss = 87.5360\n",
      "test_loss = 74.9786\n",
      "****************************\n",
      "Epoch: 4664\n",
      "train_loss = 87.6606\n",
      "test_loss = 76.3777\n",
      "****************************\n",
      "Epoch: 4665\n",
      "train_loss = 87.5332\n",
      "test_loss = 75.9404\n",
      "****************************\n",
      "Epoch: 4666\n",
      "train_loss = 87.9410\n",
      "test_loss = 74.3775\n",
      "****************************\n",
      "Epoch: 4667\n",
      "train_loss = 87.4647\n",
      "test_loss = 75.1787\n",
      "****************************\n",
      "Epoch: 4668\n",
      "train_loss = 87.5203\n",
      "test_loss = 74.8890\n",
      "****************************\n",
      "Epoch: 4669\n",
      "train_loss = 87.8306\n",
      "test_loss = 74.4137\n",
      "****************************\n",
      "Epoch: 4670\n",
      "train_loss = 87.5191\n",
      "test_loss = 75.4694\n",
      "****************************\n",
      "Epoch: 4671\n",
      "train_loss = 88.2513\n",
      "test_loss = 74.2095\n",
      "****************************\n",
      "Epoch: 4672\n",
      "train_loss = 87.4985\n",
      "test_loss = 75.5434\n",
      "****************************\n",
      "Epoch: 4673\n",
      "train_loss = 87.9757\n",
      "test_loss = 74.3233\n",
      "****************************\n",
      "Epoch: 4674\n",
      "train_loss = 87.7984\n",
      "test_loss = 76.9448\n",
      "****************************\n",
      "Epoch: 4675\n",
      "train_loss = 87.6644\n",
      "test_loss = 76.4752\n",
      "****************************\n",
      "Epoch: 4676\n",
      "train_loss = 87.5521\n",
      "test_loss = 76.0964\n",
      "****************************\n",
      "Epoch: 4677\n",
      "train_loss = 88.4143\n",
      "test_loss = 78.3842\n",
      "****************************\n",
      "Epoch: 4678\n",
      "train_loss = 87.6095\n",
      "test_loss = 74.7542\n",
      "****************************\n",
      "Epoch: 4679\n",
      "train_loss = 87.6510\n",
      "test_loss = 76.4524\n",
      "****************************\n",
      "Epoch: 4680\n",
      "train_loss = 87.5247\n",
      "test_loss = 75.0490\n",
      "****************************\n",
      "Epoch: 4681\n",
      "train_loss = 87.5655\n",
      "test_loss = 76.2183\n",
      "****************************\n",
      "Epoch: 4682\n",
      "train_loss = 87.4717\n",
      "test_loss = 75.4420\n",
      "****************************\n",
      "Epoch: 4683\n",
      "train_loss = 87.4599\n",
      "test_loss = 75.4491\n",
      "****************************\n",
      "Epoch: 4684\n",
      "train_loss = 87.5778\n",
      "test_loss = 76.3105\n",
      "****************************\n",
      "Epoch: 4685\n",
      "train_loss = 87.4363\n",
      "test_loss = 75.4351\n",
      "****************************\n",
      "Epoch: 4686\n",
      "train_loss = 87.4433\n",
      "test_loss = 75.6579\n",
      "****************************\n",
      "Epoch: 4687\n",
      "train_loss = 88.2405\n",
      "test_loss = 74.2377\n",
      "****************************\n",
      "Epoch: 4688\n",
      "train_loss = 87.4999\n",
      "test_loss = 74.9438\n",
      "****************************\n",
      "Epoch: 4689\n",
      "train_loss = 87.6313\n",
      "test_loss = 74.6553\n",
      "****************************\n",
      "Epoch: 4690\n",
      "train_loss = 87.5059\n",
      "test_loss = 75.8679\n",
      "****************************\n",
      "Epoch: 4691\n",
      "train_loss = 87.6391\n",
      "test_loss = 74.6318\n",
      "****************************\n",
      "Epoch: 4692\n",
      "train_loss = 87.7432\n",
      "test_loss = 76.7744\n",
      "****************************\n",
      "Epoch: 4693\n",
      "train_loss = 87.7061\n",
      "test_loss = 76.6834\n",
      "****************************\n",
      "Epoch: 4694\n",
      "train_loss = 88.3832\n",
      "test_loss = 78.2731\n",
      "****************************\n",
      "Epoch: 4695\n",
      "train_loss = 87.6764\n",
      "test_loss = 76.5596\n",
      "****************************\n",
      "Epoch: 4696\n",
      "train_loss = 87.7542\n",
      "test_loss = 74.5234\n",
      "****************************\n",
      "Epoch: 4697\n",
      "train_loss = 87.4469\n",
      "test_loss = 75.2534\n",
      "****************************\n",
      "Epoch: 4698\n",
      "train_loss = 87.5471\n",
      "test_loss = 74.7966\n",
      "****************************\n",
      "Epoch: 4699\n",
      "train_loss = 87.4582\n",
      "test_loss = 75.1884\n",
      "****************************\n",
      "Epoch: 4700\n",
      "train_loss = 87.4288\n",
      "test_loss = 75.5432\n",
      "****************************\n",
      "Epoch: 4701\n",
      "train_loss = 89.2869\n",
      "test_loss = 80.0279\n",
      "****************************\n",
      "Epoch: 4702\n",
      "train_loss = 87.7475\n",
      "test_loss = 74.4794\n",
      "****************************\n",
      "Epoch: 4703\n",
      "train_loss = 87.4609\n",
      "test_loss = 75.0021\n",
      "****************************\n",
      "Epoch: 4704\n",
      "train_loss = 87.4166\n",
      "test_loss = 75.4106\n",
      "****************************\n",
      "Epoch: 4705\n",
      "train_loss = 87.4337\n",
      "test_loss = 75.1447\n",
      "****************************\n",
      "Epoch: 4706\n",
      "train_loss = 87.4279\n",
      "test_loss = 75.3897\n",
      "****************************\n",
      "Epoch: 4707\n",
      "train_loss = 87.4333\n",
      "test_loss = 75.5569\n",
      "****************************\n",
      "Epoch: 4708\n",
      "train_loss = 87.8633\n",
      "test_loss = 77.2771\n",
      "****************************\n",
      "Epoch: 4709\n",
      "train_loss = 87.4708\n",
      "test_loss = 75.8765\n",
      "****************************\n",
      "Epoch: 4710\n",
      "train_loss = 87.4372\n",
      "test_loss = 75.1184\n",
      "****************************\n",
      "Epoch: 4711\n",
      "train_loss = 87.4477\n",
      "test_loss = 75.2112\n",
      "****************************\n",
      "Epoch: 4712\n",
      "train_loss = 87.8192\n",
      "test_loss = 77.1427\n",
      "****************************\n",
      "Epoch: 4713\n",
      "train_loss = 88.4157\n",
      "test_loss = 78.3042\n",
      "****************************\n",
      "Epoch: 4714\n",
      "train_loss = 87.9265\n",
      "test_loss = 74.3898\n",
      "****************************\n",
      "Epoch: 4715\n",
      "train_loss = 87.4926\n",
      "test_loss = 75.0263\n",
      "****************************\n",
      "Epoch: 4716\n",
      "train_loss = 87.4556\n",
      "test_loss = 75.7719\n",
      "****************************\n",
      "Epoch: 4717\n",
      "train_loss = 87.6742\n",
      "test_loss = 76.7026\n",
      "****************************\n",
      "Epoch: 4718\n",
      "train_loss = 87.7315\n",
      "test_loss = 74.5219\n",
      "****************************\n",
      "Epoch: 4719\n",
      "train_loss = 87.6603\n",
      "test_loss = 76.4993\n",
      "****************************\n",
      "Epoch: 4720\n",
      "train_loss = 87.6888\n",
      "test_loss = 76.7347\n",
      "****************************\n",
      "Epoch: 4721\n",
      "train_loss = 87.4396\n",
      "test_loss = 75.6885\n",
      "****************************\n",
      "Epoch: 4722\n",
      "train_loss = 88.1420\n",
      "test_loss = 77.9587\n",
      "****************************\n",
      "Epoch: 4723\n",
      "train_loss = 88.0807\n",
      "test_loss = 77.6681\n",
      "****************************\n",
      "Epoch: 4724\n",
      "train_loss = 87.7824\n",
      "test_loss = 74.5845\n",
      "****************************\n",
      "Epoch: 4725\n",
      "train_loss = 87.5970\n",
      "test_loss = 74.6934\n",
      "****************************\n",
      "Epoch: 4726\n",
      "train_loss = 87.8070\n",
      "test_loss = 76.8459\n",
      "****************************\n",
      "Epoch: 4727\n",
      "train_loss = 87.4528\n",
      "test_loss = 75.2108\n",
      "****************************\n",
      "Epoch: 4728\n",
      "train_loss = 87.5724\n",
      "test_loss = 76.0933\n",
      "****************************\n",
      "Epoch: 4729\n",
      "train_loss = 88.0040\n",
      "test_loss = 77.4840\n",
      "****************************\n",
      "Epoch: 4730\n",
      "train_loss = 87.4325\n",
      "test_loss = 75.2469\n",
      "****************************\n",
      "Epoch: 4731\n",
      "train_loss = 88.2591\n",
      "test_loss = 78.0148\n",
      "****************************\n",
      "Epoch: 4732\n",
      "train_loss = 87.6534\n",
      "test_loss = 74.6535\n",
      "****************************\n",
      "Epoch: 4733\n",
      "train_loss = 87.4782\n",
      "test_loss = 75.2627\n",
      "****************************\n",
      "Epoch: 4734\n",
      "train_loss = 87.4650\n",
      "test_loss = 75.3442\n",
      "****************************\n",
      "Epoch: 4735\n",
      "train_loss = 87.5288\n",
      "test_loss = 74.9256\n",
      "****************************\n",
      "Epoch: 4736\n",
      "train_loss = 87.4804\n",
      "test_loss = 75.8827\n",
      "****************************\n",
      "Epoch: 4737\n",
      "train_loss = 87.7915\n",
      "test_loss = 77.0841\n",
      "****************************\n",
      "Epoch: 4738\n",
      "train_loss = 87.4225\n",
      "test_loss = 75.6858\n",
      "****************************\n",
      "Epoch: 4739\n",
      "train_loss = 87.4282\n",
      "test_loss = 75.7234\n",
      "****************************\n",
      "Epoch: 4740\n",
      "train_loss = 87.5684\n",
      "test_loss = 74.7106\n",
      "****************************\n",
      "Epoch: 4741\n",
      "train_loss = 87.6077\n",
      "test_loss = 74.7014\n",
      "****************************\n",
      "Epoch: 4742\n",
      "train_loss = 87.6013\n",
      "test_loss = 74.6868\n",
      "****************************\n",
      "Epoch: 4743\n",
      "train_loss = 87.7836\n",
      "test_loss = 76.8442\n",
      "****************************\n",
      "Epoch: 4744\n",
      "train_loss = 88.9088\n",
      "test_loss = 79.1707\n",
      "****************************\n",
      "Epoch: 4745\n",
      "train_loss = 87.4945\n",
      "test_loss = 75.8788\n",
      "****************************\n",
      "Epoch: 4746\n",
      "train_loss = 87.5001\n",
      "test_loss = 75.3184\n",
      "****************************\n",
      "Epoch: 4747\n",
      "train_loss = 87.4637\n",
      "test_loss = 75.3702\n",
      "****************************\n",
      "Epoch: 4748\n",
      "train_loss = 87.5407\n",
      "test_loss = 76.0726\n",
      "****************************\n",
      "Epoch: 4749\n",
      "train_loss = 87.4783\n",
      "test_loss = 74.9740\n",
      "****************************\n",
      "Epoch: 4750\n",
      "train_loss = 87.7861\n",
      "test_loss = 74.4513\n",
      "****************************\n",
      "Epoch: 4751\n",
      "train_loss = 87.6536\n",
      "test_loss = 76.4930\n",
      "****************************\n",
      "Epoch: 4752\n",
      "train_loss = 87.4219\n",
      "test_loss = 75.4016\n",
      "****************************\n",
      "Epoch: 4753\n",
      "train_loss = 88.0737\n",
      "test_loss = 77.7432\n",
      "****************************\n",
      "Epoch: 4754\n",
      "train_loss = 87.9278\n",
      "test_loss = 74.4964\n",
      "****************************\n",
      "Epoch: 4755\n",
      "train_loss = 87.6483\n",
      "test_loss = 76.3757\n",
      "****************************\n",
      "Epoch: 4756\n",
      "train_loss = 88.0973\n",
      "test_loss = 74.2921\n",
      "****************************\n",
      "Epoch: 4757\n",
      "train_loss = 87.5704\n",
      "test_loss = 74.7636\n",
      "****************************\n",
      "Epoch: 4758\n",
      "train_loss = 87.6317\n",
      "test_loss = 74.6886\n",
      "****************************\n",
      "Epoch: 4759\n",
      "train_loss = 87.5620\n",
      "test_loss = 74.7665\n",
      "****************************\n",
      "Epoch: 4760\n",
      "train_loss = 87.4349\n",
      "test_loss = 75.5648\n",
      "****************************\n",
      "Epoch: 4761\n",
      "train_loss = 87.7060\n",
      "test_loss = 74.5190\n",
      "****************************\n",
      "Epoch: 4762\n",
      "train_loss = 87.4366\n",
      "test_loss = 75.5583\n",
      "****************************\n",
      "Epoch: 4763\n",
      "train_loss = 88.0775\n",
      "test_loss = 77.5900\n",
      "****************************\n",
      "Epoch: 4764\n",
      "train_loss = 87.4442\n",
      "test_loss = 75.3587\n",
      "****************************\n",
      "Epoch: 4765\n",
      "train_loss = 88.0898\n",
      "test_loss = 74.2353\n",
      "****************************\n",
      "Epoch: 4766\n",
      "train_loss = 87.4986\n",
      "test_loss = 75.6515\n",
      "****************************\n",
      "Epoch: 4767\n",
      "train_loss = 87.9377\n",
      "test_loss = 77.4221\n",
      "****************************\n",
      "Epoch: 4768\n",
      "train_loss = 87.4675\n",
      "test_loss = 75.1788\n",
      "****************************\n",
      "Epoch: 4769\n",
      "train_loss = 87.4497\n",
      "test_loss = 75.7484\n",
      "****************************\n",
      "Epoch: 4770\n",
      "train_loss = 87.4674\n",
      "test_loss = 75.0359\n",
      "****************************\n",
      "Epoch: 4771\n",
      "train_loss = 87.6359\n",
      "test_loss = 74.6242\n",
      "****************************\n",
      "Epoch: 4772\n",
      "train_loss = 87.4532\n",
      "test_loss = 75.1125\n",
      "****************************\n",
      "Epoch: 4773\n",
      "train_loss = 87.5727\n",
      "test_loss = 76.2628\n",
      "****************************\n",
      "Epoch: 4774\n",
      "train_loss = 87.4114\n",
      "test_loss = 75.5485\n",
      "****************************\n",
      "Epoch: 4775\n",
      "train_loss = 87.4613\n",
      "test_loss = 75.7166\n",
      "****************************\n",
      "Epoch: 4776\n",
      "train_loss = 88.0348\n",
      "test_loss = 77.5488\n",
      "****************************\n",
      "Epoch: 4777\n",
      "train_loss = 87.5045\n",
      "test_loss = 74.8905\n",
      "****************************\n",
      "Epoch: 4778\n",
      "train_loss = 87.6221\n",
      "test_loss = 74.5977\n",
      "****************************\n",
      "Epoch: 4779\n",
      "train_loss = 87.4789\n",
      "test_loss = 75.9457\n",
      "****************************\n",
      "Epoch: 4780\n",
      "train_loss = 87.4247\n",
      "test_loss = 75.5681\n",
      "****************************\n",
      "Epoch: 4781\n",
      "train_loss = 87.5120\n",
      "test_loss = 76.1749\n",
      "****************************\n",
      "Epoch: 4782\n",
      "train_loss = 87.4665\n",
      "test_loss = 75.3435\n",
      "****************************\n",
      "Epoch: 4783\n",
      "train_loss = 87.7174\n",
      "test_loss = 76.7649\n",
      "****************************\n",
      "Epoch: 4784\n",
      "train_loss = 87.6826\n",
      "test_loss = 74.5817\n",
      "****************************\n",
      "Epoch: 4785\n",
      "train_loss = 87.5655\n",
      "test_loss = 76.1940\n",
      "****************************\n",
      "Epoch: 4786\n",
      "train_loss = 87.4784\n",
      "test_loss = 75.0087\n",
      "****************************\n",
      "Epoch: 4787\n",
      "train_loss = 87.5377\n",
      "test_loss = 74.8069\n",
      "****************************\n",
      "Epoch: 4788\n",
      "train_loss = 87.9468\n",
      "test_loss = 74.7616\n",
      "****************************\n",
      "Epoch: 4789\n",
      "train_loss = 87.5463\n",
      "test_loss = 75.9197\n",
      "****************************\n",
      "Epoch: 4790\n",
      "train_loss = 87.7854\n",
      "test_loss = 76.9649\n",
      "****************************\n",
      "Epoch: 4791\n",
      "train_loss = 87.5011\n",
      "test_loss = 75.0767\n",
      "****************************\n",
      "Epoch: 4792\n",
      "train_loss = 87.4338\n",
      "test_loss = 75.3186\n",
      "****************************\n",
      "Epoch: 4793\n",
      "train_loss = 87.8355\n",
      "test_loss = 74.4749\n",
      "****************************\n",
      "Epoch: 4794\n",
      "train_loss = 87.5315\n",
      "test_loss = 76.1437\n",
      "****************************\n",
      "Epoch: 4795\n",
      "train_loss = 88.5562\n",
      "test_loss = 74.1623\n",
      "****************************\n",
      "Epoch: 4796\n",
      "train_loss = 87.5811\n",
      "test_loss = 74.6823\n",
      "****************************\n",
      "Epoch: 4797\n",
      "train_loss = 88.2878\n",
      "test_loss = 74.1798\n",
      "****************************\n",
      "Epoch: 4798\n",
      "train_loss = 87.4693\n",
      "test_loss = 75.8271\n",
      "****************************\n",
      "Epoch: 4799\n",
      "train_loss = 87.4665\n",
      "test_loss = 75.0671\n",
      "****************************\n",
      "Epoch: 4800\n",
      "train_loss = 87.4710\n",
      "test_loss = 75.9079\n",
      "****************************\n",
      "Epoch: 4801\n",
      "train_loss = 87.6423\n",
      "test_loss = 74.6182\n",
      "****************************\n",
      "Epoch: 4802\n",
      "train_loss = 87.4367\n",
      "test_loss = 75.5965\n",
      "****************************\n",
      "Epoch: 4803\n",
      "train_loss = 87.5720\n",
      "test_loss = 74.6976\n",
      "****************************\n",
      "Epoch: 4804\n",
      "train_loss = 87.5730\n",
      "test_loss = 76.4088\n",
      "****************************\n",
      "Epoch: 4805\n",
      "train_loss = 87.8938\n",
      "test_loss = 77.3994\n",
      "****************************\n",
      "Epoch: 4806\n",
      "train_loss = 87.4090\n",
      "test_loss = 75.1421\n",
      "****************************\n",
      "Epoch: 4807\n",
      "train_loss = 87.5890\n",
      "test_loss = 76.4478\n",
      "****************************\n",
      "Epoch: 4808\n",
      "train_loss = 88.5719\n",
      "test_loss = 74.8457\n",
      "****************************\n",
      "Epoch: 4809\n",
      "train_loss = 87.5979\n",
      "test_loss = 74.9093\n",
      "****************************\n",
      "Epoch: 4810\n",
      "train_loss = 87.4913\n",
      "test_loss = 75.8558\n",
      "****************************\n",
      "Epoch: 4811\n",
      "train_loss = 87.8820\n",
      "test_loss = 77.1593\n",
      "****************************\n",
      "Epoch: 4812\n",
      "train_loss = 87.4306\n",
      "test_loss = 75.3012\n",
      "****************************\n",
      "Epoch: 4813\n",
      "train_loss = 87.4731\n",
      "test_loss = 74.9792\n",
      "****************************\n",
      "Epoch: 4814\n",
      "train_loss = 87.5774\n",
      "test_loss = 76.3389\n",
      "****************************\n",
      "Epoch: 4815\n",
      "train_loss = 87.4718\n",
      "test_loss = 75.6727\n",
      "****************************\n",
      "Epoch: 4816\n",
      "train_loss = 88.2670\n",
      "test_loss = 77.9092\n",
      "****************************\n",
      "Epoch: 4817\n",
      "train_loss = 87.4459\n",
      "test_loss = 75.5636\n",
      "****************************\n",
      "Epoch: 4818\n",
      "train_loss = 87.5941\n",
      "test_loss = 74.6813\n",
      "****************************\n",
      "Epoch: 4819\n",
      "train_loss = 87.8905\n",
      "test_loss = 77.1803\n",
      "****************************\n",
      "Epoch: 4820\n",
      "train_loss = 87.5479\n",
      "test_loss = 74.7513\n",
      "****************************\n",
      "Epoch: 4821\n",
      "train_loss = 88.1149\n",
      "test_loss = 77.8781\n",
      "****************************\n",
      "Epoch: 4822\n",
      "train_loss = 87.4674\n",
      "test_loss = 75.0968\n",
      "****************************\n",
      "Epoch: 4823\n",
      "train_loss = 87.6979\n",
      "test_loss = 74.5317\n",
      "****************************\n",
      "Epoch: 4824\n",
      "train_loss = 87.5679\n",
      "test_loss = 76.2109\n",
      "****************************\n",
      "Epoch: 4825\n",
      "train_loss = 87.6308\n",
      "test_loss = 76.3749\n",
      "****************************\n",
      "Epoch: 4826\n",
      "train_loss = 87.5551\n",
      "test_loss = 76.2224\n",
      "****************************\n",
      "Epoch: 4827\n",
      "train_loss = 87.4753\n",
      "test_loss = 75.9206\n",
      "****************************\n",
      "Epoch: 4828\n",
      "train_loss = 87.5860\n",
      "test_loss = 76.3954\n",
      "****************************\n",
      "Epoch: 4829\n",
      "train_loss = 87.4117\n",
      "test_loss = 75.3879\n",
      "****************************\n",
      "Epoch: 4830\n",
      "train_loss = 87.5021\n",
      "test_loss = 75.9841\n",
      "****************************\n",
      "Epoch: 4831\n",
      "train_loss = 87.4605\n",
      "test_loss = 75.6270\n",
      "****************************\n",
      "Epoch: 4832\n",
      "train_loss = 88.4310\n",
      "test_loss = 78.3761\n",
      "****************************\n",
      "Epoch: 4833\n",
      "train_loss = 87.5075\n",
      "test_loss = 74.9549\n",
      "****************************\n",
      "Epoch: 4834\n",
      "train_loss = 87.5484\n",
      "test_loss = 75.8649\n",
      "****************************\n",
      "Epoch: 4835\n",
      "train_loss = 87.9327\n",
      "test_loss = 74.3444\n",
      "****************************\n",
      "Epoch: 4836\n",
      "train_loss = 87.7738\n",
      "test_loss = 76.9331\n",
      "****************************\n",
      "Epoch: 4837\n",
      "train_loss = 87.9570\n",
      "test_loss = 77.3476\n",
      "****************************\n",
      "Epoch: 4838\n",
      "train_loss = 87.7489\n",
      "test_loss = 76.9226\n",
      "****************************\n",
      "Epoch: 4839\n",
      "train_loss = 87.9604\n",
      "test_loss = 74.2672\n",
      "****************************\n",
      "Epoch: 4840\n",
      "train_loss = 88.0916\n",
      "test_loss = 74.2281\n",
      "****************************\n",
      "Epoch: 4841\n",
      "train_loss = 87.6340\n",
      "test_loss = 74.5689\n",
      "****************************\n",
      "Epoch: 4842\n",
      "train_loss = 87.8770\n",
      "test_loss = 74.3459\n",
      "****************************\n",
      "Epoch: 4843\n",
      "train_loss = 87.4539\n",
      "test_loss = 75.0710\n",
      "****************************\n",
      "Epoch: 4844\n",
      "train_loss = 87.5113\n",
      "test_loss = 75.4538\n",
      "****************************\n",
      "Epoch: 4845\n",
      "train_loss = 87.6669\n",
      "test_loss = 74.6751\n",
      "****************************\n",
      "Epoch: 4846\n",
      "train_loss = 87.8573\n",
      "test_loss = 74.3686\n",
      "****************************\n",
      "Epoch: 4847\n",
      "train_loss = 87.9069\n",
      "test_loss = 77.1863\n",
      "****************************\n",
      "Epoch: 4848\n",
      "train_loss = 88.0489\n",
      "test_loss = 74.2382\n",
      "****************************\n",
      "Epoch: 4849\n",
      "train_loss = 87.5288\n",
      "test_loss = 74.7608\n",
      "****************************\n",
      "Epoch: 4850\n",
      "train_loss = 87.6101\n",
      "test_loss = 76.3763\n",
      "****************************\n",
      "Epoch: 4851\n",
      "train_loss = 87.6409\n",
      "test_loss = 74.5784\n",
      "****************************\n",
      "Epoch: 4852\n",
      "train_loss = 87.6105\n",
      "test_loss = 74.7173\n",
      "****************************\n",
      "Epoch: 4853\n",
      "train_loss = 87.4645\n",
      "test_loss = 75.3462\n",
      "****************************\n",
      "Epoch: 4854\n",
      "train_loss = 87.9663\n",
      "test_loss = 74.3378\n",
      "****************************\n",
      "Epoch: 4855\n",
      "train_loss = 87.8468\n",
      "test_loss = 74.4840\n",
      "****************************\n",
      "Epoch: 4856\n",
      "train_loss = 87.6214\n",
      "test_loss = 74.6500\n",
      "****************************\n",
      "Epoch: 4857\n",
      "train_loss = 87.5831\n",
      "test_loss = 74.8181\n",
      "****************************\n",
      "Epoch: 4858\n",
      "train_loss = 87.4412\n",
      "test_loss = 75.4501\n",
      "****************************\n",
      "Epoch: 4859\n",
      "train_loss = 87.6172\n",
      "test_loss = 74.6364\n",
      "****************************\n",
      "Epoch: 4860\n",
      "train_loss = 87.5529\n",
      "test_loss = 74.7906\n",
      "****************************\n",
      "Epoch: 4861\n",
      "train_loss = 87.6161\n",
      "test_loss = 74.6300\n",
      "****************************\n",
      "Epoch: 4862\n",
      "train_loss = 87.6168\n",
      "test_loss = 75.6120\n",
      "****************************\n",
      "Epoch: 4863\n",
      "train_loss = 87.5285\n",
      "test_loss = 75.8651\n",
      "****************************\n",
      "Epoch: 4864\n",
      "train_loss = 87.5531\n",
      "test_loss = 76.0844\n",
      "****************************\n",
      "Epoch: 4865\n",
      "train_loss = 87.7122\n",
      "test_loss = 76.6025\n",
      "****************************\n",
      "Epoch: 4866\n",
      "train_loss = 87.7801\n",
      "test_loss = 76.5447\n",
      "****************************\n",
      "Epoch: 4867\n",
      "train_loss = 88.0383\n",
      "test_loss = 77.4528\n",
      "****************************\n",
      "Epoch: 4868\n",
      "train_loss = 87.6476\n",
      "test_loss = 74.6439\n",
      "****************************\n",
      "Epoch: 4869\n",
      "train_loss = 87.4735\n",
      "test_loss = 75.0771\n",
      "****************************\n",
      "Epoch: 4870\n",
      "train_loss = 87.7787\n",
      "test_loss = 74.4630\n",
      "****************************\n",
      "Epoch: 4871\n",
      "train_loss = 88.9194\n",
      "test_loss = 74.1288\n",
      "****************************\n",
      "Epoch: 4872\n",
      "train_loss = 87.4952\n",
      "test_loss = 75.1860\n",
      "****************************\n",
      "Epoch: 4873\n",
      "train_loss = 87.8716\n",
      "test_loss = 77.0439\n",
      "****************************\n",
      "Epoch: 4874\n",
      "train_loss = 87.4524\n",
      "test_loss = 75.6516\n",
      "****************************\n",
      "Epoch: 4875\n",
      "train_loss = 87.5284\n",
      "test_loss = 74.8231\n",
      "****************************\n",
      "Epoch: 4876\n",
      "train_loss = 87.5145\n",
      "test_loss = 74.8658\n",
      "****************************\n",
      "Epoch: 4877\n",
      "train_loss = 87.7655\n",
      "test_loss = 77.0365\n",
      "****************************\n",
      "Epoch: 4878\n",
      "train_loss = 87.4533\n",
      "test_loss = 75.6941\n",
      "****************************\n",
      "Epoch: 4879\n",
      "train_loss = 87.5606\n",
      "test_loss = 74.8276\n",
      "****************************\n",
      "Epoch: 4880\n",
      "train_loss = 87.4599\n",
      "test_loss = 75.5590\n",
      "****************************\n",
      "Epoch: 4881\n",
      "train_loss = 87.5157\n",
      "test_loss = 76.1125\n",
      "****************************\n",
      "Epoch: 4882\n",
      "train_loss = 87.4367\n",
      "test_loss = 75.2362\n",
      "****************************\n",
      "Epoch: 4883\n",
      "train_loss = 87.4648\n",
      "test_loss = 75.7803\n",
      "****************************\n",
      "Epoch: 4884\n",
      "train_loss = 88.0650\n",
      "test_loss = 74.2683\n",
      "****************************\n",
      "Epoch: 4885\n",
      "train_loss = 87.4519\n",
      "test_loss = 75.7598\n",
      "****************************\n",
      "Epoch: 4886\n",
      "train_loss = 87.6175\n",
      "test_loss = 74.5689\n",
      "****************************\n",
      "Epoch: 4887\n",
      "train_loss = 87.4883\n",
      "test_loss = 74.8548\n",
      "****************************\n",
      "Epoch: 4888\n",
      "train_loss = 87.7030\n",
      "test_loss = 74.4972\n",
      "****************************\n",
      "Epoch: 4889\n",
      "train_loss = 87.5566\n",
      "test_loss = 74.9599\n",
      "****************************\n",
      "Epoch: 4890\n",
      "train_loss = 87.4731\n",
      "test_loss = 75.3756\n",
      "****************************\n",
      "Epoch: 4891\n",
      "train_loss = 87.7726\n",
      "test_loss = 76.8340\n",
      "****************************\n",
      "Epoch: 4892\n",
      "train_loss = 87.4534\n",
      "test_loss = 75.5103\n",
      "****************************\n",
      "Epoch: 4893\n",
      "train_loss = 87.6529\n",
      "test_loss = 74.5408\n",
      "****************************\n",
      "Epoch: 4894\n",
      "train_loss = 87.4525\n",
      "test_loss = 75.7766\n",
      "****************************\n",
      "Epoch: 4895\n",
      "train_loss = 87.4285\n",
      "test_loss = 75.5788\n",
      "****************************\n",
      "Epoch: 4896\n",
      "train_loss = 87.4911\n",
      "test_loss = 76.0551\n",
      "****************************\n",
      "Epoch: 4897\n",
      "train_loss = 87.4417\n",
      "test_loss = 75.7321\n",
      "****************************\n",
      "Epoch: 4898\n",
      "train_loss = 87.5070\n",
      "test_loss = 75.9902\n",
      "****************************\n",
      "Epoch: 4899\n",
      "train_loss = 87.5731\n",
      "test_loss = 76.1486\n",
      "****************************\n",
      "Epoch: 4900\n",
      "train_loss = 87.6296\n",
      "test_loss = 76.4360\n",
      "****************************\n",
      "Epoch: 4901\n",
      "train_loss = 89.5390\n",
      "test_loss = 80.3225\n",
      "****************************\n",
      "Epoch: 4902\n",
      "train_loss = 87.4331\n",
      "test_loss = 75.4128\n",
      "****************************\n",
      "Epoch: 4903\n",
      "train_loss = 87.6401\n",
      "test_loss = 74.6000\n",
      "****************************\n",
      "Epoch: 4904\n",
      "train_loss = 87.4854\n",
      "test_loss = 75.8626\n",
      "****************************\n",
      "Epoch: 4905\n",
      "train_loss = 87.9282\n",
      "test_loss = 77.3425\n",
      "****************************\n",
      "Epoch: 4906\n",
      "train_loss = 88.5155\n",
      "test_loss = 78.5936\n",
      "****************************\n",
      "Epoch: 4907\n",
      "train_loss = 87.4865\n",
      "test_loss = 75.0976\n",
      "****************************\n",
      "Epoch: 4908\n",
      "train_loss = 87.4631\n",
      "test_loss = 75.7322\n",
      "****************************\n",
      "Epoch: 4909\n",
      "train_loss = 87.9538\n",
      "test_loss = 74.4293\n",
      "****************************\n",
      "Epoch: 4910\n",
      "train_loss = 87.5918\n",
      "test_loss = 74.9047\n",
      "****************************\n",
      "Epoch: 4911\n",
      "train_loss = 87.5451\n",
      "test_loss = 76.0833\n",
      "****************************\n",
      "Epoch: 4912\n",
      "train_loss = 87.5790\n",
      "test_loss = 76.3850\n",
      "****************************\n",
      "Epoch: 4913\n",
      "train_loss = 87.4626\n",
      "test_loss = 75.5057\n",
      "****************************\n",
      "Epoch: 4914\n",
      "train_loss = 87.4978\n",
      "test_loss = 74.9329\n",
      "****************************\n",
      "Epoch: 4915\n",
      "train_loss = 88.0640\n",
      "test_loss = 77.6720\n",
      "****************************\n",
      "Epoch: 4916\n",
      "train_loss = 87.8327\n",
      "test_loss = 74.5354\n",
      "****************************\n",
      "Epoch: 4917\n",
      "train_loss = 87.5916\n",
      "test_loss = 74.7971\n",
      "****************************\n",
      "Epoch: 4918\n",
      "train_loss = 87.5716\n",
      "test_loss = 76.2113\n",
      "****************************\n",
      "Epoch: 4919\n",
      "train_loss = 87.9970\n",
      "test_loss = 77.3909\n",
      "****************************\n",
      "Epoch: 4920\n",
      "train_loss = 87.7560\n",
      "test_loss = 74.4545\n",
      "****************************\n",
      "Epoch: 4921\n",
      "train_loss = 87.4983\n",
      "test_loss = 75.7255\n",
      "****************************\n",
      "Epoch: 4922\n",
      "train_loss = 87.5565\n",
      "test_loss = 74.7149\n",
      "****************************\n",
      "Epoch: 4923\n",
      "train_loss = 88.0448\n",
      "test_loss = 74.3674\n",
      "****************************\n",
      "Epoch: 4924\n",
      "train_loss = 87.8897\n",
      "test_loss = 76.9544\n",
      "****************************\n",
      "Epoch: 4925\n",
      "train_loss = 87.8514\n",
      "test_loss = 76.7748\n",
      "****************************\n",
      "Epoch: 4926\n",
      "train_loss = 87.6977\n",
      "test_loss = 74.5490\n",
      "****************************\n",
      "Epoch: 4927\n",
      "train_loss = 87.6486\n",
      "test_loss = 76.3052\n",
      "****************************\n",
      "Epoch: 4928\n",
      "train_loss = 89.0744\n",
      "test_loss = 79.4603\n",
      "****************************\n",
      "Epoch: 4929\n",
      "train_loss = 87.4841\n",
      "test_loss = 75.7000\n",
      "****************************\n",
      "Epoch: 4930\n",
      "train_loss = 87.5408\n",
      "test_loss = 74.8526\n",
      "****************************\n",
      "Epoch: 4931\n",
      "train_loss = 87.5317\n",
      "test_loss = 74.8690\n",
      "****************************\n",
      "Epoch: 4932\n",
      "train_loss = 87.5303\n",
      "test_loss = 75.4626\n",
      "****************************\n",
      "Epoch: 4933\n",
      "train_loss = 87.5287\n",
      "test_loss = 75.8346\n",
      "****************************\n",
      "Epoch: 4934\n",
      "train_loss = 87.4532\n",
      "test_loss = 75.3453\n",
      "****************************\n",
      "Epoch: 4935\n",
      "train_loss = 88.1722\n",
      "test_loss = 74.2654\n",
      "****************************\n",
      "Epoch: 4936\n",
      "train_loss = 87.6013\n",
      "test_loss = 75.9657\n",
      "****************************\n",
      "Epoch: 4937\n",
      "train_loss = 87.5953\n",
      "test_loss = 74.8207\n",
      "****************************\n",
      "Epoch: 4938\n",
      "train_loss = 87.5370\n",
      "test_loss = 75.2999\n",
      "****************************\n",
      "Epoch: 4939\n",
      "train_loss = 87.6526\n",
      "test_loss = 74.7041\n",
      "****************************\n",
      "Epoch: 4940\n",
      "train_loss = 87.5987\n",
      "test_loss = 74.7371\n",
      "****************************\n",
      "Epoch: 4941\n",
      "train_loss = 87.4744\n",
      "test_loss = 75.8360\n",
      "****************************\n",
      "Epoch: 4942\n",
      "train_loss = 89.4145\n",
      "test_loss = 74.4737\n",
      "****************************\n",
      "Epoch: 4943\n",
      "train_loss = 87.5341\n",
      "test_loss = 75.0804\n",
      "****************************\n",
      "Epoch: 4944\n",
      "train_loss = 87.4848\n",
      "test_loss = 75.3422\n",
      "****************************\n",
      "Epoch: 4945\n",
      "train_loss = 87.5792\n",
      "test_loss = 76.2973\n",
      "****************************\n",
      "Epoch: 4946\n",
      "train_loss = 87.7936\n",
      "test_loss = 74.5114\n",
      "****************************\n",
      "Epoch: 4947\n",
      "train_loss = 87.7726\n",
      "test_loss = 76.9951\n",
      "****************************\n",
      "Epoch: 4948\n",
      "train_loss = 87.4294\n",
      "test_loss = 75.3867\n",
      "****************************\n",
      "Epoch: 4949\n",
      "train_loss = 87.8454\n",
      "test_loss = 74.8045\n",
      "****************************\n",
      "Epoch: 4950\n",
      "train_loss = 87.6260\n",
      "test_loss = 76.3140\n",
      "****************************\n",
      "Epoch: 4951\n",
      "train_loss = 87.6037\n",
      "test_loss = 76.2955\n",
      "****************************\n",
      "Epoch: 4952\n",
      "train_loss = 87.5979\n",
      "test_loss = 76.1909\n",
      "****************************\n",
      "Epoch: 4953\n",
      "train_loss = 87.6029\n",
      "test_loss = 74.7059\n",
      "****************************\n",
      "Epoch: 4954\n",
      "train_loss = 87.9114\n",
      "test_loss = 74.6846\n",
      "****************************\n",
      "Epoch: 4955\n",
      "train_loss = 88.8322\n",
      "test_loss = 78.9924\n",
      "****************************\n",
      "Epoch: 4956\n",
      "train_loss = 87.5593\n",
      "test_loss = 76.0878\n",
      "****************************\n",
      "Epoch: 4957\n",
      "train_loss = 87.5320\n",
      "test_loss = 75.0135\n",
      "****************************\n",
      "Epoch: 4958\n",
      "train_loss = 87.5879\n",
      "test_loss = 75.9802\n",
      "****************************\n",
      "Epoch: 4959\n",
      "train_loss = 87.6873\n",
      "test_loss = 76.5066\n",
      "****************************\n",
      "Epoch: 4960\n",
      "train_loss = 87.6577\n",
      "test_loss = 76.4242\n",
      "****************************\n",
      "Epoch: 4961\n",
      "train_loss = 87.5772\n",
      "test_loss = 74.8364\n",
      "****************************\n",
      "Epoch: 4962\n",
      "train_loss = 87.6506\n",
      "test_loss = 74.6177\n",
      "****************************\n",
      "Epoch: 4963\n",
      "train_loss = 87.8639\n",
      "test_loss = 77.0514\n",
      "****************************\n",
      "Epoch: 4964\n",
      "train_loss = 87.4485\n",
      "test_loss = 75.2503\n",
      "****************************\n",
      "Epoch: 4965\n",
      "train_loss = 87.6138\n",
      "test_loss = 76.4534\n",
      "****************************\n",
      "Epoch: 4966\n",
      "train_loss = 87.6445\n",
      "test_loss = 76.4665\n",
      "****************************\n",
      "Epoch: 4967\n",
      "train_loss = 87.4739\n",
      "test_loss = 74.9317\n",
      "****************************\n",
      "Epoch: 4968\n",
      "train_loss = 87.4899\n",
      "test_loss = 74.8631\n",
      "****************************\n",
      "Epoch: 4969\n",
      "train_loss = 87.4184\n",
      "test_loss = 75.3654\n",
      "****************************\n",
      "Epoch: 4970\n",
      "train_loss = 88.0750\n",
      "test_loss = 74.2057\n",
      "****************************\n",
      "Epoch: 4971\n",
      "train_loss = 87.4446\n",
      "test_loss = 75.0244\n",
      "****************************\n",
      "Epoch: 4972\n",
      "train_loss = 87.5428\n",
      "test_loss = 74.7069\n",
      "****************************\n",
      "Epoch: 4973\n",
      "train_loss = 87.5353\n",
      "test_loss = 74.7819\n",
      "****************************\n",
      "Epoch: 4974\n",
      "train_loss = 87.4991\n",
      "test_loss = 75.9920\n",
      "****************************\n",
      "Epoch: 4975\n",
      "train_loss = 87.4915\n",
      "test_loss = 75.9453\n",
      "****************************\n",
      "Epoch: 4976\n",
      "train_loss = 87.4149\n",
      "test_loss = 75.2894\n",
      "****************************\n",
      "Epoch: 4977\n",
      "train_loss = 87.6118\n",
      "test_loss = 76.5721\n",
      "****************************\n",
      "Epoch: 4978\n",
      "train_loss = 87.7593\n",
      "test_loss = 74.4621\n",
      "****************************\n",
      "Epoch: 4979\n",
      "train_loss = 88.1390\n",
      "test_loss = 77.9098\n",
      "****************************\n",
      "Epoch: 4980\n",
      "train_loss = 88.1706\n",
      "test_loss = 74.5702\n",
      "****************************\n",
      "Epoch: 4981\n",
      "train_loss = 87.6380\n",
      "test_loss = 76.4773\n",
      "****************************\n",
      "Epoch: 4982\n",
      "train_loss = 87.6980\n",
      "test_loss = 74.8951\n",
      "****************************\n",
      "Epoch: 4983\n",
      "train_loss = 87.6499\n",
      "test_loss = 76.3954\n",
      "****************************\n",
      "Epoch: 4984\n",
      "train_loss = 87.4918\n",
      "test_loss = 75.4941\n",
      "****************************\n",
      "Epoch: 4985\n",
      "train_loss = 87.8186\n",
      "test_loss = 74.4540\n",
      "****************************\n",
      "Epoch: 4986\n",
      "train_loss = 87.4608\n",
      "test_loss = 75.6508\n",
      "****************************\n",
      "Epoch: 4987\n",
      "train_loss = 87.5446\n",
      "test_loss = 75.5555\n",
      "****************************\n",
      "Epoch: 4988\n",
      "train_loss = 87.5469\n",
      "test_loss = 75.3663\n",
      "****************************\n",
      "Epoch: 4989\n",
      "train_loss = 87.6129\n",
      "test_loss = 74.7771\n",
      "****************************\n",
      "Epoch: 4990\n",
      "train_loss = 87.5559\n",
      "test_loss = 75.5085\n",
      "****************************\n",
      "Epoch: 4991\n",
      "train_loss = 87.9794\n",
      "test_loss = 74.3942\n",
      "****************************\n",
      "Epoch: 4992\n",
      "train_loss = 88.0890\n",
      "test_loss = 74.2948\n",
      "****************************\n",
      "Epoch: 4993\n",
      "train_loss = 87.8897\n",
      "test_loss = 74.4437\n",
      "****************************\n",
      "Epoch: 4994\n",
      "train_loss = 88.4265\n",
      "test_loss = 78.2149\n",
      "****************************\n",
      "Epoch: 4995\n",
      "train_loss = 87.5471\n",
      "test_loss = 74.8586\n",
      "****************************\n",
      "Epoch: 4996\n",
      "train_loss = 87.6195\n",
      "test_loss = 76.1880\n",
      "****************************\n",
      "Epoch: 4997\n",
      "train_loss = 87.6650\n",
      "test_loss = 76.5352\n",
      "****************************\n",
      "Epoch: 4998\n",
      "train_loss = 87.5505\n",
      "test_loss = 76.1569\n",
      "****************************\n",
      "Epoch: 4999\n",
      "train_loss = 87.4431\n",
      "test_loss = 75.5528\n",
      "****************************\n",
      "Epoch: 5000\n",
      "train_loss = 87.9318\n",
      "test_loss = 77.3024\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Создание и обучение нейронной сети\n",
    "net = Net()\n",
    "net.add('Linear', X_train.shape[1], 32, momentum=0.9)\n",
    "net.add('ReLU')\n",
    "net.add('Linear', 32, 16, momentum=0.9)\n",
    "net.add('ReLU')\n",
    "net.add('Linear', 16, 1, momentum=0.9)\n",
    "loss = net.MeanSquaredError()\n",
    "\n",
    "net.fit(\n",
    "    task_type='regression',\n",
    "    train_dataset=[X_train, y_train],\n",
    "    val_dataset=[X_test, y_test],\n",
    "    loss_f=loss,\n",
    "    epochs=5000,\n",
    "    batch_size=32,\n",
    "    lr=2e-4,\n",
    "    optimizer='momentum_sgd'\n",
    "    # optimizer='gd'\n",
    "    # optimizer='sgd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.11881562]]\n",
      "21.2\n",
      "[[22.75336555]]\n",
      "9.6\n",
      "[[23.55754632]]\n",
      "18.8\n"
     ]
    }
   ],
   "source": [
    "n = 78\n",
    "print(net.predict(X_scaled[n]))\n",
    "print(y.iloc[n])\n",
    "\n",
    "n = 436\n",
    "print(net.predict(X_scaled[n]))\n",
    "print(y.iloc[n])\n",
    "\n",
    "n = 112\n",
    "print(net.predict(X_scaled[n]))\n",
    "print(y.iloc[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.53328008]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict([0,0,2,0,0,0,0.2,0,0,0,0,0.3,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.007036528680711918,\n",
       " 73.84979842879568,\n",
       " 6.223938633316221,\n",
       " 39.31507465539874)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
